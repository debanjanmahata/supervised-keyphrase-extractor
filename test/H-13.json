{"abstract": "Web search engines present lists of captions , comprising title , snippet , and URL , to help users decide which search results to visit .Understanding the influence of features of these captions on Web search behavior may help validate algorithms and guidelines for their improved generation .In this paper we develop a methodology to use clickthrough logs from a commercial search engine to study user behavior when interacting with search result captions .The findings of our study suggest that relatively simple caption features such as the presence of all terms query terms , the readability of the snippet , and the length of the URL shown in the caption , can significantly influence users ' Web search behavior .", "id": "H-13", "conclusions": "Clickthrough inversions form an appropriate tool for assessing the influence of caption features .Using clickthrough inversions , we have demonstrated that relatively simple caption features can significantly influence user behavior .To our knowledge , this is first methodology validated for assessing the quality of Web captions through implicit feedback .In the future , we hope to substantially expand this work , considering more features over larger datasets .We also hope to directly address the goal of predicting relevance from clickthoughs and other information present in search engine logs .", "reader_keywords_stem": ["clickthrough pattern", "caption featur", "web search behavior", "human factor", "extract summar", "snippet", "queri log", "queri re-formul", "signific word", "clickthrough invers", "queri term match"], "combined_keywords_stem": ["clickthrough pattern", "caption featur", "web search behavior", "human factor", "extract summar", "snippet", "queri log", "queri re-formul", "signific word", "clickthrough invers", "queri term match", "web search", "summar"], "introduction": "The major commercial Web search engines all present their results in much the same way .Each search result is described by a brief caption , comprising the URL of the associated Web page , a title , and a brief summary or `` snippet '' describing the contents of the page .Often the snippet is extracted from the Web page itself , but it may also be taken from external sources , such as the human-generated summaries found in Web directories .Figure 1 shows a typical Web search , with captions for the top three results .While the three captions share the samebasic structure , their content differs in several respects .The snippet of the third caption is nearly twice as long as that of the first , while the snippet is missing entirely from the second caption .The title of the third caption contains all of the query terms in order , while the titles of the first and second captions contain only two of the three terms .One of the query terms is repeated in the first caption .All of the query terms appear in the URL of the third caption , while none appear in the URL of the first caption .The snippet of the first caption consists of a complete sentence that concisely describes the associated page , while the snippet of the third caption consists of two incomplete sentences that are largely unrelated to the overall contents of the associated page and to the apparent intent of the query .While these differences may seem minor , they may also have a substantial impact on user behavior .A principal motivation for providing a caption is to assist the user in determining the relevance of the associated page without actually having to click through to the result .In the case of a navigational query particularly when the destination is well known the URL alone may be sufficient to identify the desired page .But in the case of an informational query , the title and snippet may be necessary to guide the user in selecting a page for further study , and she may judge the relevance of a page on the basis of the caption alone .When this judgment is correct , it can speed the search process by allowing the user to avoid unwanted material .When it fails , the user may waste her time clicking through to an inappropriate result and scanning a page containing little or nothing of interest .Even worse , the user may be misled into skipping a page that contains desired information .All three of the results in figure 1 are relevant , with some limitations .The first result links to the main Yahoo Kids !homepage , but it is then necessary to follow a link in a menu to find the main page for games .Despite appearances , the second result links to a surprisingly large collection of online games , primarily with environmental themes .The third result might be somewhat disappointing to a user , since it leads to only a single game , hosted at the Centers for Disease Control , that could not reasonably be described as `` online '' .Unfortunately , these page characteristics are not entirely reflected in the captions .In this paper , we examine the influence of caption features on user 's Web search behavior , using clickthroughs extracted from search engines logs as our primary investigative tool .Understanding this influence may help to validate algorithms and guidelines for the improved generation of thecaptions themselves .In addition , these features can play a role in the process of inferring relevance judgments from user behavior 1 .By better understanding their influence , better judgments may result .Different caption generation algorithms might select snippets of different lengths from different areas of a page .Snippets may be generated in a query-independent fashion , providing a summary of the page as a whole , or in a querydependent fashion , providing a summary of how the page relates to the query terms .The correct choice of snippet may depend on aspects of both the query and the result page .The title may be taken from the HTML header or extracted from the body of the document 8 .For links that re-direct , it may be possible to display alternative URLs .Moreover , for pages listed in human-edited Web directories such as the Open Directory Project ' , it may be possible to display alternative titles and snippets derived from these listings .When these alternative snippets , titles and URLs are available , the selection of an appropriate combination for display may be guided by their features .A snippet from a Web directory may consist of complete sentences and be less fragmentary than an extracted snippet .A title extracted from the body may provide greater coverage of the query terms .A URL before re-direction may be shorter and provide a clearer idea of the final destination .The work reported in this paper was undertaken in the context of the Windows Live search engine .The image in figure 1 was captured from Windows Live and cropped to eliminate branding , advertising and navigational elements .The experiments reported in later sections are based on Windows Live query logs , result pages and relevance judgments collected as part of ongoing research into search engine performance 1 , 2 .Nonetheless , given the similarity of caption formats across the major Web search engines we believe the results are applicable to these other engines .The query in ` www.dmoz.org figure 1 produces results with similar relevance on the other major search engines .This and other queries produce captions that exhibit similar variations .In addition , we believe our methodology may be generalized to other search applications when sufficient clickthrough data is available .", "title": "The Influence of Caption Features on Clickthrough Patterns in Web Search", "method": "Many researchers have explored alternative methods for displaying Web search results .Dumais et al. 5 compared an interface typical of those used by major Web search engines with one that groups results by category , finding that users perform search tasks faster with the category interface .Paek et al. 12 propose an interface based on a fisheye lens , in which mouse hovers and other events cause captions to zoom and snippets to expand with additional text .White et al. 17 evaluated three alternatives to the standard Web search interface : one that displays expanded summaries on mouse hovers , one that displays a list of top ranking sentences extracted from the results taken as a group , and one that updates this list automatically through implicit feedback .They treat the length of time that a user spends viewing a summary as an implicit indicator of relevance .Their goal was to improve the ability of users to interact with a given result set , helping them to look beyond the first page of results and to reduce the burden of query re-formulation .Outside the narrow context of Web search considerable related research has been undertaken on the problem of document summarization .The basic idea of extractive summarization creating a summary by selecting sentences or fragments goes back to the foundational work of Luhn 11 .Luhn 's approach uses term frequencies to identify `` significant words '' within a document and then selects and extracts sentences that contain significant words in close proximity .A considerable fraction of later work may be viewed as extending and tuning this basic approach , developing improved methods for identifying significant words and selecting sentences .For example , a recent paper by Sun et al. 14 describes a variant of Luhn 's algorithm that uses clickthrough data to identify significant words .At its simplest , snippet generation for Web captions might also be viewed as following this approach , with query terms taking on the role of significant words .Since 2000 , the annual Document Understanding Conference DUC series , conducted by the US National Institute of Standards and Technology , has provided a vehicle for evaluating much of the research in document summarization2 .Each year DUC defines a methodology for one or more experimental tasks , and supplies the necessary test documents , human-created summaries , and automatically extracted baseline summaries .The majority of participating systems use extractive summarization , but a number attempt natural language generation and other approaches .Evaluation at DUC is achieved through comparison with manually generated summaries .Over the years DUC has included both single-document summarization and multidocument summarization tasks .The main DUC 2007 task is posed as taking place in a question answering context .Given a topic and 25 documents , participants were asked to generate a 250-word summary satisfying the information need enbodied in the topic .We view our approach of evaluating summarization through the analysis of Web logs as complementing the approach taken at DUC .A number of other researchers have examined the value of query-dependent summarization in a non-Web context .Tombros and Sanderson 15 compared the performance of 20 subjects searching a collection of newspaper articles when 2duc .nist.gov guided by query-independent vs. query-dependent snippets .The query-independent snippets were created by extracting the first few sentences of the articles ; the query-dependent snippets were created by selecting the highest scoring sentences under a measure biased towards sentences containing query terms .When query-dependent summaries were presented , subjects were better able to identify relevant documents without clicking through to the full text .Goldstein et al. 6 describe another extractive system for generating query-dependent summaries from newspaper articles .In their system , sentences are ranked by combining statistical and linguistic features .They introduce normalized measures of recall and precision to facilitate evaluation .Queries and clickthroughs taken from the logs of commercial Web search engines have been widely used to improve the performance of these systems and to better understand how users interact with them .In early work , Broder 3 examined the logs of the AltaVista search engine and identified three broad categories of Web queries : informational , navigational and transactional .Rose and Levinson 13 conducted a similar study , developing a hierarchy of query goals with three top-level categories : informational , navigational and resource .Under their taxonomy , a transactional query as defined by Broder might fall under either of their three categories , depending on details of the desired transaction .Lee et al. 10 used clickthrough patterns to automatically categorize queries into one of two categories : informational for which multiple Websites may satisfy all or part of the user 's need and navigational for which users have a particular Website in mind .Under their taxonomy , a transactional or resource query would be subsumed under one of these two categories .Agichtein et al. interpreted caption features , clickthroughs and other user behavior as implicit feedback to learn preferences 2 and improve ranking 1 in Web search .Xue et al. 18 present several methods for associating queries with documents by analyzing clickthrough patterns and links between documents .Queries associated with documents in this way are treated as meta-data .In effect , they are added to the document content for indexing and ranking purposes .Of particular interest to us is the work of Joachims et al. 9 and Granka et al. 7 .They conducted eye-tracking studies and analyzed log data to determine the extent to which clickthrough data may be treated as implicit relevance judgments .They identified a `` trust bias '' , which leads users to prefer the higher ranking result when all other factors are equal .In addition , they explored techniques that treat clicks as pairwise preferences .For example , a click at position N + 1 after skipping the result at position N may be viewed as a preference for the result at position N +1 relative to the result at position N .These findings form the basis of the clickthrough inversion methodology we use to interpret user interactions with search results .Our examination of large search logs compliments their detailed analysis of a smaller number of participants .While other researchers have evaluated the display of Web search results through user studies presenting users with a small number of different techniques and asking them to complete experimental tasks we approach the problemby extracting implicit feedback from search engine logs .Examining user behavior in situ allows us to consider many more queries and caption characteristics , with the volume of available data compensating for the lack of a controlled lab environment .The problem remains of interpreting the information in these logs as implicit indicators of user preferences , and in this matter we are guided by the work of Joachims et al. 9 .We consider caption pairs , which appear adjacent to one another in the result list .Our primary tool for examining the influence of caption features is a type of pattern observed with respect to these caption pairs , which we call a clickthrough inversion .A clickthrough inversion occurs at position N when the result at position N receives fewer clicks than the result at position N + 1 .Following Joachims et al. 9 , we interpret a clickthrough inversion as indicating a preference for the lower ranking result , overcoming any trust bias .For simplicity , in the remainder of this paper we refer to the higher ranking caption in a pair as `` caption A '' and the lower ranking caption as `` caption B '' .For the experiments reported in this paper , we sampled a subset of the queries and clickthroughs from the logs of the Windows Live search engine over a period of 3-4 days on three separate occasions : once for results reported in section 3.3 , once for a pilot of our main experiment , and once for the experiment itself sections 4 and 5 .For simplicity we restricted our sample to queries submitted to the US English interface and ignored any queries containing complex or non-alphanumeric terms e.g. operators and phrases .At the end of each sampling period , we downloaded captions for the queries associated with the clickthrough sample .When identifying clickthroughs in search engine logs , we consider only the first clickthrough action taken by a user after entering a query and viewing the result page .Users are identified by IP address , which is a reasonably reliable method of eliminating multiple results from a single user , at the cost of falsely eliminating results from multiple users sharing the same address .By focusing on the initial clickthrough , we hope to capture a user 's impression of the relative relevance within a caption pair when first encountered .If the user later clicks on other results or re-issues the same query , we ignore these actions .Any preference captured by a clickthrough inversion is therefore a preference among a group of users issuing a particular query , rather than a preference on the part of a single user .In the remainder of the paper , we use the term `` clickthrough '' to refer only to this initial action .Given the dynamic nature of the Web and the volumes of data involved , search engine logs are bound to contain considerable `` noise '' .For example , even over a period of hours or minutes the order of results for a given query can change , with some results dropping out of the top ten and new ones appearing .For this reason , we retained clickthroughs for a specific combination of a query and a result only if this result appears in a consistent position for at least 50 % of the clickthroughs .Clickthroughs for the same result when it appeared at other positions were discarded .For similar reasons , if we did not detect at least ten clickthroughs for a particular query during the sampling period , no clickthroughs for that query were retained .The outcome at the end of each sampling period is a set of records , with each record describing the clickthroughs for a given query/result combination .Each record includes a query , a result position , a title , a snippet , a URL , the number of clickthroughs for this result , and the total number of clickthroughs for this query .We then processed this set to generate clickthrough curves and identify inversions .It could be argued that under ideal circumstances , clickthrough inversions would not be present in search engine logs .A hypothetical `` perfect '' search engine would respond to a query by placing the result most likely to be relevant first in the result list .Each caption would appropriately summarize the content of the linked page and its relationship to the query , allowing users to make accurate judgments .Later results would complement earlier ones , linking to novel or supplementary material , and ordered by their interest to the greatest number of users .Figure 2 provides clickthrough curves for three example queries .For each example , we plot the percentage of clickthroughs against position for the top ten results .The first query craigslist is stereotypically navigational , showing a spike at the `` correct '' answer www.craigslist.org .The second query is informational in the sense of Lee et al. 10 periodic table of elements .Its curve is flatter and less skewed toward a single result .For both queries , the number of clickthroughs is consistent with the result positions , with the percentage of clickthroughs decreasing monotonically as position increases , the ideal behavior .Regrettably , no search engine is perfect , and clickthrough inversions are seen for many queries .For example , for the third query kids online games the clickthrough curve exhibits a number of clickthrough inversions , with an apparent preference for the result at position 4 .Several causes may be enlisted to explain the presence of an inversion in a clickthrough curve .The search engine may have failed in its primary goal , ranking more relevant results below less relevant results .Even when the relative ranking is appropriate , a caption may fail to reflect the content of the underlying page with respect to the query , leading the user to make an incorrect judgment .Before turning to the second case , we address the first , and examine the extent to which relevance alone may explain these inversions .The simplest explanation for the presence of a clickthrough inversion is a relevance difference between the higher ranking member of caption pair and the lower ranking member .In order to examine the extent to which relevance plays a role in clickthrough inversions , we conducted an initial experiment using a set of 1,811 queries with associated judgments created as part of on-going work .Over a four-day period , we sampled the search engine logs and extracted over one hundred thousand clicks involving these queries .From these clicks we identified 355 clickthrough inversions , satisfying the criteria of section 3.1 , where relevance judgments existed for both pages .The relevance judgments were made by independent assessors viewing the pages themselves , rather than the captions .Relevance was assessed on a 6-point scale .The outcome is presented in figure 3 , which shows the explicit judgments for the 355 clickthrough inversions .In all of these cases , there were more clicks on the lower ranked member of thepair B .The figure shows the corresponding relevance judgments .For example , the first row rel A < rel B , indicates that the higher ranking member of pair A was rated as less relevant than the lower ranking member of the pair B .As we see in the figure , relevance alone appears inadequate to explain the majority of clickthrough inversions .For twothirds of the inversions 236 , the page associated with caption A is at least as relevant as the page associated with caption B. For 28.7 % of the inversions , A has greater relevance than B , which received the greater number of clickthroughs .Having demonstrated that clickthrough inversions can not always be explained by relevance differences , we explore what features of caption pairs , if any , lead users to prefer one caption over another .For example , we may hypothesize that the absence of a snippet in caption A and the presence of a snippet in caption B e.g. captions 2 and 3 in figure 1 leads users to prefer caption A. Nonetheless , due to competing factors , a large set of clickthrough inversions may also include pairs where the snippet is missing in caption B and not in caption A. However , if we compare a large set of clickthrough inversions to a similar set of pairs for which the clickthroughs are consistent with their ranking , we would expect to see relatively more pairs where the snippet was missing in caption A.Following this line of reasoning , we extracted two sets of caption pairs from search logs over a three day period .The first is a set of nearly five thousand clickthrough inversions , extracted according to the procedure described in section 3.1 .The second is a corresponding set of caption pairs that do not exhibit clickthrough inversions .In other words , for pairs in this set , the result at the higher rank caption A received more clickthroughs than the result at the lower rank caption B .To the greatest extent possible , each pair in the second set was selected to correspond to a pair in the first set , in terms of result position and number of clicks on each result .We refer to the first set , containing clickthrough inversions , as the INV set ; we refer to the second set , containing caption pairs for which the clickthroughs are consistent with their rank order , as the CON set .We extract a number of features characterizing snippets described in detail in the next section and compare the presence of each feature in the INV and CON sets .We describe the features as a hypothesized preference e.g. , a preference for captions containing a snippet .Thus , in either set , a given feature may be present in one of two forms : favoring the higher ranked caption caption A or favoring the lower ranked caption caption B .For example , the abtitle of caption A contains matches to fewer query terms than the title of caption B title + snippet of caption A contains matches to fewer query terms than the title + snippet of caption B title + snippet + URL of caption A contains matches to fewer query terms than caption B title of caption B but not A starts with a phrase match to the query title + snippet + url contains the query as a phrase match caption B contains one match to each term ; caption A contains more matches with missing termstitle or snippet of caption B but not A contains the term `` official '' with stemming title or snippet of caption B but not A contains the phrase `` home page '' title or snippet of caption B but not A contains a term suggesting the presence of an image gallery caption B but not A passes a simple readability testsence of a snippet in caption A favors caption B , and the absence of a snippet in caption B favors caption A .When the feature favors caption B consistent with a clickthrough inversion we refer to the caption pair as a `` positive '' pair .When the feature favors caption A , we refer to it as a `` negative '' pair .For missing snippets , a positive pair has the caption missing in caption A but not B and a negative pair has the caption missing in B but not A .Thus , for a specific feature , we can construct four subsets : 1 INV + , the set of positive pairs from INV ; 2 INV , the set of negative pairs from INV ; 3 CON + ; the set of positive pairs from CON ; and 4 CON the set of negative pairs from CON .The sets INV + , INV , CON + , and CON will contain different subsets of INV and CON for each feature .When stating a feature corresponding to a hypothesized user preference , we follow the practice of stating the feature with the expectation that the size of INV + relative to the size of INV should be greater than the size of CON + relative to the size of CON .For example , we state the missing snippet feature as `` snippet missing in caption A and present in caption B '' .This evaluation methodology allows us to construct a contingency table for each feature , with INV essentially forming the experimental group and CON the control group .We can then apply Pearson 's chi-square test for significance .Figure 4 lists the features tested .Many of the features on this list correspond to our own assumptions regarding the importance of certain caption characteristics : the presence of query terms , the inclusion of a snippet , and the importance of query term matches in the title .Other features suggested themselves during the examination of the snippets collected as part of the study described in section 3.3 and during a pilot of the evaluation methodology section 4.1 .For this pilot we collected INV and CON sets of similar sizes , and used these sets to evaluate a preliminary list of features and to establish appropriate parameters for the SnippetShort and Readable features .In the pilot , all of the features list in figure 4 were significant at the 95 % level .A small number of other features were dropped after the pilot .These features all capture simple aspects of the captions .The first feature concerns the existence of a snippet and the second concerns the relative size of snippets .Apart from this first feature , we ignore pairs where one caption has a missing snippet .These pairs are not included in the sets constructed for the remaining features , since captions with missing snippets do not contain all the elements of a standard caption and we wanted to avoid their influence .The next six features concern the location and number of matching query terms .For the first five , a match for each query term is counted only once , additional matches for the same term are ignored .The MatchAll feature tests the idea that matching all the query terms exactly once is preferable to matching a subset of the terms many times with a least one query term unmatched .The next three features concern the URLs , capturing aspects of their length and complexity , and the last four features concern caption content .The first two of these content features Official and Home suggest claims about the importance or significance of the associated page .The third content feature Image suggests the presence of an image gallery , a popular genre of Web page .Terms represented by this feature include `` pictures '' , `` pics '' , and `` gallery '' .The last content feature Readable applies an ad hoc readability metric to each snippet .Regular users of Web search engines may notice occasional snippets that consist of little more than lists of words and phrases , rather than a coherent description .We define our own metric , since the Flesch-Kincaid readability score and similar measures are intended for entire documents not text fragments .While the metric has not been experimentally validated , it does reflect our intuitions and observations regarding result snippets .In English , the 100 most frequent words represent about 48 % of text , and we would expect readable prose , as opposed to a disjointed list of words , to contain these words in roughly this proportion .The Readable feature computes the percentage of these top-100 words appearing in each caption .If these words represent more than 40 % of one caption and less than 10 % of the other , the pair is included in the appropriate set .Figure 5 presents the results .Each row lists the size of the four sets INV + , INV \u2212 , CON + , and CON \u2212 for a given feature and indicates the percentage of positive pairs % + for INV and CON .In order to reject the null hypothesis , this percentage should be significantly greater for INV than CON .Except in one case , we applied the chi-squared test of independence to these sizes , with p-values shown in the last column .For the MatchAll feature , where the sum of the set sizes is 15 , we applied Fisher 's exact test .Features supported at the 95 % confidence level are bolded .", "evaluation": "The results support claims that missing snippets , short snippets , missing query terms and complex URLs negatively impact clickthroughs .While this outcome may not be surprising , we are aware of no other work that can provide support for claims of this type in the context of a commercial Web search engine .This work was originally motivated by our desire to validate some simple guidelines for the generation of captions summarizing opinions that we formulated while working on related issues .While our results do not direct address all of the many variables that influence users understanding of captions , they are consistent with the major guidelines .Further work is needed to provide additional support for the guidelines and to understand the relationships among variables .The first of these guidelines underscores the importance of displaying query terms in context : Whenever possible all of the query terms should appear in the caption , reflecting their relationship to the associated page .If a query term is missing from a caption , the user may have no idea why the result was returned .The results for the MatchAll feature directly support this guideline .The results for TermMatchTitle and TermMatchTSU confirm that matching more terms is desirable .Other features provide additional indirect support for this guideline , and none of the results are inconsistent with it .A second guideline speaks to the desirability of presenting the user with a readable snippet : When query terms are present in the title , they need not be repeated in the snippet .In particular , when a high-quality query-independent summary is available from an external source , such as a Web directory , it may be more appropriate to display this summary than a lower-quality query-dependent fragment selected on-the-fly .When titles are available from multiple sources the header , the body , Web directories a caption generation algorithm might a select a combination of title , snippet and URL that includes as many of the query terms as possible .When a title containing all query terms can be found , the algorithm might select a query-independent snippet .The MatchAll and Readable features directly support this guideline .Once again , other features provide indirect support , and none of the results are inconsistent with it .Finally , the length and complexity of a URL influences user behavior .When query terms appear in the URL they should highlighted or otherwise distinguished .When multiple URLs reference the same page due to re-directions , etc. the shortest URL should be preferred , provided that all query terms will still appear in the caption .In other words , URLs should be selected and displayed in a manner that emphasizes their relationship to the query .The three URL features , as well as TermMatchTSU , directly support this guideline .The influence of the Official and Image features led us to wonder what other terms are prevalent in the captions of clickthrough inversions .As an additional experiment , we treated each of the terms appearing in the INV and CON sets as a separate feature case normalized , ranking them by their \u03c72 values .The results are presented in figure 6 .Since we use the \u03c72 statistic as a divergence measure , rather than a significance test , no p-values are given .The final column of the table indicates the direction of the influence , whether the presence of the terms positively or negatively influence clickthroughs .The positive influence of `` official '' has already been observed the difference in the \u03c72 value from that of figure 5 is due to stemming .None of the terms included in the Imagefeature appear in the top ten , but `` pictures '' and `` photos '' appear at positions 21 and 22 .The high rank given to `` and '' may be related to readability the term `` the '' appears in position 20 .Most surprising to us is the negative influence of the terms : `` encyclopedia '' , `` wikipedia '' , `` free '' , and `` medlineplus '' .The first three terms appear in the title of Wikipedia articles3 and the last appears in the title of MedlinePlus articles4 .These individual word-level features provide hints about issues .More detailed analyses and further experiments will be required to understand these features .", "author_keywords_stem": ["web search", "summar", "snippet", "queri log"], "related work": "While commercial Web search engines have followed similar approaches to caption display since their genesis , relatively little research has been published about methods for generating these captions and evaluating their impact on user behavior .Most related research in the area of document summarization has focused on newspaper articles and similar material , rather than Web pages , and has conducted evaluations by comparing automatically generated summaries with manually generated summaries .Most research on the display of Web results has proposed substantial interface changes , rather than addressing details of the existing interfaces .Varadarajan and Hristidis 16 are among the few who have attempted to improve directly upon the snippets generated by commercial search systems , without introducing additional changes to the interface .They generated snippets from spanning trees of document graphs and experimentally compared these snippets against the snippets generated for the same documents by the Google desktop search system and MSN desktop search system .They evaluated their method by asking users to compare snippets from the various sources .Cutrell and Guan 4 conducted an eye-tracking study to investigate the influence of snippet length on Web search performance and found that the optimal snippet length varied according to the task type , with longer snippets leading to improved performance for informational tasks and shorter snippets for navigational tasks ."}