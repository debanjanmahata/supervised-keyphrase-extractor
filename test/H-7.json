{"abstract": "A content-based personalized recommendation system learns user specific profiles from user feedback so that it can deliver information tailored to each individual user 's interest .A system serving millions of users can learn a better user profile for a new user , or a user with little feedback , by borrowing information from other users through the use of a Bayesian hierarchical model .Learning the model parameters to optimize the joint data likelihood from millions of users is very computationally expensive .The commonly used EM algorithm converges very slowly due to the sparseness of the data in IR applications .This paper proposes a new fast learning technique to learn a large number of individual user profiles .The efficacy and efficiency of the proposed algorithm are justified by theory and demonstrated on actual user data from Netflix and MovieLens .", "id": "H-7", "conclusions": "Content-based user profile learning is an important problem and is the key to providing personal recommendations to a user , especially for recommending new items with a small number of ratings .The Bayesian hierarchical modeling approach is becoming an important user profile learning approach due to its theoretically justified ability to help one user through information transfer from the other users by way of hyperpriors .This paper examined the weakness of the popular EM based learning approach for Bayesian hierarchical linear models and proposed a better learning technique called Modified EM .We showed that the new technique is theoretically more computationally efficient than the standard EM algorithm .Evaluation on the MovieLens and Netflix data sets demonstrated the effectiveness of the new technique when the data is sparse , by which we mean the ratio of related user-feature pairs to unrelated pairs is small .Evaluation on the Reuters data set showed that the new technique performed similar to the standard EM algorithm when the sparseness condition does not hold .In general , it is better to use the new algorithm since it is as simple as standard EM , the performance is either better or similar to EM , and the computation complexity is lower at each iteration .It is worth mentioning that even if the original problem space is not sparse , sparseness can be created artificially when a recommendation system uses user-specific feature selection techniques to reduce the noise and user model complexity .The proposed technique can also be adapted to improve the learning in such a scenario .We also demonstrated that the proposed technique can learn half a million user profiles from 100 million ratings in a few hours with a single CPU .The research is important because scalability is a major concern for researchers when using the Bayesian hierarchical linear modeling approach to build a practical large scale system , even though the literature have demonstrated the effectiveness of the models in many applications .Our work is one major step on the road to make Bayesian hierarchical linear models more practical .The proposed new technique can be easily adapted to run on a cluster of machines , and thus further speed up the learning process to handle a larger scale system with hundreds of millions of users .The research has much potential to benefit people using EM algorithm on many other IR problems as well as machine learning problems .EM algorithm is a commonly used machine learning technique .It is used to find model parameters in many IR problems where the training data is very sparse .Although we are focusing on the Bayesian hierarchical linear models for recommendation and filtering , the new idea of using analytical solution instead of numerical solution for unrelated user-feature pairs at the M step could be adapted to many other problems .", "reader_keywords_stem": ["model", "content-base", "recommend system", "linear regress", "collabor filter", "paramet", "learn techniqu", "ir", "em algorithm", "classif", "rate"], "combined_keywords_stem": ["model", "content-base", "recommend system", "linear regress", "collabor filter", "paramet", "learn techniqu", "ir", "em algorithm", "classif", "rate", "recommend system", "inform filter", "person", "bayesian hierarch model"], "introduction": "Personalization is the future of the Web , and it has achieved great success in industrial applications .For example , online stores , such as Amazon and Netflix , provide customized recommendations for additional products or services based on a user 's history .Recent offerings such as My MSN , My Yahoo! , My Google , and Google News have attracted much attention due to their potential ability to infer a user 's interests from his/her history .One major personalization topic studied in the information retrieval community is content-based personal recommendation systems ' .These systems learn user-specific pro'Content based recommendation is also called adaptive filfiles from user feedback so that they can recommend information tailored to each individual user 's interest without requiring the user to make an explicit query .Learning the user profiles is the core problem for these systems .A user profile is usually a classifier that can identify whether a document is relevant to the user or not , or a regression model that tells how relevant a document is to the user .One major challenge of building a recommendation or personalization system is that the profile learned for a particular user is usually of low quality when the amount of data from that particular user is small .This is known as the `` cold start '' problem .This means that any new user must endure poor initial performance until sufficient feedback from that user is provided to learn a reliable user profile .There has been much research on improving classification accuracy when the amount of labeled training data is small .The semi-supervised learning approach combines unlabeled and labeled data together to achieve this goal 26 .Another approach is using domain knowledge .Researchers have modified different learning algorithms , such as Na \u00a8 \u0131veBayes 17 , logistic regression 7 , and SVMs 22 , to integrate domain knowledge into a text classifier .The third approach is borrowing training data from other resources 5 7 .The effectiveness of these different approaches is mixed , due to how well the underlying model assumption fits the data .One well-received approach to improve recommendation system performance for a particular user is borrowing information from other users through a Bayesian hierarchical modeling approach .Several researchers have demonstrated that this approach effectively trades off between shared and user-specific information , thus alleviating poor initial performance for each user 27 25 .In order to learn a Bayesian hierarchical model , the system usually tries to find the most likely model parameters for the given data .A mature recommendation system usually works for millions of users .It is well known that learning the optimal parameters of a Bayesian hierarchical model is computationally expensive when there are thousands or millions of users .The EM algorithm is a commonly used technique for parameter learning due to its simplicity and convergence guarantee .However , a content based recommendation system often handles documents in a very high dimensional space , in which each document is represented by a very sparse vector .With careful analysis of the EM algorithm in this scenario Section 4 , we find that the EM tering , or item-based collaborative filtering .In this paper , the words `` filtering '' and `` recommendation '' are used interchangeably .algorithm converges very slowly due to the sparseness of the input variables .We also find that updating the model parameter at each EM iteration is also expensive with computational complexity of O MK , where M is the number of users and K is the number of dimensions .This paper modifies the standard EM algorithm to create an improved learning algorithm , which we call the `` Modified EM algorithm . ''The basic idea is that instead of calculating the numerical solution for all the user profile parameters , we derive the analytical solution of the parameters for some feature dimensions , and at the M step use the analytical solution instead of the numerical solution estimated at E step for those parameters .This greatly reduces the computation at a single EM iteration , and also has the benefit of increasing the convergence speed of the learning algorithm .The proposed technique is not only well supported by theory , but also by experimental results .The organization of the remaining parts of this paper is as follows : Section 3 describes the Bayesian hierarchical linear regression modeling framework used for content-based recommendations .Section 4 describes how to learn the model parameters using the standard EM algorithm , along with using the new technique proposed in this paper .The experimental setting and results used to validate the proposed learning technique are reported in Sections 5 and 6 .Section 7 summarizes and offers concluding remarks .", "title": "Efficient Bayesian Hierarchical User Modeling for Recommendation Systems", "method": "Assume there are M users in the system .The task of the system is to recommend documents that are relevant to each user .For each user , the system learns a user model from the user 's history .In the rest of this paper , we will use the following notations to represent the variables in the system .m = 1 , 2 , ... , M : The index for each individual user .M is the total number of users .wm : The user model parameter associated with user m. wm is a K dimensional vector .j = 1 , 2 , ... , Jm : The index for a set of data for user m. Jm is the number of training data for user m. Dm = xm , j , ym , j : A set of data associated with user m. xm , j is a K dimensional vector that represents the mth user 's jth training document .2 ym , j is a scalar that represents the label of document xm , j.The Bayesian hierarchical modeling approach has been widely used in real-world information retrieval applications .Generalized Bayesian hierarchical linear models , one of the simplest Bayesian hierarchical models , are commonly used and have achieved good performance on collaborative filtering 25 and content-based adaptive filtering 27 tasks .Figure 1 shows the graphical representation of a Bayesian hierarchical model .In this graph , each user model is represented by a random vector wm. We assume a user model is sampled randomly from a prior distribution P w | 4 .The system can predict the user label y of a document x given an estimation of wm or wm 's distribution using a function y = f x , w .The model is called generalized Bayesian hierarchical linear model when y = f wT x is any generalized linear model such as logistic regression , SVM , and linear regression .To reliably estimate the user model wm , the system can borrow information from other users through the prior 4 = \u00b5 , \u03a3 .Now we look at one commonly used model where y = wT x + e , where e \u223c N 0 , \u03c322 is a random noise 25 27 .Assume that each user model wm is an independent draw from a population distribution P w | 4 , which is governed by some unknown hyperparameter 4 .Let the prior distribution of user model w be a Gaussian distribution with parameter 4 = \u00b5 , \u03a3 , which is the commonly used prior for linear models .\u00b5 = \u00b51 , \u00b52 , ... , \u00b5K is a K dimensional vector that represents the mean of the Gaussian distribution , and \u03a3 is the covariance matrix of the Gaussian .Usually , a Normal distribution N 0 , aI and an Inverse Wishart distribution P \u03a3 \u221d | \u03a3 | \u2212 2 b exp \u2212 1model the prior distribution of \u00b5 and \u03a3 respectively .I is the K dimensional identity matrix , and a , b , and c are real numbers .With these settings , we have the following model for the system :in the hierarchical model .The rating , y , for a document , x , is conditioned on the document and the user model , wm , associated with the user m. Users share information about their models through the prior , 4 = \u00b5 , \u03a3 .Let \u03b8 = 4 , w1 , w2 , ... , wM represent the parameters of this system that needs to be estimated .The joint likelihood for all the variables in the probabilistic model , which includes the data and the parameters , is :For simplicity , we assume a , b , c , and \u03c32 are provided to the system .If the prior 4 is known , finding the optimal wm is straightforward : it is a simple linear regression .Therefore , we will focus on estimating 4 .The maximum a priori solution of 4 is given byFinding the optimal solution for the above problem is challenging , since we need to integrate over all w = w1 , w2 , ... , wM , which are unobserved hidden variables .In Equation 5 , 4 is the parameter needs to be estimated , and the result depends on unobserved latent variables w .This kind of optimization problem is usually solved by the EM algorithm .Applying EM to the above problem , the set of user models w are the unobservable hidden variables and we have :Based on the derivation of the EM formulas presented in 24 , we have the following Expectation-Maximization steps for finding the optimal hyperparameters .For space considerations , we omit the derivation in this paper since it is not the focus of our work .E step : For each user m , estimate the user model distribution P wm | Dm , 4 = N wm ; \u00af wm , \u03a32m based on the current estimation of the prior 4 = \u00b5 , \u03a32 .M step : Optimize the prior 4 = \u00b5 , \u03a32 based on the estimation from the last E step .Many machine learning driven IR systems use a point estimate of the parameters at different stages in the system .However , we are estimating the posterior distribution of the variables at the E step .This avoids overfitting wm to a particular user 's data , which may be small and noisy .A detailed discussion about this subject appears in 10 .Although the EM algorithm is widely studied and used in machine learning applications , using the above EM process to solve Bayesian hierarchical linear models in large-scale information retrieval systems is still too computationally expensive .In this section , we describe why the learning rate of the EM algorithm is slow in our application and introduce a new technique to make the learning of the Bayesian hierarchical linear model scalable .The derivation of the new learning algorithm will be based on the EM algorithm described in the previous section .First , the covariance matrices \u03a32 , \u03a32m are usually too large to be computationally feasible .For simplicity , and as a common practice in IR , we do not model the correlation between features .Thus we approximate these matrices with K dimensional diagonal matrices .In the rest of the paper , we use these symbols to represent their diagonal approximations :Secondly , and most importantly , the input space is very sparse and there are many dimensions that are not `` related '' to a particular user in a real IR application .For example , let us consider a movie recommendation system , with the input variable x representing a particular movie .For the jth movie that the user m has seen , let xm , j , k = 1 if the director of the movie is `` Jean-Pierre Jeunet '' indexed by k .Here we assume that whether or not that this director directed a specific movie is represented by the kth dimension .If the user m has never seen a movie directed by `` Jean-Pierre Jeunet '' , then the corresponding dimension is always zero xm , j , k = 0 for all j .One major drawback of the EM algorithm is that the imwho have never encountered this feature i.e. E portance of a feature , \u00b5k , may be greatly dominated by users j xm , j , k = 0 at the M step Equation 8 .Assume that 100 out of 1 million users have viewed the movie directed by `` Jean-Pierre Jeunet '' , and that the viewers have rated all of his movies as `` excellent '' .Intuitively , he is a good director and the weight for him \u00b5k should be high .Before the EM iteration , the initial value of \u00b5 is usually set to 0 .Since the other 999,900 users have not seen this movie , their corresponding weights w1 , k , w2 , k , ... , wm , k. .., w999900 , k for that director would be very small initially .Thus the corresponding weight of the director in the prior \u00b5k at the first M step would be very low , and the variance \u03c3m , k will be large Equations 8 and 7 .It is undesirable that users who have never seen any movie produced by the director influence the importance of the director so much .This makes the convergence of the standard EM algorithm very slow .Now let 's look at whether we can improve the learning speed of the algorithm .Without a loss of generality , let us assume that the kth dimension of the input variable x is not related to a particular user m. By which we mean , xm , j , k = 0 for all j = 1 , ... , Jm .It is straightforward to prove that the kth row and kth column of Sxx , m are completely filled with zeros , and that the kth dimension of Sxy , m is zeroed as well .Thus the corresponding kth dimension of the user model 's mean , \u00af wm , should be equal to that of the prior : \u00af wm , k = \u00b5k , with the corresponding covariance of \u03c3m , k = \u03c3k .At the M step , the standard EM algorithm uses the numerical solution of the distribution P wm | Dm , 4 estimated at E step Equation 8 and Equation 7 .However , the numerical solutions are very unreliable for \u00af wm , k and \u03c3m , k when the kth dimension is not related to the mth user .A better approach is using the analytical solutions \u00af wm , k = \u00b5k , and \u03c3m , k = \u03c3k for the unrelated m , k pairs , along with the numerical solution estimated at E step for the other m , k pairs .Thus we get the following new EM-like algorithm : Modified E step : For each user m , estimate the user model distribution P wm | Dm , 4 = N wm ; \u00af wm , \u03a32m based on the current estimation of \u03c32 , \u00b5 , \u03a32 .Modified M Step Optimize the prior 4 = \u00b5 , \u03a32 based on the estimation from the last E step for related userfeature pairs .The M step implicitly uses the analytical solution for unrelated user-feature pairs .where Mk is the number of users that are related to feature k We only estimate the diagonal of \u03a32m and \u03a3 since we are using the diagonal approximation of the covariance matrices .To estimate \u00af wm , we only need to calculate the numerical solutions for dimensions that are related to user m. To estimate \u03c32k and \u00b5k , we only sum over users that are related to the kth feature .There are two major benefits of the new algorithm .First , because only the related m , k pairs are needed at the modified M step , the computational complexity in a single EM iteration is much smaller when the data is sparse , and many of m , k pairs are unrelated .Second , the parameters estimated at the modified M step Equations 12 13 are more accurate than the standard M step described in Section 4.1 because the exact analytical solutions \u00af wm , k = \u00b5k and \u03c3m , k = \u03c3k for the unrelated m , k pairs were used in the new algorithm instead of an approximate solution as in the standard algorithm .To evaluate the proposed technique , we used the following three major data sets Table 1 : MovieLens Data : This data set was created by combining the relevance judgments from the MovieLens 9 data set with documents from the Internet Movie Database IMDB .MovieLens allows users to rank how much he/she enjoyed a specific movie on a scale from 1 to 5 .This `` likeability '' rating was used as a measurement of how relevant the document representing the corresponding movie is to the user .We considered documents with likeability scores of 4 or 5 as relevant , and documents with a score of 1 to 3 as irrelevant to the user .MovieLens provided relevance judgments on 3,057 documents from 6,040 separate users .On average , each user rated 151 movies , of these 87 were judged to be relevant .The average score for a document was 3.58 .Documents representing each movie were constructed from the portion of the IMDB database that is available for public download 13 .Based on this database , we created one document per movie that contained the relevant information about it e.g. directors , actors , etc. .ber of rating for a simulated user is the number of documents relevant to the corresponding topic .Netflix Data : This data set was constructed by combining documents about movies crawled from the web with a set of actual movie rental customer relevance judgments from Netflix 19 .Netflix publicly provides the relevance judgments of 480,189 anonymous customers .There are around 100 million rating on a scale of 1 to 5 for 17,770 documents .Similar to MovieLens , we considered documents with likeability scores of 4 or 5 as relevant .This number was reduced to 1000 customers through random sampling .The average customer on the reduced data set provided 127 judgments , with 70 being deemed relevant .The average score for documents is 3.55 .Reuters Data : This is the Reuters Corpus , Volume 1 .It covers 810,000 Reuters English language news stories from August 20 , 1996 to August 19 , 1997 .Only the first 100,000 news were used in our experiments .The Reuters corpus comes with a topic hierarchy .Each document is assigned to one of several locations on the hierarchical tree .The first level of the tree contains four topics , denoted as C , E , M , and G. For the experiments in this paper , the tree was cut at level 1 to create four smaller trees , each of which corresponds to one smaller data set : Reuters-E Reuters-C , ReutersM and Reuters-G .For each small data set , we created several profiles , one profile for each node in a sub-tree , to simulate multiple users , each with a related , yet separate definition of relevance .All the user profiles on a sub-tree are supposed to share the same prior model distribution .Since this corpus explicitly indicates only the relevant documents for a topic user , all other documents are considered irrelevant .We designed the experiments to answer the following three questions :To answer the first question , we compared the Bayesian hierarchical models with commonly used Norm-2 regularized linear regression models .In fact , the commonly used approach is equivalent to the model learned at the end of the first EM iteration .To answer the second question , we compared the proposed new algorithm with the standard EM algorithm to see whether the new learning algorithm is better .To answer the third question , we tested the efficiency of the new algorithm on the entire Netflix data set where about half a million user models need to be learned together .For the MovieLens and Netflix data sets , algorithm effectiveness was measured by mean square error , while on the Reuters data set classification error was used because it was more informative .We first evaluated the performance on each individual user , and then estimated the macro average over all users .Statistical tests t-tests were carried out to see whether the results are significant .For the experiments on the MovieLens and Netflix data sets , we used a random sample of 90 % of each user for training , and the rest for testing .On Reuters ' data set , because there are too many relevant documents for each topic in the corpus , we used a random sample of 10 % of each topic for training , and 10 % of the remaining documents for testing .For all runs , we set a , b , c , \u03a3E = 0.1 , 10 , 0.1 , 1 manually .", "evaluation": "Figure 2 , Figure 3 , and Figure 4 show that on all data sets , the Bayesian hierarchical modeling approach has a statistical significant improvement over the regularized linear regression model , which is equivalent to the Bayesian hierarchical models learned at the first iteration .Further analysis shows a negative correlation between the number of training data for a user and the improvement the system gets .This suggests that the borrowing information from other users has more significant improvements for users with less training data , which is as expected .However , the strength of the correlation differs over data sets , and the amount of training data is not the only characteristics that will influence the final performance .Figure 2 and Figure 3 show that the proposed new algorithm works better than the standard EM algorithm on the Netflix and MovieLens data sets .This is not surprising since the number of related feature-users pairs is much smaller than the number of unrelated feature-user pairs on these two data sets , and thus the proposed new algorithm is expected to work better .Figure 4 shows that the two algorithms work similarly on the Reuters-E data set .The accuracy of the new algorithm is similar to that of the standard EM algorithm at each iteration .The general patterns are very similar on other Reuters ' subsets .Further analysis shows that only 58 % of the user-feature pairs are unrelated on this data set .Since the number of unrelated user-feature pairs is not extremely large , the sparseness is not a serious problem on the Reuters data set .Thus the two learning algorithms perform similarly .The results suggest that only on a corpus where the number of unrelated user-feature pairs is much larger than the number of related pairs , such as on the Netflix data set , the proposed technique will get a significant improvement over standard EM .However , the experiments also show that when the assumption does not hold , the new algorithm does not hurt performance .Although the proposed technique is faster than standardEM , can it really learn millions of user models quickly ?Our results show that the modified EM algorithm converges quickly , and 2 3 modified EM iterations would result in a reliable estimation .We evaluated the algorithm on the whole Netflix data set 480,189 users , 159,836 features , and 100 million ratings running on a single CPU PC 2GB memory , P4 3GHz .The system finished one modified EM iteration in about 4 hours .This demonstrates that the proposed technique can efficiently handle large-scale system like Netflix .", "author_keywords_stem": ["recommend system", "inform filter", "person", "em algorithm", "bayesian hierarch model"], "related work": "Providing personalized recommendations to users has been identified as a very important problem in the IR community since the 1970 's .The approaches that have been used to solve this problem can be roughly classified into two major categories : content based filtering versus collaborative filtering .Content-based filtering studies the scenario where a recommendation system monitors a document stream and pushes documents that match a user profile to the corresponding user .The user may read the delivered documents and provide explicit relevance feedback , which the filtering system then uses to update the user 's profile using relevance feedback retrieval models e.g. Boolean models , vector space models , traditional probabilistic models 20 , inference networks 3 and language models 6 or machine learning algorithms e.g. Support Vector Machines SVM , K nearest neighbors K-NN clustering , neural networks , logistic regression , or Winnow 16 4 23 .Collaborative filtering goes beyond merely using document content to recommend items to a user by leveraging information from other users with similar tastes and preferences in the past .Memorybased heuristics and model based approaches have been used in collaborative filtering task 15 8 2 14 12 11 .This paper contributes to the content-based recommendation research by improving the efficiency and effectiveness of Bayesian hierarchical linear models , which have a strong theoretical basis and good empirical performance on recommendation tasks 27 25 .This paper does not intend to compare content-based filtering with collaborative filtering or claim which one is a better .We think each complements the other , and that content-based filtering is extremely useful for handling new documents/items with little or no user feedback .Similar to some other researchers 18 1 21 , we found that a recommendation system will be more effective when both techniques are combined .However , this is beyond the scope of this paper and thus not discussed here ."}