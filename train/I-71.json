{"abstract": "Ontology matching is currently a key technology to achieve the semantic alignment of ontological entities used by knowledge-based applications , and therefore to enable their interoperability in distributed environments such as multiagent systems .Most ontology matching mechanisms , however , assume matching prior integration and rely on semantics that has been coded a priori in concept hierarchies or external sources .In this paper , we present a formal model for a semantic alignment procedure that incrementally aligns differing conceptualisations of two or more agents relative to their respective perception of the environment or domain they are acting in .It hence makes the situation in which the alignment occurs explicit in the model .We resort to Channel Theory to carry out the formalisation .", "id": "I-71", "reader_keywords_stem": ["ontolog", "multi-agent system", "feder databas", "semant web", "knowledg-base system", "disjoint union", "sum infomorph", "constraint", "inform-channel refin", "distribut logic"], "reader_keywords": ["ontology", "multi-agent system", "federated database", "semantic web", "knowledge-based system", "disjoint union", "sum infomorphism", "constraint", "information-channel refinement", "distributed logic"], "introduction": "An ontology is commonly defined as a specification of the conceptualisation of a particular domain .It fixes the vocabulary used by knowledge engineers to denote concepts and their relations , and it constrains the interpretation of this vocabulary to the meaning originally intended by knowledgeengineers .As such , ontologies have been widely adopted as a key technology that may favour knowledge sharing in distributed environments , such as multi-agent systems , federated databases , or the Semantic Web .But the proliferation of many diverse ontologies caused by different conceptualisations of even the same domain and their subsequent specification using varying terminology has highlighted the need of ontology matching techniques that are capable of computing semantic relationships between entities of separately engineered ontologies .5 , 11 Until recently , most ontology matching mechanisms developed so far have taken a classical functional approach to the semantic heterogeneity problem , in which ontology matching is seen as a process taking two or more ontologies as input and producing a semantic alignment of ontological entities as output 3 .Furthermore , matching often has been carried out at design-time , before integrating knowledge-based systems or making them interoperate .This might have been successful for clearly delimited and stable domains and for closed distributed systems , but it is untenable and even undesirable for the kind of applications that are currently deployed in open systems .Multi-agent communication , peer-to-peer information sharing , and webservice composition are all of a decentralised , dynamic , and open-ended nature , and they require ontology matching to be locally performed during run-time .In addition , in many situations peer ontologies are not even open for inspection e.g. , when they are based on commercially confidential information .Certainly , there exist efforts to efficiently match ontological entities at run-time , taking only those ontology fragment that are necessary for the task at hand 10 , 13 , 9 , 8 .Nevertheless , the techniques used by these systems to establish the semantic relationships between ontological entities even though applied at run-time still exploit a priori defined concept taxonomies as they are represented in the graph-based structures of the ontologies to be matched , use previously existing external sources such as thesauri e.g. , WordNet and upper-level ontologies e.g. , CyC or SUMO , or resort to additional background knowledge repositories or shared instances .We claim that semantic alignment of ontological terminology is ultimately relative to the particular situation in which the alignment is carried out , and that this situation should be made explicit and brought into the alignment mechanism .Even two agents with identical conceptualisation capabilities , and using exactly the same vocabulary to specify their respective conceptualisations may fail to interoperatein a concrete situation because of their differing perception of the domain .Imagine a situation in which two agents are facing each other in front of a checker board .Agent A1 may conceptualise a figure on the board as situated on the left margin of the board , while agent A2 may conceptualise the same figure as situated on the right .Although the conceptualisation of ` left ' and ` right ' is done in exactly the same manner by both agents , and even if both use the terms left and right in their communication , they still will need to align their respective vocabularies if they want to successfully communicate to each other actions that change the position of figures on the checker board .Their semantic alignment , however , will only be valid in the scope of their interaction within this particular situation or environment .The same agents situated differently may produce a different alignment .This scenario is reminiscent to those in which a group of distributed agents adapt to form an ontology and a shared lexicon in an emergent , bottom-up manner , with only local interactions and no central control authority 12 .This sort of self-organised emergence of shared meaning is namely ultimately grounded on the physical interaction of agents with the environment .In this paper , however , we address the case in which agents are already endowed with a top-down engineered ontology it can even be the same one , which they do not adapt or refine , but for which they want to find the semantic relationships with separate ontologies of other agents on the grounds of their communication within a specific situation .In particular , we provide a formal model that formalises situated semantic alignment as a sequence of information-channel refinements in the sense of Barwise and Seligman 's theory of information flow 1 .This theory is particularly useful for our endeavour because it models the flow of information occurring in distributed systems due to the particular situations or tokens that carry information .Analogously , the semantic alignment that will allow information to flow ultimately will be carried by the particular situation agents are acting in .We shall therefore consider a scenario with two or more agents situated in an environment .Each agent will have its own viewpoint of the environment so that , if the environment is in a concrete state , both agents may have different perceptions of this state .Because of these differences there may be a mismatch in the meaning of the syntactic entities by which agents describe their perceptions and which constitute the agents ' respective ontologies .We state that these syntactic entities can be related according to the intrinsic semantics provided by the existing relationship between the agents ' viewpoint of the environment .The existence of this relationship is precisely justified by the fact that the agents are situated and observe the same environment .In Section 2 we describe our formal model for Situated Semantic Alignment SSA .First , in Section 2.1 we associate a channel to the scenario under consideration and show how the distributed logic generated by this channel provides the logical relationships between the agents ' viewpoints of the environment .Second , in Section 2.2 we present a method by which agents obtain approximations of this distributed logic .These approximations gradually become more reliable as the method is applied .In Section 3 we report on an application of our method .Conclusions and further work are analyzed in Section 4 .Finally , an appendix summarizes the terms and theorems of Channel theory used along the paper .We do not assume any knowledge of Channel Theory ; we restate basic definitions and theorems in the appendix , but any detailed exposition of the theory is outside the scope of this paper .", "title": "A Formal Model for Situated Semantic Alignment", "combined_keywords": ["ontology", "multi-agent system", "federated database", "semantic web", "knowledge-based system", "disjoint union", "sum infomorphism", "constraint", "information-channel refinement", "distributed logic", "semantic alignment", "distribute logic", "channel refinement"], "author_keywords": ["semantic alignment", "distribute logic", "channel refinement"], "method": "Consider a scenario with two agents A1 and A2 situated in an environment E the generalization to any numerable set of agents is straightforward .We associate a numerable set S of states to E and , at any given instant , we suppose E to be in one of these states .We further assume that each agent is able to observe the environment and has its own perception of it .This ability is faithfully captured by a surjective function seei : S + Pi , where i E 11 , 21 , and typically see1 and see2 are different .According to Channel Theory , information is only viable where there is a systematic way of classifying some range of things as being this way or that , in other words , where there is a classification see appendix A .So in order to be within the framework of Channel Theory , we must associate classifications to the components of our system .For each i E 11 , 21 , we consider a classification Ai that models Ai 's viewpoint of E. First , tok Ai is composed of Ai 's perceptions of E states , that is , tok Ai = Pi .Second , typ Ai contains the syntactic entities by which Ai describes its perceptions , the ones constituting the ontology of Ai .Finally , = Ai synthesizes how Ai relates its perceptions with these syntactic entities .Now , with the aim of associating environment E with a classification E we choose the power classification of S as E , which is the classification whose set of types is equal to 2S , whose tokens are the elements of S , and for which a token e is of type \u03b5 if e E \u03b5 .The reason for taking the power classification is because there are no syntactic entities that may play the role of types for E since , in general , there is no global conceptualisation of the environment .However , the set of types of the power classification includes all possible token configurations potentially described by types .Thus tok E = S , typ E = 2S and e = E \u03b5 if and only if e E \u03b5 .The notion of channel see appendix A is fundamental in Barwise and Seligman 's theory .The information flow among the components of a distributed system is modelled in terms of a channel and the relationships among these components are expressed via infomorphisms see appendix A which provide a way of moving information between them .The information flow of the scenario under consideration is accurately described by channel E = 1fi : Ai + Eb \u2208 1,2 defined as follows :where i E 11 , 21 .Definition of \u02c7fi seems natural while \u02c6fi is defined in such a way that the fundamental property of the infomorphisms is fulfilled :E explains the information flow of our scenario by virtue of agents A1 and A2 being situated and perceiving the same environment E .We want to obtain meaningful relations among agents ' syntactic entities , that is , agents ' types .We state that meaningfulness must be in accord with E .The sum operation see appendix A gives us a way of putting the two agents ' classifications of channel E together into a single classification , namely A1 + A2 , and also the two infomorphisms together into a single infomorphism , f1 + f2 : A1 + A2 + E. A1 + A2 assembles agents ' classifications in a very coarse way .tok A1 + A2 is the cartesian product of tok A1 and tok A2 , that is , tok A1 + A2 = p1 , p2 | pi \u2208 Pi , so a token of A1 + A2 is a pair of agents ' perceptions with no restrictions .typ A1 + A2 is the disjoint union of typ A1 and typ A2 , and p1 , p2 is of type i , \u03b1 if pi is of type \u03b1 .We attach importance to take the disjoint union because A1 and A2 could use identical types with the purpose of describing their respective perceptions of E. Classification A1 + A2 seems to be the natural place in which to search for relations among agents ' types .Now , Channel Theory provides a way to make all these relations explicit in a logical fashion by means of theories and local logics see appendix A .The theory generated by the sum classification , Th A1 + A2 , and hence its logic generated , Log A1 + A2 , involve all those constraints among agents ' types valid according to A1 + A2 .Notice however that these constraints are obvious .As we stated above , meaningfulness must be in accord with channel E. Classifications A1 + A2 and E are connected via the sum infomorphism , f = f1 + f2 , where :Meaningful constraints among agents ' types are in accord with channel E because they are computed making use of f as we expound below .As important as the notion of channel is the concept of distributed logic see appendix A .Given a channel C and a logic 2 on its core , DLogC 2 represents the reasoning about relations among the components of C justified by 2 .If 2 = Log C , the distributed logic , we denoted by Log C , captures in a logical fashion the information flow inherent in the channel .In our case , Log E explains the relationship between the agents ' viewpoints of the environment in a logical fashion .On the one hand , constraints of Th Log E are defined by :where \u0393 , \u0394 \u2286 typ A1 + A2 .On the other hand , the set of normal tokens , NLog E , is equal to the range of function \u02c7f :Therefore , a normal token is a pair of agents ' perceptions that are restricted by coming from the same environment state unlike A1 + A2 tokens .All constraints of Th Log E are satisfied by all normal tokens because of being a logic .In this particular case , this condition is also sufficient the proof is straightforward ; as alternative to 1 we have :where \u0393 , \u0394 \u2286 typ A1 + A2 .Log E is the logic of SSA .Th Log E comprises the most meaningful constraints among agents ' types in accord with channel E .In other words , the logic of SSA contains and also justifies the most meaningful relations among those syntactic entities that agents use in order to describe their own environment perceptions .necessarily sound because although Log E is sound , f\u02c7 is Log E is complete since Log E is complete but it is not not surjective in general see appendix B .If Log E is also sound then Log E = Log A1 + A2 see appendix B .That means there is no significant relation between agents ' points of view of the environment according to E .It is just the fact that Log E is unsound what allows a significant relation between the agents ' viewpoints .This relation is expressed at the type level in terms of constraints by Th Log E and at the token level by NLog E .We have dubbed Log E the logic of SSA .Th Log E comprehends the most meaningful constraints among agents ' types according to E .The problem is that neither agent can make use of this theory because they do not know E completely .In this section , we present a method by which agents obtain approximations to Th Log E .We also prove these approximations gradually become more reliable as the method is applied .Agents can obtain approximations to Th Log E through communication .A1 and A2 communicate by exchanging information about their perceptions of environment states .This information is expressed in terms of their own classification relations .Specifically , if E is in a concrete state e , we assume that agents can convey to each other which types are satisfied by their respective perceptions of e and which are not .This exchange generates a channel C = fi : Ai +C i \u2208 1,2 and Th Log C contains the constraints among agents ' types justified by the fact that agents have observed e. Now , if E turns to another state e ~ and agents proceed as before , another channel C ~ = fi ~ : Ai \u2192 C ~ i \u2208 1,2 gives account of the new situation considering also the previous information .Th Log C ~ comprises the constraints among agents ' types justified by the fact that agents have observed e and e ~ .The significant point is that C ~ is a refinement of C see appendix A .Theorem 2.1 below ensures that the refined channel involves more reliable information .The communication supposedly ends when agents have observed all the environment states .Again this situation can be modeled by a channel , call it C \u2217 = fi \u2217 : Ai \u2192 C \u2217 i \u2208 1,2 .Theorem 2.2 states that Th Log C \u2217 = Th Log E .Theorem 2.1 and Theorem 2.2 assure that applying the method agents can obtain approximations to Th Log E gradually more reliable .\u02c6f \u0393 ~ c \u02c6f \u0394 .We proceed by reductio ad absurdum .Suppose c \u2208 tok C does not satisfy the sequent ~ \u02c6f \u0393 , \u02c6f \u0394 .Then c | = c \u02c6f \u03b3 for all \u03b3 \u2208 \u0393 and c | = c \u02c6f \u03b4 for all \u03b4 \u2208 \u0394 .Let us choose an arbitrary \u03b3 \u2208 \u0393 .We have thatConsequently , \u02c7r c | = c , \u02c6f ~ \u03b3 for all \u03b3 \u2208 \u0393 .Since \u02c6f ~ \u0394 then there exists \u03b4 \u2217 \u2208 \u0394 such that \u02c6f ~ \u03b4 \u2217 .A sequence of equivalences similar to the above one justifies c | = c \u02c6f \u03b4 \u2217 , contradicting that c is a counterexample to ~ \u02c6f \u0393 , \u02c6f \u0394 .Hence \u0393 ~ Log C \u0394 as we wanted to prove .Therefore , there exists c token in C such that ~ a1 , a2 = \u02c7f c .Then we have ai = \u02c7fi c = \u02c7fi ~ \u25e6 \u02c7r c = \u02c7fi ~ \u02c7r c , for i \u2208 1 , 2 .Hence ~ a1 , a2 = \u02c7f ~ \u02c7r c and ~ a1 , a2 \u2208 NLog C , .Consequently , NLog C , \u2287 NLog C which concludes the proof .REMARK 2.1 .Theorem 2.1 asserts that the more refined channel gives more reliable information .Even though its theory has less constraints , it has more normal tokens to which they apply .In the remainder of the section , we explicitly describe the process of communication and we conclude with the proof of Theorem 2.2 .Let us assume that typ Ai is finite for i \u2208 1 , 2 and S is infinite numerable , though the finite case can be treated in a similar form .We also choose an infinite numerable set of symbols cn | n \u2208 N 1 .We omit informorphisms superscripts when no confusion arises .Types are usually denoted by greek letters and tokens \u02c6f \u03b1 and Agents communication starts from the observation of E. Let us suppose that E is in state e1 \u2208 S = tok E .A1 's perception of e1 is f1 e1 and A2 's perception of e1 is f2 e1 .We take for granted that A1 can communicate A2 those types that are and are not satisfied by f1 e1 according to its classification A1 .So can A2 do .Since both typ A1 and typ A2 are finite , this process eventually finishes .After this communication a channel C1 = fi1 : Ai \u2192 C1 i = 1,2 arises see Figure 2 .On the one hand , C1 is defined by :On the other hand , fi1 , with i \u2208 1 , 2 , is defined by :Log C1 represents the reasoning about the first stage of communication .It is easy to prove that Th Log C1 = Th C1 .The significant point is that both agents know C1 as the result of the communication .Hence they can compute separately theory Th C1 = ~ typ C1 , ~ cl which contains the constraints among agents ' types justified by the fact that agents have observed e1 .Now , let us assume that E turns to a new state e2 .Agents can proceed as before , exchanging this time information about their perceptions of e2 .Another channel C2 = fi2 : Ai \u2192 C2 i \u2208 1,2 comes up .We define C2 so as to take also into account the information provided by the previous stage of communication .On the one hand , C2 is defined by :In the general situation , once the states e1 , e2 , ... , en \u2212 1 n \u2265 2 have been observed and a new state en appears , channel Cn = fin : Ai \u2192 Cn i \u2208 1,2 informs about agents communication up to that moment .Cn definition is similar to the previous ones and analogous remarks can be made see at the top of Figure 3 .Theory Th Log Cn = Th Cn = ~ typ Cn , ~ Cn ~ contains the constraints among agents ' types justified by the fact that agents have observed e1 , e2 , ... , en .agents to decide when to stop communicating should a good enough approximation have been reached for the purposes of their respective tasks .But the study of possible termination criteria is outside the scope of this paper and left for future work .From a theoretical point of view , however , we can consider the channel C \u2217 = fi \u2217 : Ai \u2192 C \u2217 i \u2208 1,2 which informs of the end of the communication after observing all environment states .On the one hand , C \u2217 is defined by :Theorem below constitutes the cornerstone of the model exposed in this paper .It ensures , together with Theorem 2.1 , that at each communication stage agents obtain a theory that approximates more closely to the theory generated by the logic of SSA .THEOREM 2.2 .The following statements hold :Remember we have assumed that S is infinite numerable .It is therefore unpractical to let communication finish when all environment states have been observed by A1 and A2 .At that point , the family of channels Cn n \u2208 N would inform of all the communication stages .It is therefore up to theIn the previous section we have described in great detail our formal model for SSA .However , we have not tackled the practical aspect of the model yet .In this section , we give a brushstroke of the pragmatic view of our approach .We study a very simple example and explain how agents can use those approximations of the logic of SSA they can obtain through communication .Let us reflect on a system consisting of robots located in a two-dimensional grid looking for packages with the aim of moving them to a certain destination Figure 4 .Robots can carry only one package at a time and they can not move through a package .Robots have a partial view of the domain and there exist two kinds of robots according to the visual field they have .Some robots are capable of observing the eight adjoining squares but others just observe the three squares they have in front see Figure 5 .We call them URDL shortened form of Up-Right-Down-Left and LCR abbreviation for Left-Center-Right robots respectively .Describing the environment states as well as the robots ' perception functions is rather tedious and even unnecessary .We assume the reader has all those descriptions in mind .All robots in the system must be able to solve package distribution problems cooperatively by communicating their intentions to each other .In order to communicate , agents send messages using some ontology .In our scenario , there coexist two ontologies , the UDRL and LCR ontologies .Both of them are very simple and are just confined to describe what robots observe .When a robot carrying a package finds another package obstructing its way , it can either go around it or , if there is another robot in its visual field , ask it for assistance .Let us suppose two URDL robots are in a situation like the one depicted in Figure 6 .Robot1 the one carrying a package decides to ask Robot2 for assistance and sends a request .This request is written below as a KQML message and it should be interpreted intuitively as : Robot2 , pick up the package located in gay `` Up '' square , knowing that you are located in gay `` Up-Right '' square .Robot2 understands the content of the request and it can use a rule represented by the following constraint :The above constraint should be interpreted intuitively as : if Robot2 is situated in Robot1 's `` Up-Right '' square , Robot1 is situated in Robot2 's `` Up-Left '' square and a package is located in Robot1 's `` Up '' square , then a package is located in Robot2 's `` Up '' square .Now , problems arise when a LCR robot and a URDL robot try to interoperate .See Figure 7 .Robot1 sends a request of the form :Robot2 does not understand the content of the request but they decide to begin a process of alignment corresponding with a channel C1 .Once finished , Robot2 searches in Th C1 for constraints similar to the expected one , that is , those of the form :where \u03bb E U , R , D , L , UR , DR , DL , UL .From these , only the following constraints are plausible according to C1 :If subsequently both robots adopting the same roles take part in a situation like the one depicted in Figure 8 , a new process of alignment corresponding with a channel C2 takes place .C2 also considers the previous information and hence refines C1 .The only constraint from the above ones that remains plausible according to C2 is :Notice that this constraint is an element of the theory of the distributed logic .Agents communicate in order to cooperate successfully and success is guaranteed using constrains of the distributed logic .In this paper we have exposed a formal model of semantic alignment as a sequence of information-channel refinements that are relative to the particular states of the environment in which two agents communicate and align their respective conceptualisations of these states .Before us , Kent 6 and Kalfoglou and Schorlemmer 4 , 10 have applied Channel Theory to formalise semantic alignment using also Barwise and Seligman 's insight to focus on tokens as the enablers of information flow .Their approach to semantic alignment , however , like most ontology matching mechanisms developed to date regardless of whether they follow a functional , design-time-based approach , or an interaction-based , runtime-based approach , still defines semantic alignment in terms of a priori design decisions such as the concept taxonomy of the ontologies or the external sources brought into the alignment process .Instead the model we have presented in this paper makes explicit the particular states of the environment in which agents are situated and are attempting to gradually align their ontological entities .In the future , our effort will focus on the practical side of the situated semantic alignment problem .We plan to further refine the model presented here e.g. , to include pragmatic issues such as termination criteria for the alignment process and to devise concrete ontology negotiation protocols based on this model that agents may be able to enact .The formal model exposed in this paper will constitute a solid base of future practical results .This work is supported under the UPIC project , sponsored by Spain 's Ministry of Education and Science under grant number TIN2004-07461-C02 02 and also under the OpenKnowledge Specific Targeted Research Project STREP , sponsored by the European Commission under contract number FP6-027253 .Marco Schorlemmer is supported by a Ram \u00b4 on y Cajal Research Fellowship from Spain 's Ministry of Education and Science , partially funded by the European Social Fund .Classification : is a tuple A = ~ tok A , typ A , | = A ~ where tok A is a set of tokens , typ A is a set of types and | = A is a binary relation between tok A and typ A .If a | = A \u03b1 then a is said to be of type \u03b1 .Infomorphism : f : A \u2192 B from classifications A to B is a contravariant pair of functions f = ~ \u02c6f , \u02c7f ~ , where f\u02c6 : typ A \u2192 typ B and f\u02c7 : tok B \u2192 tok A , satisfying the following fundamental property : \u02c7f b | = A \u03b1 iff b | = B for each token b \u2208 tok B and each type \u03b1 \u2208 typ A .Channel : consists of two infomorphisms C = fi : Ai \u2192 C i \u2208 1,2 with a common codomain C , called the core of C. C tokens are called connections and a connection c is said to connect tokens \u02c7f1 c and \u02c7f2 c .2 Sum : given classifications A and B , the sum of A and B , denoted by A + B , is the classification with tok A + B = tok A \u00d7 tok B = ~ a , b ~ | a \u2208 tok A and b \u2208 tok B , typ A + B = typ A ~ typ B = ~ i , \u03b3 ~ | i = 1 and \u03b3 \u2208 typ A or i = 2 and \u03b3 \u2208 typ B and relation | = A+B defined by : ~ a , b ~ | = A+B ~ 1 , \u03b1 ~ if a | = A \u03b1 ~ a , b ~ | = A+B ~ 2 , \u03b2 ~ if b | = B \u03b2 Given infomorphisms f : A \u2192 C and g : B \u2192 C , the sum f + g : A + B \u2192 C is defined on types by f \u02c6 + g ~ 1 , \u03b1 ~ = \u02c6f \u03b1 and f \u02c6 + g ~ 2 , \u03b2 ~ = \u02c6g \u03b2 , and on tokens by f \u02c7 + g c = ~ \u02c7f c , \u02c7g c ~ .Theory : given a set \u03a3 , a sequent of \u03a3 is a pair ~ \u0393 , \u0394 ~ of subsets of \u03a3 .A binary relation ~ between subsets of \u03a3 is called a consequence relation on \u03a3 .A theory is a pair T = ~ \u03a3 , ~ ~ where ~ is a consequence relation on \u03a3 .A sequent ~ \u0393 , \u0394 ~ of \u03a3 for which \u0393 ~ \u0394 is called a constraint of the theory T. T is regular if it satisfies :for all \u03b1 \u2208 \u03a3 and all \u0393 , \u0393 ~ , \u0394 , \u0394 ~ , Il \u2286 \u03a3 .3 Theory generated by a classification : let A be a classification .A token a \u2208 tok A satisfies a sequent ~ \u0393 , \u0394 ~ of typ A provided that if a is of every type in \u0393 then it is of some type in \u0394 .The theory generated by A , denoted by Th A , is the theory ~ typ A , ~ A ~ where \u0393 ~ A \u0394 if every token in A satisfies ~ \u0393 , \u0394 ~ .Local logic : is a tuple , E = ~ tok , E , typ , E , | = # , ~ # , N # ~ where :A local logic , E is sound if every token in Cla , E is normal , that is , N # = tok , E ., E is complete if every sequent of typ , E satisfied by every normal token is a constraint of Th , E .Local logic generated by a classification : given a classification A , the local logic generated by A , written Log A , is the local logic on A i.e. , Cla Log A = A , with Th Log A = Th A and such that all its tokens are normal , i.e. , NLog A = tok A .Inverse image : given an infomorphism f : A \u2192 B and a local logic , E on B , the inverse image of , E under f , denoted f \u2212 1 , E , is the local logic on A such that \u02c6f \u0394 and Nf \u2212 1 # = \u02c7f N # = a \u2208 tok A | a = \u02c7f b for some b \u2208 N # .Distributed logic : let C = fi : Ai \u2192 C i \u2208 1,2 be a channel and , E a local logic on its core C , the distributed logic of C generated by , E , written DLogC , E , is the inverse image of , E under the sum f1 + f2 .Refinement : let C = fi : Ai \u2192 C i \u2208 1,2 and C ~ = fi ~ : Ai \u2192 C ~ i \u2208 1,2 be two channels with the same component classifications A1 and A2 .A refinement infomorphism from C ~ to C is an infomorphism r : C ~ \u2192 C such that for each i \u2208 1 , 2 , fi = r \u25e6 fi ~ i.e. , \u02c6fi = r\u02c6 \u25e6 \u02c6fi ~ and \u02c7fi = \u02c7fi ~ \u25e6 \u02c7r .Channel C ~ is a refinement of C if there exists a refinement infomorphism r from C ~ to C.", "author_keywords_stem": ["semantic alignment", "distribute logic", "channel refinement"], "combined_keywords_stem": ["ontolog", "multi-agent system", "feder databas", "semant web", "knowledg-base system", "disjoint union", "sum infomorph", "constraint", "inform-channel refin", "distribut logic", "semant align", "distribut logic", "channel refin"]}