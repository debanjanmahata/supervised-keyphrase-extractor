{"reader_keywords": ["random graph", "pagerank", "ranking", "web graph", "link community", "web spam", "keyword stuffing", "link stuffing", "machine learning", "link analysis", "seed selection algorithm", "gaussian kernel smoothing", "equal voting ability", "group-to-group relation"], "reader_keywords_stem": ["random graph", "pagerank", "rank", "web graph", "link commun", "web spam", "keyword stuf", "link stuf", "machin learn", "link analysi", "seed select algorithm", "gaussian kernel smooth", "equal vote abil", "group-to-group relat"], "introduction": "While the PageRank algorithm 13 has proven to be very effective for ranking Web pages , inaccurate PageRank results are induced because of web page manipulations by people for commercial interests .The manipulation problem is also called the Web spam , which refers to hyperlinked pages on the World Wide Web that are created with the intention of misleading search engines 7 .It is reported that approximately 70 % of all pages in the .biz domain and about 35 % of the pages in the .us domain belong to the spam category 12 .The reason for the increasing amount of Web spam is explained in 12 : some web site operators try to influence the positioning of their pages within search results because of the large fraction of web traffic originating from searches and the high potential monetary value of this traffic .From the viewpoint of the Web site operators who want to increase the ranking value of a particular page for search engines , Keyword Stuffing and Link Stuffing are being used widely 7 , 12 .From the viewpoint of the search engine managers , the Web spam is very harmful to the users ' evaluations and thus their preference to choosing search engines because people believe that a good search engine should not return irrelevant or low-quality results .There are two methods being employed to combat the Web spam problem .Machine learning methods are employed to handle the keyword stuffing .To successfully apply machine learning methods , we need to dig out some useful textual features for Web pages , to mark part of the Web pages as either spam or non-spam , then to apply supervised learning techniques to mark other pages .For example , see 5 , 12 .Link analysis methods are also employed to handle the link stuffing problem .One example is the TrustRank 7 , a link-based method , in which the link structure is utilized so that human labelled trusted pages can propagate their trust scores trough their links .This paper focuses on the link-based method .The rest of the materials are organized as follows .In the next section , we give a brief literature review on various related ranking techniques .We establish the Heat Diffusion Model HDM on various cases in Section 3 , and propose DiffusionRank in Section 4 .In Section 5 , we describe the data sets that we worked on and the experimental results .Finally , we draw conclusions in Section 6 .", "title": "DiffusionRank : A Possible Penicillin for Web Spamming", "author_keywords_stem": ["random graph", "pagerank", "diffusionrank"], "abstract": "While the PageRank algorithm has proven to be very effective for ranking Web pages , the rank scores of Web pages can be manipulated .To handle the manipulation problem and to cast a new insight on the Web structure , we propose a ranking algorithm called DiffusionRank .DiffusionRank is motivated by the heat diffusion phenomena , which can be connected to Web ranking because the activities flow on the Web can be imagined as heat flow , the link from a page to another can be treated as the pipe of an air-conditioner , and heat flow can embody the structure of the underlying Web graph .Theoretically we show that DiffusionRank can serve as a generalization of PageRank when the heat diffusion coefficient y tends to infinity .In such a case 1 / y = 0 , DiffusionRank PageRank has low ability of anti-manipulation .When y = 0 , DiffusionRank obtains the highest ability of anti-manipulation , but in such a case , the web structure is completely ignored .Consequently , y is an interesting factor that can control the balance between the ability of preserving the original Web and the ability of reducing the effect of manipulation .It is found empirically that , when y = 1 , DiffusionRank has a Penicillin-like effect on the link manipulation .Moreover , DiffusionRank can be employed to find group-to-group relations on the Web , to divide the Web graph into several parts , and to find link communities .Experimental results show that the DiffusionRank algorithm achieves the above mentioned advantages as expected .", "id": "H-38", "combined_keywords_stem": ["random graph", "pagerank", "rank", "web graph", "link commun", "web spam", "keyword stuf", "link stuf", "machin learn", "link analysi", "seed select algorithm", "gaussian kernel smooth", "equal vote abil", "group-to-group relat", "diffusionrank"], "evaluation": "In this section , we show the experimental data , the methodology , the setting , and the results .Our input data consist of a toy graph , a middle-size realworld graph , and a large-size real-world graph .The toy graph is shown in Fig. 2 a .The graph below it shows node 1 is being manipulated by adding new nodes A , B , C , ...such that they all point to node 1 , and node 1 points to them all .The data of two real Web graph were obtained from the domain in our institute in October , 2004 .The total number of pages found are 18,542 in the middle-size graph , and 607,170 in the large-size graph respectively .The middle-size graph is a subgraph of the large-size graph , and they were obtained by the same crawler : one is recorded by the crawler in its earlier time , and the other is obtained when the crawler stopped .The algorithms we run include PageRank , TrustRank and DiffusionRank .All the rank values are multiplied by the number of nodes so that the sum of the rank values is equal to the number of nodes .By this normalization , we can compare the results on graphs with different sizes since the average rank value is one for any graph after such normalization .We will need value difference and pairwise order difference as comparison measures .Their definitions are listed as follows .Value Difference .The value difference between A = Ai ni = 1 and B = Bi ni = 1 is measured as Eni = 1 | Ai \u2212 Bi | .Pairwise Order Difference .The order difference between A and B is measured as the number of significant order differences between A and B .The pair A i , A j and B i , B j is considered as a significant order difference if one of the following cases happens : both A i > < A j +0.1 and B i < > A j ; both A i < > A j and B i > < A j + 0.1 .The experiments on the middle-size graph and the largesize graphs are conducted on the workstation , whose hardware model is Nix Dual Intel Xeon 2.2 GHz with 1GB RAM and a Linux Kernel 2.4.18-27smp RedHat7 .3 .In calculating DiffusionRank , we employ Eq .6 and the discrete approximation of Eq .4 for such graphs .The related tasks are implemented using C language .While in the toy graph , we employ the continuous diffusion kernel in Eq .4 and Eq .5 , and implement related tasks using Matlab .For nodes that have zero out-degree dangling nodes , we employ the method in the modified PageRank algorithm 8 , in which dangling nodes of are considered to have random links uniformly to each node .We set \u03b1 = \u03b1I = \u03b1B = 0.85 in all algorithms .We also set g to be the uniform distribution in both PageRank and DiffusionRank .For DiffusionRank , we set y = 1 .According to the discussions in Section 4.3 and Section 4.4 , we set the iteration number to be MB = 100 in DiffusionRank , and for accuracy consideration , the iteration number in all the algorithms is set to be 100 .We show that when y tends to infinity , the value differences between DiffusionRank and PageRank tend to zero .Fig. 2 b shows the approximation property of DiffusionRank , as proved in Theorem 1 , on the toy graph .The horizontal axis of Fig. 2 b marks the y value , and vertical axis corresponds to the value difference between DiffusionRank and PageRank .All the possible trusted sets with L = 1 are considered .For L > 1 , the results should be the linear combination of some of these curves because of the linearity of the solutions to heat equations .On other graphs , the situations are similar .In this section , we show how the rank values change as the intensity of manipulation increases .We measure the intensity of manipulation by the number of newly added points that point to the manipulated point .The horizontal axes of Fig. 3 stand for the numbers of newly added points , and vertical axes show the corresponding rank values of the manipulated nodes .To be clear , we consider all six situations .Every node in Fig. 2 a is manipulated respectively , and its corresponding values for PageRank , TrustRank TR , DiffusionRank DR are shown in the one of six sub-figures in Fig. 3 .The vertical axes show which node is being manipulated .In each sub-figure , the trusted sets are computed below .Since the inverse PageRank yields the results 1.26 , 0.85 , 1.31 , 1.36 , 0.51 , 0.71 .Let L = 1 .If the manipulated node is not 4 , then the trusted set is 4 , and otherwise 3 .We observe that in all the cases , rank values of the manipulated node for DiffusionRank grow slowest as the number of the newly added nodes increases .On the middle-size graph and the large-size graph , this conclusion is also true , see Fig. 4 .Note that , in Fig. 4 a , we choose four trusted sets L = 1 , on which we test DiffusionRank and TrustRank , the results are denoted by DiffusionRanki and TrustRanki i = 0 , 1 , 2 , 3 denotes the four trusted set ; in Fig. 4 b , we choose one trusted set L = 1 .Moreover , in both Fig. 4 a and Fig. 4 b , we show the results for DiffusionRank when we have no trusted set , and we trust all the pages before some of them are manipulated .We also test the order difference between the ranking order A before the page is manipulated and the ranking order PA after the page is manipulated .Because after manipulation , the number of pages changes , we only compare the common part of A and PA. .This experiment is used to test the stability of all these algorithms .The less the order difference , the stabler the algorithm , in the sense that only a smaller part of the order relations is affected by the manipulation .Figure 5 a shows that the order difference values change when we add new nodes that point to the manipulated node .We give several ry settings .We find that when ry = 1 , the least order difference is achieved by DiffusionRank .It is interesting to point out that as ry increases , the order difference will increase first ; after reaching a maximum value , it will decrease , and finally it tends to the PageRank results .We show this tendency in Fig. 5 b , in which we choose three different settings the number of manipulated nodes are 2,000 , 5,000 , and 10,000 respectively .From these figures , we can see that when ry < 2 , the values are less than those for PageRank , and that when ry > 20 , the difference between PageRank and DiffusionRank is very small .After these investigations , we find that in all the graphs we tested , DiffusionRank when ry = 1 is most robust to manipulation both in value difference and order difference .The trust set selection algorithm proposed in 7 is effective for both TrustRank and DiffusionRank .", "combined_keywords": ["random graph", "pagerank", "ranking", "web graph", "link community", "web spam", "keyword stuffing", "link stuffing", "machine learning", "link analysis", "seed selection algorithm", "gaussian kernel smoothing", "equal voting ability", "group-to-group relation", "diffusionrank"], "author_keywords": ["random graph", "pagerank", "diffusionrank"], "method": "The importance of a Web page is determined by either the textual content of pages or the hyperlink structure or both .As in previous work 7 , 13 , we focus on ranking methods solely determined by hyperlink structure of the Web graph .All the mentioned ranking algorithms are established on a graph .For our convenience , we first give some notations .Denote a static graph by G = V , E , where V = v1 , v2 , ... , vn , E = vi , vj | there is an edge from vi tovj .Ii and di denote the in-degree and the out-degree of page i respectively .The importance of a Web page is an inherently subjective matter , which depends on the reader 's interests , knowledge and attitudes 13 .However , the average importance of all readers can be considered as an objective matter .PageRank tries to find such average importance based on the Web link structure , which is considered to contain a large amount of statistical data .The Web is modelled by a directed graph G in the PageRank algorithms , and the rank or `` importance '' which point to it : xi = E xi for page vi \u2208 V is defined recursively in terms of pages j , i \u2208 E aijxj , where aij is assumed to be 1/dj if there is a link from j to i , and 0 otherwise .Or in matrix terms , x = Ax .When the concept of `` random jump '' is introduced , the matrix form is changed towhere \u03b1 is the probability of following the actual link from a page , 1 \u2212 \u03b1 is the probability of taking a `` random jump '' , and g is a stochastic vector , i.e. , 1T g = 1 .Typically , \u03b1 = 0.85 , and g = n1 1 is one of the standard settings , where 1 is the vector of all ones 6 , 13 .TrustRank 7 is composed of two parts .The first part is the seed selection algorithm , in which the inverse PageRank was proposed to help an expert of determining a good node .The second part is to utilize the biased PageRank , in which the stochastic distribution g is set to be shared by all the trusted pages found in the first part .Moreover , the initial input of x is also set to be g .The justification for the inverse PageRank and the solid experiments support its advantage in combating the Web spam .Although there are many variations of PageRank , e.g. , a family of link-based ranking algorithms in 2 , TrustRank is especially chosen for comparisons for three reasonss : 1 it is designed for combatting spamming ; 2 its fixed parameters make a comparison easy ; and 3 it has a strong theoretical relations with PageRank and DiffusionRank .In 17 , the idea of ranking on the data manifolds was proposed .The data points represented as vectors in Euclidean space are considered to be drawn from a manifold .From the data points on such a manifold , an undirected weighted graph is created , then the weight matrix is given by the Gaussian Kernel smoothing .While the manifold ranking algorithm achieves an impressive result on ranking images , the biased vector g and the parameter k in the general personalized PageRank in 17 are unknown in the Web graph setting ; therefore we do not include it in the comparisons .Heat diffusion is a physical phenomena .In a medium , heat always flow from position with high temperature to position with low temperature .Heat kernel is used to describe the amount of heat that one point receives from another point .Recently , the idea of heat kernel on a manifold is borrowed in applications such as dimension reduction 3 and classification 9 , 10 , 14 .In these work , the input data is considered to lie in a special structure .All the above topics are related to our work .The readers can find that our model is a generalization of PageRank in order to resist Web manipulation , that we inherit the first part of TrustRank , that we borrow the concept of ranking on the manifold to introduce our model , and that heat diffusion is a main scheme in this paper .Heat diffusion provides us with another perspective about how we can view the Web and also a way to calculate ranking values .In this paper , the Web pages are considered to be drawn from an unknown manifold , and the link structure forms a directed graph , which is considered as an approximation to the unknown manifold .The heat kernel established on the Web graph is considered as the representation of the relationship between Web pages .The temperature distribution after a fixed time period , induced by a special initial temperature distribution , is considered as the rank scores on the Web pages .Before establishing the proposed models , we first show our motivations .There are two points to explain that PageRank is susceptible to web spam .The input-independent feature of PageRank can be further explained as follows .P = 1 \u2212 \u03b1 g1T + \u03b1A is a positive stochastic matrix if g is set to be a positive stochastic vector the uniform distribution is one of such settings , and so the largest eigenvalue is 1 and no other eigenvalue whose absolute value is equal to 1 , which is guaranteed by the Perron Theorem 11 .Let y be the eigenvector corresponding to 1 , then we have Py = y. Let xk be the sequence generated from the iterations xk +1 = Pxk , and x0 is the initial input .If xk converges to x , then xk +1 = Pxk implies that x must satisfy Px = x .Since the only maximum eigenvalue is 1 , we have x = cy where c is a constant , and if both x and y are normalized by their sums , then c = 1 .The above discussions show that PageRank is independent of the initial input x0 .In our opinion , g and \u03b1 are objective parameters determined by the users ' behaviors and preferences .A , \u03b1 and g are the `` true '' web structure .While A is obtained by a crawler and the setting \u03b1 = 0.85 is accepted by the people , we think that g should be determined by a user behavior investigation , something like 1 .Without any prior knowledge , g has to be set as g = n1 1 .TrustRank model does not follow the `` true '' web structure by setting a biased g , but the effects of combatting spamming are achieved in 7 ; PageRank is on the contrary in some ways .We expect a ranking algorithm that has an effect of anti-manipulation as TrustRank while respecting the `` true '' web structure as PageRank .We observe that the heat diffusion model is a natural way to avoid the over-democratic and input-independent feature of PageRank .Since heat always flows from a position with higher temperatures to one with lower temperatures , points are not equal as some points are born with high temperatures while others are born with low temperatures .On the other hand , different initial temperature distributions will give rise to different temperature distributions after a fixed time period .Based on these considerations , we propose the novel DiffusionRank .This ranking algorithm is also motivated by the viewpoint for the Web structure .We view all the Web pages as points drawn from a highly complex geometric structure , like a manifold in a high dimensional space .On a manifold , heat can flow from one point to another through the underlying geometric structure in a given time period .Different geometric structures determine different heat diffusion behaviors , and conversely the diffusion behavior can reflect the geometric structure .More specifically , on the manifold , the heat flows from one point to another point , and in a given time period , if one point x receives a large amount of heat from another point y , we can say x and y are well connected , and thus x and y have a high similarity in the sense of a high mutual connection .We note that on a point with unit mass , the temperature and the heat of this point are equivalent , and these two terms are interchangeable in this paper .In the following , we first show the HDM on a manifold , which is the origin of HDM , but can not be employed to the World Wide Web directly , and so is considered as the ideal case .To connect the ideal case and the practical case , we then establish HDM on a graph as an intermediate case .To model the real world problem , we further build HDM on a random graph as a practical case .Finally we demonstrate the DiffusionRank which is derived from the HDM on a random graph .If the underlying manifold is known , the heat flow throughout a geometric manifold with initial conditions can be described by the following second order differential equation :at time t , and Af is the Laplace-Beltrami operator on a function f .The heat diffusion kernel Kt x , y is a special solution to the heat equation with a special initial condition a unit heat source at position y when there is no heat in other positions .Based on this , the heat kernel Kt x , y describes the heat distribution at time t diffusing from the initial unit heat source at position y , and thus describes the connectivity which is considered as a kind of similarity between x and y. However , it is very difficult to represent the World Wide Web as a regular geometry with a known dimension ; even the underlying is known , it is very difficult to find the heat kernel Kt x , y , which involves solving the heat equation with the delta function as the initial condition .This motivates us to investigate the heat flow on a graph .The graph is considered as an approximation to the underlying manifold , and so the heat flow on the graph is considered as an approximation to the heat flow on the manifold .On an undirected graph G , the edge vi , vj is considered as a pipe that connects nodes vi and vj .The value fi t describes the heat at node vi at time t , beginning from an initial distribution of heat given by fi 0 at time zero .f t f 0 denotes the vector consisting of fi t fi 0 .We construct our model as follows .Suppose , at time t , each node i receives M i , j , t , At amount of heat from its neighbor j during a period of At .The heat M i , j , t , At should be proportional to the time period At and the heat difference fj t fi t .Moreover , the heat flows from node j to node i through the pipe that connects nodes i and j. Based on this consideration , we assume that M i , j , t , At = y fj t fi t At .As a result , the heat difference at node i between time t + At and time t will be equal to the sum of the heat that it receives from all its neighbors .This is formulated aswhere E is the set of edges .To find a closed form solution to Eq .2 , we express it in a matrix form : f t + At f t / At = yHf t , where d v denotes the degree of the node v .In the limit At \u2192 0 , it becomes dtd f t = yHf t .Solving it , we obtain f t = e\u03b3tHf 0 , especially we haveThe above heat diffusion model must be modified to fit the situation where the links between Web pages are directed .On one Web page , when the page-maker creates a link a , b to another page b , he actually forces the energy flow , for example , people 's click-through activities , to that page , and so there is added energy imposed on the link .As a result , heat flows in a one-way manner , only from a to b , not from b to a. Based on such consideration , we modified the heat diffusion model on an undirected graph as follows .On a directed graph G , the pipe vi , vj is forced by added energy such that heat flows only from vi to vj .Suppose , at time t , each node vi receives RH = RH i , j , t , At amount of heat from vj during a period of At .We have three assumptions : 1 RH should be proportional to the time period At ; 2 RH should be proportional to the the heat at node vj ; and 3 RH is zero if there is no link from vj to vi .As a result , vi will receive Ej : vj , vi \u2208 E \u03c3j fj t At amount of heat from all its neighbors that points to it .On the other hand , node vi diffuses DH i , t , At amount of heat to its subsequent nodes .We assume that : 1 The heat DH i , t , At should be proportional to the time period At .2 The heat DH i , t , At should be proportional to the the heat at node vi .3 Each node has the same ability of diffusing heat .This fits the intuition that a Web surfer only has one choice to find the next page that he wants to browse .4 The heat DH i , t , At should be uniformly distributed to its subsequent nodes .The real situation is more complex than what we assume , but we have to make this simple assumption in order to make our model concise .As a result , node vi will diffuse yfi t At/di amount of heat to any of itssubsequent nodes , and each of its subsequent node should receive yfi t \u0394t / di amount of heat .Therefore \u03c3j = y/dj .To sum up , the heat difference at node vi between time t + \u0394t and time t will be equal to the sum of the heat that it receives , deducted by what it diffuses .This is formulated as fi t + \u0394t \u2212 fi t = \u2212 yfi t \u0394t + Ej : vj , vi \u2208 E y/djfj t \u0394t .Similarly , we obtainFor real world applications , we have to consider random edges .This can be seen in two viewpoints .The first one is that in Eq .1 , the Web graph is actually modelled as a random graph , there is an edge from node vi to node vj with a probability of 1 \u2212 \u03b1 gj see the item 1 \u2212 \u03b1 g1T , and that the Web graph is predicted by a random graph 15 , 16 .The second one is that the Web structure is a random graph in essence if we consider the content similarity between two pages , though this is not done in this paper .For these reasons , the model would become more flexible if we extend it to random graphs .The definition of a random graph is given below .The original definition of random graphs in 4 , is changed slightly to consider the situation of directed graphs .Note that every static graph can be considered as a special random graph in the sense that pij can only be 0 or 1 .On a random graph RG = V , P , where P = pij is the probability of the edge vi , vj exists .In such a random graph , the expected heat difference at node i between time t + \u0394t and time t will be equal to the sum of the expected heat that it receives from all its antecedents , deducted by the expected heat that it diffuses .Since the probability of the link vj , vi is pji , the expected heat flow from node j to node i should be multiplied by pji , and so we have fi t + \u0394t \u2212 fi t = \u2212 y fi t \u0394t + P j : vj , vi \u2208 E ypjifj t \u0394t / RD + vj , where RD + vi is the expected out-degree of node vi , it is defined as Ek pik .Similarly we haveWhen the graph is large , a direct computation of e\u03b3R is time-consuming , and we adopt its discrete approximation :The matrix I + \u03b3NR N in Eq .6 and matrix e\u03b3R in Eq .5 are called Discrete Diffusion Kernel and the Continuous Diffusion Kernel respectively .Based on the Heat Diffusion Models and their solutions , DiffusionRank can be established on undirected graphs , directed graphs , and random graphs .In the next section , we mainly focus on DiffusionRank in the random graph setting .For a random graph , the matrix I + \u03b3NR N or e\u03b3R can measure the similarity relationship between nodes .Let fi 0 = 1 , fj 0 = 0 if j = 6 i , then the vector f 0 represent the unit heat at node vi while all other nodes has zero heat .For such f 0 in a random graph , we can find the heat distribution at time 1 by using Eq .5 or Eq .6 .The heat distribution is exactly the i \u2212 th row of the matrix of I + \u03b3N R N or e\u03b3R .So the ith-row jth-column element hij in the matrix I + y\u0394tR N or e\u03b3R means the amount of heat that vi can receive from vj from time 0 to 1 .Thus the value hij can be used to measure the similarity from vj to vi .For a static graph , similarly the matrix I + \u03b3N H N or e\u03b3H can measure the similarity relationship between nodes .The intuition behind is that the amount h i , j of heat that a page vi receives from a unit heat in a page vj in a unit time embodies the extent of the link connections from page vj to page vi .Roughly speaking , when there are more uncrossed paths from vj to vi , vi will receive more heat from vj ; when the path length from vj to vi is shorter , vi will receive more heat from vj ; and when the pipe connecting vj and vi is wide , the heat will flow quickly .The final heat that vi receives will depend on various paths from vj to vi , their length , and the width of the pipes .Algorithm 1 DiffusionRank Function Input : The transition matrix A ; the inverse transition matrix U ; the decay factor \u03b1I for the inverse PageRank ; the decay factor \u03b1B for PageRank ; number of iterations MI for the inverse PageRank ; the number of trusted pages L ; the thermal conductivity coefficient y. Output : DiffusionRank score vector h.For the ranking task , we adopt the heat kernel on a random graph .Formally the DiffusionRank is described in Algorithm 1 , in which , the element Uij in the inverse transition matrix U is defined to be 1/Ij if there is a link from i to j , and 0 otherwise .This trusted pages selection procedure by inverse PageRank is completely borrowed from TrustRank 7 except for a fix number of the size of the trusted set .Although the inverse PageRank is not perfect in its ability of determining the maximum coverage , it is appealing because of its polynomial execution time and its reasonable intuition we actually inverse the original link when we try to build the seed set from those pages that point to many pages that in turn point to many pages and so on .In the algorithm , the underlying random graph is set as P = \u03b1B \u00b7 A + 1 \u2212 \u03b1B \u00b7 n1 \u00b7 1n \u00d7 n , which is induced by the Web graph .As a result , R = \u2212 I + P .In fact , the more general setting for DiffusionRank is P = \u03b1B \u00b7 A + 1 \u2212 \u03b1B \u00b7 n1 \u00b7 g \u00b7 1T .By such a setting , DiffusionRank is a generalization of TrustRank when y tends to infinity and when g is set in the same way as TrustRank .However , the second part of TrustRank is not adopted by us .In our model , g should be the true `` teleportation '' determined by the user 's browse habits , popularity distribution over all the Web pages , and so on ; P should be the true model of the random nature of the World Wide Web .Setting g according to the trusted pages will not be consistent with the basic idea of Heat Diffusion on a random graph .We simply set g = 1 only because we can not find it without any priori knowledge .Remark .In a social network interpretation , DiffusionRank first recognizes a group of trusted people , who may not be highly ranked , but they know many other people .The initially trusted people are endowed with the power to decide who can be further trusted , but can not decide the final voting results , and so they are not dictators .Next we show the four advantages for DiffusionRank .First , its solutions have two forms , both of which are closed form .One takes the discrete form , and has the advantage of fast computing while the other takes the continuous form , and has the advantage of being easily analyzed in theoretical aspects .The theoretical advantage has been shown in the proof of theorem in the next section .Second , it can be naturally employed to detect the groupgroup relation .For example , let G2 and G1 denote two groups , containing pages j1 , j2 , ... , js and i1 , i2 , ... , it , respectively .Then Eu , v hi. , j \u201e is the total amounts of heat that G1 receives from G2 , where hi. , j \u201e is the iu \u2212 th row jv \u2212 th column element of the heat kernel .More specifically , we need to first set f 0 for such an application as follows .In f 0 = f1 0 , f2 0 , ... , fn 0 T , if i \u2208 j1 , j2 , ... , js , then fi 0 = 1 , and 0 otherwise .Then we employ Eq .5 to calculate f 1 = f1 1 , f2 1 , ... , fn 1 T , finally we sum those fj 1 where j \u2208 i1 , i2 , ... , it .Fig. 1 a shows the results generated by the DiffusionRank .We consider five groups five departments in our Engineering Faculty : CSE , MAE , EE , IE , and SE .y is set to be 1 , the numbers in Fig. 1 a are the amount of heat that they diffuse to each other .These results are normalized by the total number of each group , and the edges are ignored if the values are less than 0.000001 .The group-to-group relations are therefore detected , for example , we can see that the most strong overall tie is from EE to IE .While it is a natural application for DiffusionRank because of the easy interpretation by the amount heat from one group to another group , it is difficult to apply other ranking techniques to such an application because they lack such a physical meaning .Third , it can be used to partition the Web graph into several parts .A quick example is shown below .The graph in Fig. 1 b is an undirected graph , and so we employ the Eq .3 .If we know that node 1 belongs to one community and that node 12 belongs to another community , then we can put one unit positive heat source on node 1 and one unit negative heat source on node 12 .After time 1 , if we set y = 0.5 , the heat distribution is 0.25 , 0.16 , 0.17 , 0.16 , 0.15 , 0.09 , 0.01 , -0.04 , -0.18 -0.21 , -0.21 , -0.34 , and if we set y = 1 , it will be 0.17 , 0.16 , 0.17 , 0.16 , 0.16 , 0.12 , 0.02 , -0.07 , -0.18 , -0.22 , -0.24 , -0.24 .In both settings , we can easily divide the graph into two parts : 1 , 2 , 3 , 4 , 5 , 6 , 7 with positive temperatures and 8 , 9 , 10 , 11 , 12 with negative temperatures .For directed graphs and random graphs , similarly we can cut them by employing corresponding heat solution .Fourth , it can be used to combat manipulation .Let G2 contain trusted Web pages j1 , j2 , ... , js , then for each page i , & hi , j \u201e is the heat that page i receives from G2 , and can be computed by the discrete approximation of Eq .4 in the case of a static graph or Eq .6 in the case of a random graph , in which f 0 is set to be a special initial heat distribution so that the trusted Web pages have unit heat while all the others have zero heat .In doing so , manipulated Web page will get a lower rank unless it has strong in-links from the trusted Web pages directly or indirectly .The situation is quite different for PageRank because PageRank is inputindependent as we have shown in Section 3.1 .Based on the fact that the connection from a trusted page to a `` bad '' page should be weak less uncross paths , longer distance and narrower pipe , we can say DiffusionRank can resist web spam if we can select trusted pages .It is fortunate that the trusted pages selection method in 7 the first part of TrustRank can help us to fulfill this task .For such an application of DiffusionRank , the computation complexity for Discrete Diffusion Kernel is the same as that for PageRank in cases of both a static graph and a random graph .This can be seen in Eq .6 , by which we need N iterations and for each iteration we need a multiplication operation between a matrix and a vector , while in Eq .1 we also need a multiplication operation between a matrix and a vector for each iteration .y plays an important role in the anti-manipulation effect of DiffusionRank .y is the thermal conductivity the heat diffusion coefficient .If it has a high value , heat will diffuse very quickly .Conversely , if it is small , heat will diffuse slowly .In the extreme case , if it is infinitely large , then heat will diffuse from one node to other nodes immediately , and this is exactly the case corresponding to PageRank .Next , we will interpret it mathematically .Let g = n1 1 .By the Perron Theorem 11 , we have shown that 1 is the largest eigenvalue of P = 1 \u2212 \u03b1 g1T + \u03b1A , and that no other eigenvalue whose absolute value is equal to 1 .Let x be the stable distribution , and so Px = x. x is the eigenvector corresponding to the eigenvalue 1 .Assume the n \u2212 1 other eigenvalues of P are | \u03bb2 | < 1 , ... , | \u03bbn | < 1 ,all eigenvalues of the matrix e\u03b3R are 1 , e\u03b3 \u03bb2-1 , ... , e\u03b3 \u03bbn-1 .When y + oo , they become 1 , 0 , ... , 0 , which means that 1 is the only nonzero eigenvalue of e\u03b3R when y + oo .We can see that when y + oo , e\u03b3Re\u03b3Rf 0 = e\u03b3Rf 0 , and so e\u03b3Rf 0 is an eigenvector of e\u03b3R when y + oo .On the other hand , e\u03b3Rx = I + yR + \u03b322 !R2 + \u03b333 !R3 + ... x = Ix + yRx + \u03b322 !R2x + \u03b33 3 !R3x + ... = x since Rx = \u2212 I + P x = \u2212 x + x = 0 , and hence x is the eigenvector of e\u03b3R for any y. Therefore both x and e\u03b3Rf 0 are the eigenvectors corresponding the unique eigenvalue 1 of e\u03b3R when y + oo , and consequently x = ce\u03b3Rf 0 .By this theorem , we see that DiffusionRank is a generalization of PageRank .When y = 0 , the ranking value is most robust to manipulation since no heat is diffused and the system is unchangeable , but the Web structure is completely ignored since e\u03b3Rf 0 = e0Rf 0 = If 0 = f 0 ; when y = oo , DiffusionRank becomes PageRank , it can be manipulated easily .We expect an appropriate setting of y that can balance both .For this , we have no theoretical result , but in practice we find that y = 1 works well in Section 5 .Next we discuss how to determine the number of iterations if we employ the discrete heat kernel .While we enjoy the advantage of the concise form of the exponential heat kernel , it is better for us to calculate DiffusionRank by employing Eq .6 in an iterative way .Then the problem about determining N the number of iterations arises : For a given threshold e , find N such that | | I + \u03b3NR N \u2212 e\u03b3R f 0 | | < e for any f 0 whose sum is one .Since it is difficult to solve this problem , we propose a heuristic motivated by the following observations .WhenComparing Eq .8 and Eq .9 , we observe that the eigenvalues of I + \u03b3NR N \u2212 e\u03b3R are 1 + \u03b3 \u03bbn-1 N N \u2212 e\u03b3 \u03bbn-1 .We propose a heuristic method to determine N so that the difference between the eigenvalues are less than a threshold for only positive \u03bbs .We also observe that if y = 1 , \u03bb < 1 , then | 1 + \u03b3 \u03bb-1according to different accuracy requirements .In this paper , we use the relatively accurate setting N = 100 to make the real eigenvalues in I + \u03b3N R N \u2212 e\u03b3R less than 0.005 .", "conclusions": "We conclude that DiffusionRank is a generalization of PageRank , which is interesting in that the heat diffusion coefficient ry can balance the extent that we want to model the original Web graph and the extent that we want to reduce the effect of link manipulations .The experimental results show that we can actually achieve such a balance by setting ry = 1 , although the best setting including varying rya is still under further investigation .This anti-manipulation feature enables DiffusionRank to be a candidate as a penicillin for Web spamming .Moreover , DiffusionRank can be employed to find group-group relations and to partition Web graph into small communities .All these advantages can be achieved in the same computational complexity as PageRank .For the special application of anti-manipulation , DiffusionRank performs best both in reduction effects and in its stability among all the three algorithms ."}