{"reader_keywords": ["outcome feature of interest", "interest outcome feature", "supply-chain trading", "empirical mechanism", "parameter setting", "observed behavior", "two-stage game", "player", "participant", "gametheoretic model", "analysis", "nash equilibrium"], "reader_keywords_stem": ["outcom featur of interest", "interest outcom featur", "suppli-chain trade", "empir mechan", "paramet set", "observ behavior", "two-stage game", "player", "particip", "gametheoret model", "analysi", "nash equilibrium"], "introduction": "We illustrate our problem with an anecdote from a supply chain research exercise : the 2003 and 2004 Trading Agent Competition TAC Supply Chain Management SCM game .TAC/SCM 1 defines a scenario where agents compete to maximize their profits as manufacturers in a supply chain .The agents procure components from the various suppliers and assemble finished goods for sale to customers , repeatedly over a simulated year .1 1Information about TAC and the SCM game , including specifications , rules , and competition results , can be found at http://www.sics.se/tac .As it happened , the specified negotiation behavior of suppliers provided a great incentive for agents to procure large quantities of components on day 0 : the very beginning of the simulation .During the early rounds of the 2003 SCM competition , several agent developers discovered this , and the apparent success led to most agents performing the majority of their purchasing on day 0 .Although jockeying for day-0 procurement turned out to be an interesting strategic issue in itself 19 , the phenomenon detracted from other interesting problems , such as adapting production levels to varying demand since component costs were already sunk , and dynamic management of production , sales , and inventory .Several participants noted that the predominance of day-0 procurement overshadowed other key research issues , such as factory scheduling 2 and optimizing bids for customer orders 13 .After the 2003 tournament , there was a general consensus in the TAC community that the rules should be changed to deter large day-0 procurement .The task facing game organizers can be viewed as a problem in mechanism design .The designers have certain game features under their control , and a set of objectives regarding game outcomes .Unlike most academic treatments of mechanism design , the objective is a behavioral feature moderate day-0 procurement rather than an allocation feature like economic efficiency , and the allowed mechanisms are restricted to those judged to require only an incremental modification of the current game .Replacing the supplychain negotiation procedures with a one-shot direct mechanism , for example , was not an option .We believe that such operational restrictions and idiosyncratic objectives are actually quite typical of practical mechanism design settings , where they are perhaps more commonly characterized as incentive engineering problems .In response to the problem , the TAC/SCM designers adopted several rule changes intended to penalize large day-0 orders .These included modifications to supplier pricing policies and introduction of storage costs assessed on inventories of components and finished goods .Despite the changes , day-0 procurement was very high in the early rounds of the 2004 competition .In a drastic measure , the GameMaster imposed a fivefold increase of storage costs midway through the tournament .Even this did not stem the tide , and day-0 procurement in the final rounds actually increased by some measures from 2003 9 .The apparent difficulty in identifying rule modifications that effect moderation in day-0 procurement is quite striking .Although the designs were widely discussed , predictions for the effects of various proposals were supported primarily by intuitive arguments or at best by back-of-the-envelope calculations .Much of the difficulty , of course , is anticipating the agents ' and their developers ' responses without essentially running a gaming exercise for this purpose .The episode caused us to consider whether new approaches or tools could enable more systematic analysis of design options .Standard game-theoretic and mechanism design methods are clearly relevant , although the lack of an analytic description of the game seems to be an impediment .Under the assumption that the simulator itself is the only reliable source of outcome computation , we refer to our task as empirical mechanism design .In the sequel , we develop some general methods for empirical mechanism design and apply them to the TAC/SCM redesign problem .Our analysis focuses on the setting of storage costs taking other game modifications as fixed , since this is the most direct deterrent to early procurement adopted .Our results confirm the basic intuition that incentives for day-0 purchasing decrease as storage costs rise .We also confirm that the high day-0 procurement observed in the 2004 tournament is a rational response to the setting of storage costs used .Finally , we conclude from our data that it is very unlikely that any reasonable setting of storage costs would result in acceptable levels of day-0 procurement , so a different design approach would have been required to eliminate this problem .Overall , we contribute a formal framework and a set of methods for tackling indirect mechanism design problems in settings where only a black-box description of players ' utilities is available .Our methods incorporate estimation of sets of Nash equilibria and sample Nash equilibria , used in conjuction to support general claims about the structure of the mechanism designer 's utility , as well as a restricted probabilistic analysis to assess the likelihood of conclusions .We believe that most realistic problems are too complex to be amenable to exact analysis .Consequently , we advocate the approach of gathering evidence to provide indirect support of specific hypotheses .", "title": "Empirical Mechanism Design : Methods , with Application to a Supply-Chain Scenario", "author_keywords_stem": ["empirical mechanism design", "game theory"], "background": "A normalform game2 is denoted by I , Ri , ui r , where I refers to the set of players and m = | I | is the number of players .Ri is the set of strategies available to player i \u2208 I , with R = R1 \u00d7 ... \u00d7 Rm representing the set ofjoint strategies of all players .We designate the set of pure strategies available to player i by Ai , and denote the joint set of pure strategies of all players by A = A1 \u00d7 ... \u00d7 Am .It is often convenient to refer to a strategy of player i separately from that of the remaining players .To accommodate this , we use a_i to denote the joint strategy of all players other than player i. Let Si be the set of all probability distributions mixtures over Ai and , similarly , S be the set of all distributions over A .An s \u2208 S is called a mixed strategy profile .When the game is finite i.e. , A and I are both finite , the probability that a \u2208 A is played under s is written s a = s ai , a_i .When the distribution s is not correlated , we can simply say si ai when referring to the probability player i plays ai under s. Next , we define the payoff utility function of each player i by ui : A1 \u00d7 \u00b7 \u00b7 \u00b7 \u00d7 Am + R , where ui ai , a_i indicates the payoff to player i to playing pure strategy ai when the remaining players play a_i .We can extend this definition to mixed strategies by assuming that ui are von Neumann-Morgenstern vNM utilities as follows : ui s = Es ui , where Es is the expectation taken with respect to the probability distribution of play induced by the players ' mixed strategy s. 2By employing the normal form , we model agents as playing a single action , with decisions taken simultaneously .This is appropriate for our current study , which treats strategies agent programs as atomic actions .We could capture finer-grained decisions about action over time in the extensive form .Although any extensive game can be recast in normal form , doing so may sacrifice compactness and blur relevant distinctions e.g. , subgame perfection .Occasionally , we write ui x , y to mean that x \u2208 Ai or Si and y \u2208 A_i or S_i depending on context .We also express the set of utility functions of all players as u \u00b7 = u1 \u00b7 , ... , um \u00b7 .We define a function , e : R + R , interpreted as the maximum benefit any player can obtain by deviating from its strategy in the specified profile .where r belongs to some strategy set , R , of either pure or mixed strategies .Faced with a game , an agent would ideally play its best strategy given those played by the other agents .A configuration where all agents play strategies that are best responses to the others constitutes a Nash equilibrium .When r \u2208 A , the above defines a pure strategy Nash equilibrium ; otherwise the definition describes a mixed strategy Nash equilibrium .We often appeal to the concept of an approximate , or e-Nash equilibrium , where e is the maximum benefit to any agent for deviating from the prescribed strategy .Thus , e r as defined above 1 is such that profile r is an e-Nash equilibrium iff e r \u2264 e .In this study we devote particular attention to games that exhibit symmetry with respect to payoffs , rendering agents strategically identical .", "abstract": "Our proposed methods employ learning and search techniques to estimate outcome features of interest as a function of mechanism parameter settings .We illustrate our approach with a design task from a supply-chain trading competition .Designers adopted several rule changes in order to deter particular procurement behavior , but the measures proved insufficient .Our empirical mechanism analysis models the relation between a key design parameter and outcomes , confirming the observed behavior and indicating that no reasonable parameter settings would have been likely to achieve the desired effect .More generally , we show that under certain conditions , the estimator of optimal mechanism parameter setting based on empirical data is consistent .", "id": "J-45", "combined_keywords_stem": ["outcom featur of interest", "interest outcom featur", "suppli-chain trade", "empir mechan", "paramet set", "observ behavior", "two-stage game", "player", "particip", "gametheoret model", "analysi", "nash equilibrium", "empir mechan design", "game theori"], "combined_keywords": ["outcome feature of interest", "interest outcome feature", "supply-chain trading", "empirical mechanism", "parameter setting", "observed behavior", "two-stage game", "player", "participant", "gametheoretic model", "analysis", "nash equilibrium", "empirical mechanism design", "game theory"], "author_keywords": ["empirical mechanism design", "game theory"], "method": "We model the strategic interactions between the designer of the mechanism and its participants as a two-stage game .The designer moves first by selecting a value , 0 , from a set of allowable mechanism settings , \u0398 .All the participant agents observe the mechanism parameter 0 and move simultaneously thereafter .For example , the designer could be deciding between a first-price and second-price sealed-bid auction mechanisms , with the presumption that after the choice has been made , the bidders will participate with full awareness of the auction rules .Since the participants play with full knowledge of the mechanism parameter , we define a game between them in the second stage as \u0393\u03b8 = I , Ri , ui r , 0 .We refer to \u0393\u03b8 as a game induced by 0 .Let N 0 be the set of strategy profiles considered solutions of the game \u0393\u03b8 .3 Suppose that the goal of the designer is to optimize the value of some welfare function , W r , 0 , dependent on the mechanism parameter and resulting play , r .We define a pessimistic measure , W \u02c6R , 0 = inf W r , 0 : r \u2208 \u02c6R , representing the worst-case welfare of the game induced by 0 , assuming that agents play some joint strategy in \u02c6R .Typically we care about W N 0 , 0 , the worst-case outcome of playing some solution .4 On some problems we can gain considerable advantage by using an aggregation function to map the welfare outcome of a game 3We generally adopt Nash equilibrium as the solution concept , and thus take N 0 to be the set of equilibria .However , much of the methodology developed here could be employed with alternative criteria for deriving agent behavior from a game definition .4Again , alternatives are available .For example , if one has a probability distribution over the solution set N 0 , it would be natural to take the expectation of W r , 0 instead .specified in terms of agent strategies to an equivalent welfare outcome specified in terms of a lower-dimensional summary .We overload the function symbol to apply to sets of strategy profiles : \u03c6 \u02c6R = \u03c6 r : r \u2208 \u02c6R .For convenience of exposition , we write \u03c6 \u2217 \u03b8 to mean \u03c6 N \u03b8 .Using an aggregation function yields a more compact representation of strategy profiles .For example , suppose as in our application below that an agent 's strategy is defined by a numeric parameter .If all we care about is the total value played , we may take \u03c6 a = Pmi = 1 ai .If we have chosen our aggregator carefully , we may also capture structure not obvious otherwise .For example , \u03c6 \u2217 \u03b8 could be decreasing in \u03b8 , whereas N \u03b8 might have a more complex structure .Given a description of the solution correspondence N \u03b8 equivalently , \u03c6 \u2217 \u03b8 , the designer faces a standard optimization problem .Alternatively , given a simulator that could produce an unbiased sample from the distribution of W N \u03b8 , \u03b8 for any \u03b8 , the designer would be faced with another much appreciated problem in the literature : simulation optimization 12 .However , even for a game \u0393\u03b8 with known payoffs it may be computationally intractable to solve for Nash equilibria , particularly if the game has large or infinite strategy sets .Additionally , we wish to study games where the payoffs are not explicitly given , but must be determined from simulation or other experience with the game .5 Accordingly , we assume that we are given a possibly noisy data set of payoff realizations : Do = \u03b81 , a1 , U1 , ... , \u03b8k , ak , Uk , where for every data point \u03b8i is the observed mechanism parameter setting , ai is the observed pure strategy profile of the participants , and Ui is the corresponding realization of agent payoffs .We may also have additional data generated by a possibly noisy simulator : Ds = \u03b8k +1 , ak +1 , Uk +1 , ... , \u03b8k + l , ak + l , Uk + l .Let D = Do , Ds be the combined data set .Either Do or Ds may be null for a particular problem .In the remainder of this paper , we apply our modeling approach , together with several empirical game-theoretic methods , in order to answer questions regarding the design of the TAC/SCM scenario .Since our data comes in the form of payoff experience and not as the value of an objective function for given settings of the control variable , we can no longer rely on the methods for optimizing functions using simulations .Indeed , a fundamental aspect of our design problem involves estimating the Nash equilibrium correspondence .Furthermore , we can not rely directly on the convergence results that abound in the simulation optimization literature , and must establish probabilistic analysis methods tailored for our problem setting .We describe our empirical design analysis methods by presenting a detailed application to the TAC/SCM scenario introduced above .Recall that during the 2004 tournament , the designers of the supplychain game chose to dramatically increase storage costs as a measure aimed at curbing day-0 procurement , to little avail .Here we systematically explore the relationship between storage costs and 5This is often the case for real games of interest , where natural language or algorithmic descriptions may substitute for a formal specification of strategy and payoff functions .the aggregate quantity of components procured on day 0 in equilibrium .In doing so , we consider several questions raised during and after the tournament .First , does increasing storage costs actually reduce day-0 procurement ?Second , was the excessive day-0 procurement that was observed during the 2004 tournament rational ?And third , could increasing storage costs sufficiently have reduced day-0 procurement to an `` acceptable '' level , and if so , what should the setting of storage costs have been ?It is this third question that defines the mechanism design aspect of our analysis .6 To apply our methods , we must specify the agent strategy sets , the designer 's welfare function , the mechanism parameter space , and the source of data .We restrict the agent strategies to be a multiplier on the quantity of the day-0 requests by one of the finalists , Deep Maize , in the 2004 TAC/SCM tournament .We further restrict it to the set 0,1.5 , since any strategy below 0 is illegal and strategies above 1.5 are extremely aggressive thus unlikely to provide refuting deviations beyond those available from included strategies , and certainly not part of any desirable equilibrium .All other behavior is based on the behavior of Deep Maize and is identical for all agents .This choice can provide only an estimate of the actual tournament behavior of a `` typical '' agent .However , we believe that the general form of the results should be robust to changes in the full agent behavior .sum of day-0 purchases .Let \u03c6 a = P6 We model the designer 's welfare function as a threshold on the i = 1 ai be the aggregation function representing the sum of day-0 procurement of the six agents participating in a particular supply-chain game for mixed strategy profiles s , we take expectation of \u03c6 with respect to the mixture .The designer 's welfare function W N \u03b8 , \u03b8 is then given by I sup \u03c6 \u2217 \u03b8 \u2264 \u03b1 , where \u03b1 is the maximum acceptable level of day-0 procurement and I is the indicator function .The designer selects a value \u03b8 of storage costs , expressed as an annual percentage of the baseline value of components in the inventory charged daily , from the set \u0398 = R + .Since the designer 's decision depends only on \u03c6 \u2217 \u03b8 , we present all of our results in terms of the value of the aggregation function .The objective of TAC/SCM agents is to maximize profits realized over a game instance .Thus , if we fix a strategy for each agent at the beginning of the simulation and record the corresponding profits at the end , we will have obtained a data point in the form a , U a .If we also have fixed the parameter \u03b8 of the simulator , the resulting data point becomes part of our data set D .This data set , then , contains data only in the form of pure strategies of players and their corresponding payoffs , and , consequently , in order to formulate the designer 's problem as optimization , we must first determine or approximate the set of Nash equilibria of each game \u0393\u03b8 .Thus , we need methods for approximating Nash equilibria for infinite games .Below , we describe the two methods we used in our study .The first has been explored empirically before , whereas the second is introduced here as the method specifically designed to approximate a set of Nash equilibria .The first method for estimating Nash equilibria based on data uses supervised learning to approximate payoff functions of mech6We do not address whether and how other measures e.g. , constraining procurement directly could have achieved design objectives .Our approach takes as given some set of design options , in this case defined by the storage cost parameter .In principle our methods could be applied to a different or larger design space , though with corresponding complexity growth .anism participants from a data set of game experience 17 .Once approximate payoff functions are available for all players , the Nash equilibria may be either found analytically or approximated using numerical techniques , depending on the learning model .In what follows , we estimate only a sample Nash equilibrium using this technique , although this restriction can be removed at the expense of additional computation time .One advantage of this method is that it can be applied to any data set and does not require the use of a simulator .Thus , we can apply it when Ds = \u2205 .If a simulator is available , we can generate additional data to build confidence in our initial estimates .7 We tried the following methods for approximating payoff functions : quadratic regression QR , locally weighted average LWA , and locally weighted linear regression LWLR .We also used control variates to reduce the variance of payoff estimates , as in our previous empirical game-theoretic analysis of TAC/SCM -03 19 .The quadratic regression model makes it possible to compute equilibria of the learned game analytically .For the other methods we applied replicator dynamics 7 to a discrete approximation of the learned game .The expected total day-0 procurement in equilibrium was taken as the estimate of an outcome .When we have access to a simulator , we can also use directed search through profile space to estimate the set of Nash equilibria , which we describe here after presenting some additional notation .defined as maxa ' \u2208 Snb a , D max ui a , a , a \u2212 ui a , al a , 0 .We say that a is a candidate \u03b4-equilibrium for \u03b4 \u2265 \u02c6 ~ .When Snb a , \u02dcD = \u2205 i.e. , all strategic neighbors are represented in the data , a is confirmed as an \u02c6 ~ Nash equilibrium .Our search method operates by exploring deviations from candidate equilibria .We refer to it as `` BestFirstSearch '' , as it selects with probability one a strategy profile a ' \u2208 Snb a , \u02dcD that has the smallest ~ \u02c6 in D. Finally we define an estimator for a set of Nash equilibria .DEFINITION 6 .For a set K , define Co K to be the convex hull of K. Let B\u03b4 be the set of candidates at level \u03b4 .We define \u02c6\u03c6 \u2217 \u03b8 = Co \u03c6 a : a \u2208 B\u03b4 for a fixed \u03b4 to be an estimator of \u03c6 \u2217 \u03b8 .In words , the estimate of a set of equilibrium outcomes is the convex hull of all aggregated strategy profiles with ~ bound below some fixed \u03b4 .This definition allows us to exploit structure arising from the aggregation function .If two profiles are close in terms of aggregation values , they may be likely to have similar ~ bounds .In particular , if one is an equilibrium , the other may be as well .We present some theoretical support for this method of estimating the set of Nash equilibria below .Since the game we are interested in is infinite , it is necessary to terminate BestFirstSearch before exploring the entire space of strat7For example , we can use active learning techniques 5 to improve the quality of payoff function approximation .In this work , we instead concentrate on search in strategy profile space .egy profiles .We currently determine termination time in a somewhat ad hoc manner , based on observations about the current set of candidate equilibria .8Our data was collected by simulating TAC/SCM games on a local version of the 2004 TAC/SCM server , which has a configuration setting for the storage cost .Agent strategies in simulated games were selected from the set 0 , 0.3 , 0.6 , ... , 1.5 in order to have positive probability of generating strategic neighbors .9 A baseline data set Do was generated by sampling 10 randomly generated strategy profiles for each \u03b8 \u2208 0 , 50 , 100 , 150 , 200 .Between 5 and 10 games were run for each profile after discarding games that had various flaws .10 We used search to generate a simulated data set Ds , performing between 12 and 32 iterations of BestFirstSearch for each of the above settings of \u03b8 .Since simulation cost is extremely high a game takes nearly 1 hour to run , we were able to run a total of 2670 games over the span of more than six months .For comparison , to get the entire description of an empirical game defined by the restricted finite joint strategy space for each value of \u03b8 \u2208 0 , 50 , 100 , 150 , 200 would have required at least 23100 games sampling each profile 10 times .We applied the three learning methods described above to the baseline data set Do .Additionally , we generated an estimate of the Nash equilibrium correspondence , \u02c6\u03c6 \u2217 \u03b8 , by applying Definition 6 with \u03b4 = 2.5 E6 .The results are shown in Figure 1 .As we can see , the correspondence \u02c6\u03c6 \u2217 \u03b8 has little predictive power based on Do , and reveals no interesting structure about the game .In contrast , all three learning methods suggest that total day-0 procurement is a decreasing function of storage costs .The correspondence \u02c6\u03c6 \u2217 \u03b8 is the interval between `` BaselineMin '' and `` BaselineMax '' .8Generally , search is terminated once the set of candidate equilibria is small enough to draw useful conclusions about the likely range of equilibrium strategies in the game .9Of course , we do not restrict our Nash equilibrium estimates to stay in this discrete subset of 0,1.5 .10For example , if we detected that any agent failed during the game failures included crashes , network connectivity problems , and other obvious anomalies , the game would be thrown out .To corroborate the initial evidence from the learning methods , we estimated \u02c6\u03c6 \u2217 0 again , using S = 2.5 E6 on the data set D = Do , Ds , where Ds is data generated through the application of BestFirstSearch .The results of this estimate are plotted against the results of the learning methods trained on Do11 in Figure 2 .First , we note that the addition of the search data narrows the range of potential equilibria substantially .Furthermore , the actual point predictions of the learning methods and those based on e-bounds after search are reasonably close .Combining the evidence gathered from these two very different approaches to estimating the outcome correspondence yields a much more compelling picture of the relationship between storage costs and day-0 procurement than either method used in isolation .\u02c6 imation techniques trained on Do .The correspondence \u03c6 \u2217 0 for D = Do , Ds is the interval between `` SearchMin '' and `` SearchMax '' .This evidence supports the initial intuition that day-0 procurement should be decreasing with storage costs .It also confirms that high levels of day-0 procurement are a rational response to the 2004 tournament setting of average storage cost , which corresponds to 0 = 100 .The minimum prediction for aggregate procurement at this level of storage costs given by any experimental methods is approximately 3 .This is quite high , as it corresponds to an expected commitment of 1/3 of the total supplier capacity for the entire game .The maximum prediction is considerably higher at 4.5 .In the actual 2004 competition , aggregate day-0 procurement was equivalent to 5.71 on the scale used here 9 .Our predictions underestimate this outcome to some degree , but show that any rational outcome was likely to have high day-0 procurement .We have reasonably strong evidence that the outcome correspondence is decreasing .However , the ultimate goal is to be able to either set the storage cost parameter to a value that would curb day-0 procurement in equilibrium or conclude that this is not possible .To answer this question directly , suppose that we set a conservative threshold \u03b1 = 2 on aggregate day-0 procurement .12 Linear 11It is unclear how meaningful the results of learning would be if Ds were added to the training data set .Indeed , the additional data may actually increase the learning variance .12Recall that designer 's objective is to incentivize aggergate day-0 procurement that is below the threshold \u03b1 .Our threshold here still represents a commitment of over 20 % of the suppliers ' capacity for extrapolation of the maximum of the outcome correspondence estimated from D yields 0 = 320 .The data for 0 = 320 were collected in the same way as for other storage cost settings , with 10 randomly generated profiles followed by 33 iterations of BestFirstSearch .Figure 3 shows the detailed e-bounds for all profiles in terms of their corresponding values of0 = 320 .Strategy profiles explored are presented in terms of the corresponding values of \u03c6 a .The gray region corresponds to \u02c6\u03c6 \u2217 320 with S = 2.5 M .The estimated set of aggregate day-0 outcomes is very close to that for 0 = 200 , indicating that there is little additional benefit to raising storage costs above 200 .Observe , that even the lower bound of our estimated set of Nash equilibria is well above the target day-0 procurement of 2 .Furthermore , payoffs to agents are almost always negative at 0 = 320 .Consequently , increasing the costs further would be undesirable even if day-0 procurement could eventually be curbed .Since we are reasonably confident that \u03c6 \u2217 0 is decreasing in 0 , we also do not expect that setting 0 somewhere between 200 and 320 will achieve the desired result .We conclude that it is unlikely that day-0 procurement could ever be reduced to a desirable level using any reasonable setting of the storage cost parameter .That our predictions tend to underestimate tournament outcomes reinforces this conclusion .To achieve the desired reduction in day-0 procurement requires redesigning other aspects of the mechanism .Our empirical analysis has produced evidence in support of the conclusion that no reasonable setting of storage cost was likely to sufficiently curb excessive day-0 procurement in TAC/SCM ' 04 .All of this evidence has been in the form of simple interpolation and extrapolation of estimates of the Nash equilibrium correspondence .These estimates are based on simulating game instances , and are subject to sampling noise contributed by the various stochastic elements of the game .In this section , we develop and apply methods for evaluating the sensitivity of our e-bound calculations to such stochastic effects .Suppose that all agents have finite and small pure strategy sets , A. Thus , it is feasible to sample the entire payoff matrix of the game .Additionally , suppose that noise is additive with zero-mean the entire game on average , so in practice we would probably want the threshold to be even lower .and finite variance , that is , Ui a = ui a + \u02dc\u03bei a , where Ui a is the observed payoff to i when a was played , ui a is the actual corresponding payoff , and \u02dc\u03bei a is a mean-zero normal random variable .We designate the known variance of\u02dc\u03bei a by \u03c32i a .Thus , we assume that \u02dc\u03bei a is normal with distribution N 0 , \u03c32i a .We take \u00af ui a to be the sample mean over all Ui a in D , and follow Chang and Huang 3 to assume that we have an improper prior over the actual payoffs ui a and sampling was independent for all i and a .We also rely on their result that ui a | \u00af ui a =\u00af ui a \u2212 Zi a / \u03c3i a / ni a are independent with posterior distributions N \u00af ui a , \u03c32i a / ni a , where ni a is the number of samples taken of payoffs to i for pure profile a , and Zi a \u223c N 0 , 1 .We now derive a generic probabilistic bound that a profile a \u2208 A is an ~ Nash equilibrium .If ui \u00b7 | \u00af ui \u00b7 are independent for all i \u2208 I and a \u2208 A , we have the following result from this point on we omit conditioning on \u00af ui \u00b7 for brevity :where fui a u is the pdf of N \u00af ui a , \u03c3i a .The proofs of this and all subsequent results are in the Appendix .The posterior distribution of the optimum mean of n samples , derived by Chang and Huang 3 , iswhere a \u2208 A and \u03a6 \u00b7 is the N 0 , 1 distribution function .Combining the results 2 and 3 , we obtain a probabilistic confidence bound that ~ a \u2264 \u03b3 for a given \u03b3 .Now , we consider cases of incomplete data and use the results we have just obtained to construct an upper bound restricted to profiles represented in data on the distribution of sup \u03c6 \u2217 \u03b8 and inf \u03c6 \u2217 \u03b8 assuming that both are attainable :stricted to D for \u03b8 \u2208 150 , 200 , 320 when N \u03b8 is a set of Nash equilibria .Tables 1 and 2 suggest that the existence of any equilibrium with \u03c6 a < 2.7 is unlikely for any \u03b8 that we have data for , although this judgment , as we mentioned , is only with respect to the profiles we have actually sampled .We can then accept this as another piece of evidence that the designer could not find a suitable setting of \u03b8 to achieve his objectives indeed , the designer seems unlikely to achieve his objective even if he could persuade participants to play a desirable equilibrium !Table 1 also provides additional evidence that the agents in the 2004 TAC/SCM tournament were indeed rational in procuring large numbers of components at the beginning fo the game .If we look at the third column of this table , which corresponds to \u03b8 = 100 , we can gather that no profile a in our data with \u03c6 a < 3 is very likely to be played in equilibrium .The bounds above provide some general evidence , but ultimately we are interested in a concrete probabilistic assessment of our conclusion with respect to the data we have sampled .Particularly , we would like to say something about what happens for the settings of \u03b8 for which we have no data .To derive an approximate probabilistic bound on the probability that no \u03b8 \u2208 \u0398 could have achieved the designer 's objective , let \u222a Jj = 1\u0398j , be a partition of \u0398 , and assume that the function sup \u03c6 \u2217 \u03b8 satisfies the Lipschitz condition with Lipschitz constant Aj on each subset \u0398j .13 Since we have determined that raising the storage cost above 320 is undesirable due to secondary considerations , we restrict attention to \u0398 = 0 , 320 .We now define each subset j to be the interval between two points for which we have produced data .Thus ,with j running between 1 and 5 , corresponding to subintervals above .We will further denote each \u0398j by aj , bj .14 Then , the following Proposition gives us an approximate upper bound15 on the probability that sup \u03c6 \u2217 \u03b8 \u2264 \u03b1 .where x is a real number and \u2264 D indicates that the upper bound accounts only for strategies that appear in the data set D .Since the events \u2203 a \u2208 D : \u03c6 a \u2264 x \u2227 a \u2208 N \u03b8 and inf \u03c6 \u2217 \u03b8 \u2264 x are equivalent , this also defines an upper bound on the probability of inf \u03c6 \u2217 \u03b8 \u2264 x .The values thus derived comprise the Tables 1 and 2 .stricted to D for \u03b8 \u2208 0 , 50 , 100 when N \u03b8 is a set of Nash equilibria .where cj = 2\u03b1 + Aj bj \u2212 aj and \u2264 D indicates that the upper bound only accounts for strategies that appear in the data set D.Due to the fact that our bounds are approximate , we can not use them as a conclusive probabilistic assessment .Instead , we take this as another piece of evidence to complement our findings .Even if we can assume that a function that we approximate from data is Lipschitz continuous , we rarely actually know the Lipschitz constant for any subset of \u0398 .Thus , we are faced with a task of estimating it from data .Here , we tried three methods of doing this .The first one simply takes the highest slope that the function attains within the available data and uses this constant value for every subinterval .This produces the most conservative bound , and in many situations it is unlikely to be informative .An alternative method is to take an upper bound on slope obtained within each subinterval using the available data .This produces a much less conservative upper bound on probabilities .However , since the actual upper bound is generally greater for each subinterval , the resulting probabilistic bound may be deceiving .A final method that we tried is a compromise between the two above .Instead of taking the conservative upper bound based on data over the entire function domain \u0398 , we take the average of upper bounds obtained at each \u0398j .The bound at an interval is then taken to be the maximum of the upper bound for this interval and the average upper bound for all intervals .The results of evaluating the expression forsetting of \u03b8 \u2208 0 , 320 will satisfy the designer objective with target \u03b1 = 2 .Different methods of approximating the upper bound on slope in each subinterval j are used .this work , the expression gives an upper bound on the probability that some setting of \u03b8 i.e. , storage cost in the interval 0,320 will result in total day-0 procurement that is no greater in any equilibrium than the target specified by \u03b1 and taken here to be 2 .As we had suspected , the most conservative approach to estimating the upper bound on slope , presented in the first column of the table , provides us little information here .However , the other two estimation approaches , found in columns two and three of Table 3 , suggest that we are indeed quite confident that no reasonable setting of \u03b8 \u2208 0 , 320 would have done the job .Given the tremendous difficulty of the problem , this result is very strong .16 Still , we must be very cautious in drawing too heroic a conclusion based on this evidence .Certainly , we have not `` checked '' all the profiles but only a small proportion of them infinitesimal , if we consider the entire continuous domain of \u03b8 and strategy sets .Nor can we expect ever to obtain enough evidence to make completely objective conclusions .Instead , the approach we advocate here is to collect as much evidence as is feasible given resource constraints , and make the most compelling judgment based on this evidence , if at all possible .At this point , we explore abstractly whether a design parameter choice based on payoff data can be asymptotically reliable .16Since we did not have all the possible deviations for any profile available in the data , the true upper bounds may be even lower .As a matter of convenience , we will use notation un , i a to refer to a payoff function of player i based on an average over n i.i.d. samples from the distribution of payoffs .We also assume that un , i a are independent for all a \u2208 A and i \u2208 I .We will use the notation \u0393n to refer to the game I , R , ui , n \u00b7 , whereas \u0393 will denote the `` underlying '' game , I , R , ui \u00b7 .Similarly , we define ~ n r to be ~ r with respect to the game \u0393n .In this section , we show that ~ n s \u2192 ~ s a.s. uniformly on the mixed strategy space for any finite game , and , furthermore , that all mixed strategy Nash equilibria in empirical games eventually become arbitrarily close to some Nash equilibrium strategies in the underlying game .We use these results to show that under certain conditions , the optimal choice of the design parameter based on empirical data converges almost surely to the actual optimum .PROOF .Since ~ s = 0 for every s \u2208 N , we can find M large enough such that Pr supn \u2265 M sups \u2208 N ~ n s < \u03b3 = 1 .By the Corollary , for any game with a finite set of pure strategies and for any ~ > 0 , all Nash equilibria lie in the set of empirical ~ Nash equilibria if enough samples have been taken .As we now show , this provides some justification for our use of a set of profiles with a non-zero ~ bound as an estimate of the set of Nash equilibria .First , suppose we conclude that for a particular setting of \u03b8 , sup \u02c6\u03c6 \u2217 \u03b8 \u2264 \u03b1 .Then , since for any fixed ~ > 0 , N \u03b8 \u2282 Nn , ~ \u03b8 when n is large enough ,for any such n. Thus , since we defined the welfare function of the designer to be I sup \u03c6 \u2217 \u03b8 \u2264 \u03b1 in our domain of interest , the empirical choice of \u03b8 satisfies the designer 's objective , thereby maximizing his welfare function .Alternatively , suppose we conclude that inf \u02c6\u03c6 \u2217 \u03b8 > \u03b1 for evfor every \u03b8 , and we can conclude that no setting of \u03b8 will satisfy the designer 's objective .Now , we will show that when the number of samples is large enough , every Nash equilibrium of \u0393n is close to some Nash equilibrium of the underlying game .This result will lead us to consider convergence of optimizers based on empirical data to actual optimal mechanism parameter settings .We first note that the function ~ s is continuous in a finite game .LEMMA 5 .Let S be a mixed strategy set defined on a finite game .Then ~ : S \u2192 R is continuous .For the exposition that follows , we need a bit of additional notation .First , let Z , d be a metric space , and X , Y C Z and define directed Hausdorffdistance from X to Y to beObserve that U C X = : > .h U , Y < h X , Y .Further , define BS x , \u03b4 to be an open ball in S C Z with center x E S and radius \u03b4 .Now , let Nn denote all Nash equilibria of the game \u0393n and letthat is , the union of open balls of radius \u03b4 with centers at Nash equilibria of \u0393 .Note that h N\u03b4 , N = \u03b4 .We can then prove the following general result .We will now show that in the special case when \u0398 and A are finite and each \u0393\u03b8 has a unique Nash equilibrium , the estimates 0\u02c6 of optimal designer parameter converge to an actual optimizer almost surely .Let 0\u02c6 = arg max\u03b8 \u2208 \u0398 W Nn 0 , 0 , where n is the number of times each pure profile was sampled in \u0393\u03b8 for every 0 , and let 0 \u2217 = arg max\u03b8 \u2208 \u0398 W N 0 , 0 .The shortcoming of the above result is that , within our framework , the designer has no way of knowing or ensuring that \u0393\u03b8 do , indeed , have unique equilibria .However , it does lend some theoretical justification for pursuing design in this manner , and , perhaps , will serve as a guide for more general results in the future .In this work we spent considerable effort developing general tactics for empirical mechanism design .We defined a formal gametheoretic model of interaction between the designer and the participants of the mechanism as a two-stage game .We also described in some generality the methods for estimating a sample Nash equilibrium function when the data is extremely scarce , or a Nash equilibrium correspondence when more data is available .Our techniques are designed specifically to deal with problems in which both the mechanism parameter space and the agent strategy sets are infinite and only a relatively small data set can be acquired .A difficult design issue in the TAC/SCM game which the TAC community has been eager to address provides us with a setting to test our methods .In applying empirical game analysis to the problem at hand , we are fully aware that our results are inherently inexact .Thus , we concentrate on collecting evidence about the structure of the Nash equilibrium correspondence .In the end , we can try to provide enough evidence to either prescribe a parameter setting , or suggest that no setting is possible that will satisfy the designer .In the case of TAC/SCM , our evidence suggests quite strongly that storage cost could not have been effectively adjusted in the 2004 tournament to curb excessive day-0 procurement without detrimental effects on overall profitability .The success of our analysis in this extremely complex environment with high simulation costs makes us optimistic that our methods can provide guidance in making mechanism design decisions in other challenging domains .The theoretical results confirm some intuitions behind the empirical mechanism design methods we have introduced , and increases our confidence that our framework can be effective in estimating the best mechanism parameter choice in relatively general settings .We thank Terence Kelly , Matthew Rudary , and Satinder Singh for helpful comments on earlier drafts of this work .This work was supported in part by NSF grant IIS-0205435 and the DARPA REAL strategic reasoning program .First , let us suppose that some function , f x defined on ai , bi , satisfy Lipschitz condition on ai , bi with Lipschitz constant Ai .Then the following claim holds : Claim : infx \u2208 ai , bi f x > 0.5 f ai + f bi \u2212 Ai bi \u2212 ai .To prove this claim , note that the intersection of lines at f ai and f bi with slopes \u2212 Ai and Ai respectively will determine the lower bound on the minimum of f x on ai , bi which is a lower bound on infimum of f x on ai , bj .The line at f ai is determined by f ai = \u2212 Aiai + cL and the line at f bi is determined by f bi = Aibi + cR .Thus , the intercepts are cL = f ai + Aiai and cR = f bi + Aibi respectively .Let x \u2217 be the point at which these lines intersect .Then ,Since we have a finite number of points in the data set for each \u03b8 , we can obtain the following expression :by subadditivity and the fact that a profile a is a Nash equilibrium if and only if ~ a = 0 .Putting everything together yields the desired result .First , we will need the following fact : Claim : Given a function fi x and a set X , | maxx \u2208 X f1 x \u2212To prove this claim , observe that | max x \u2208 X f1 x \u2212 max x \u2208 X f2 x | = maxx f1 x \u2212 maxx f2 x if maxx f1 x > maxx f2 x maxx f2 x \u2212 maxx f1 x if maxx f2 x > maxx f1 x In the first case ,Thus , the claim holds .By the Strong Law of Large Numbers , un , i a \u2192 ui a a.s. foror , equivalently 8 , for any \u03b1 > 0 and \u03b4 > 0 , there is M i , a > 0 such thatThus , by the claim , for any n \u2265 M ,Now , recall that ~ s = maxi maxai \u2208 Ai ui ai , s \u2212 i \u2212 ui s .By the claims above , maxai \u2208 Ai ui ai , s \u2212 i is uniformly continuous in s \u2212 i and ui s is uniformly continuous in s .Since the difference of two uniformly continuous functions is uniformly continuous , and since this continuity is preserved under maximum by our second claim , we have the desired result .Choose \u03b4 > 0 .First , we need to ascertain that the following claim holds : Claim : ~ \u00af = mins \u2208 S \\ N\u03b4 ~ s exists and ~ \u00af > 0 .Since N\u03b4 is an open subset of compact S , it follows that S \\ N\u03b4 is compact .As we had also proved in Lemma 5 that ~ s is continuous , existence follows from the Weierstrass theorem .That ~ \u00af > 0 is clear since ~ s = 0 if and only if s is a Nash equilibrium of \u0393 .Now , by Theorem 3 , for any \u03b1 > 0 there is M such thatwith probability at least 1 \u2212 \u03b1 .Note that since s \u2212 i a and s a are bounded between 0 and 1 , we were able to drop them from the expressions above to obtain a bound that will be valid independent of the particular choice of s. Furthermore , since the above result can be obtained for an arbitrary \u03b1 > 0 and \u03b4 > 0 , we have Pr limn \u2192 \u221e ~ n s = ~ s = 1 uniformly on S.We prove the result using uniform continuity of ui s and preservation of continuity under maximum .Claim : A function f : Rk \u2192 R defined by f t = Eki = 1 ziti , where zi are constants in R , is uniformly continuous in t .The claim follows because | f t \u2212 f t ~ | = | Eki = 1 zi ti \u2212 t ~ i | \u2264 Pk i = 1 | zi | | ti \u2212 t ~ i | .An immediate result of this for our purposes is that ui s is uniformly continuous in s and ui ai , s \u2212 i is uniformly continuous in s \u2212 i. Claim : Let f a , b be uniformly continuous in b \u2208 B for every a \u2208 A , with | A | < \u221e .Then V b = maxa \u2208 A f a , b is uniformly continuous in b. To show this , take \u03b3 > 0 and let b , b ~ \u2208 B such that ~ b \u2212 b ~ ~ < \u03b4 a \u21d2 | f a , b \u2212 f a , b ~ | < \u03b3 .Now take \u03b4 = mina \u2208 A \u03b4 a .Since this holds for an arbitrary \u03b1 > 0 and \u03b4 > 0 , the desired result follows .Fix \u03b8 and choose \u03b4 > 0 .Since W s , \u03b8 is continuous at s \u2217 \u03b8 , given ~ > 0 there is \u03b4 > 0 such that for every s ~ that is within \u03b4 of s \u2217 \u03b8 , | W s ~ , \u03b8 \u2212 W s \u2217 \u03b8 , \u03b8 | < ~ .By Theorem 6 , we can find M \u03b8 large enough such that all s ~ \u2208 Nn are within \u03b4 of s \u2217 \u03b8 for all n \u2265 M \u03b8 with probability 1 .Consequently , for any ~ > 0 we can find M \u03b8 large enough such that with probability 1 we have supn \u2265 M \u03b8 sups ~ \u2208 Nn | W s ~ , \u03b8 \u2212 W s \u2217 \u03b8 , \u03b8 | < ~ .Let us assume without loss of generality that there is a unique optimal choice of \u03b8 .Now , since the set \u0398 is finite , there is also the `` second-best '' choice of \u03b8 if there is only one \u03b8 \u2208 \u0398 this discussion is moot anyway :Then if we let ~ < \u2206 / 2 and let M = max\u03b8 \u2208 \u0398 M \u03b8 , where each M \u03b8 is large enough such that supn \u2265 M \u03b8 sups ~ \u2208 Nn | W s ~ , \u03b8 \u2212 W s \u2217 \u03b8 , \u03b8 | < ~ a.s. , the optimal choice of \u03b8 based on any empirical equilibrium will be \u03b8 \u2217 with probability 1 .Thus , in particular , given any probability distribution over empirical equilibria , the best choice of \u03b8 will be \u03b8 \u2217 with probability 1 similarly , if we take supremum or infimum of W Nn \u03b8 , \u03b8 over the set of empirical equilibria in constructing the objective function .", "related work": "The mechanism design literature in Economics has typically explored existence of a mechanism that implements a social choice function in equilibrium 10 .Additionally , there is an extensive literature on optimal auction design 10 , of which the work by Roger Myerson 11 is , perhaps , the most relevant .In much of this work , analytical results are presented with respect to specific utility functions and accounting for constraints such as incentive compatibility and individual rationality .Several related approaches to search for the best mechanism exist in the Computer Science literature .Conitzer and Sandholm 6 developed a search algorithm when all the relevant game parameters are common knowledge .When payoff functions of players are unknown , a search using simulations has been explored as an alternative .One approach in that direction , taken in 4 and 15 , is to co-evolve the mechanism parameter and agent strategies , using some notion of social utility and agent payoffs as fitness criteria .An alternative to co-evolution explored in 16 was to optimize a well-defined welfare function of the designer using genetic programming .In this work the authors used a common learning strategy for all agents and defined an outcome of a game induced by a mechanism parameter as the outcome of joint agent learning .Most recently , Phelps et al. 14 compared two mechanisms based on expected social utility with expectation taken over an empirical distribution of equilibria in games defined by heuristic strategies , as in 18 ."}