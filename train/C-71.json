{"reader_keywords": ["sensor-grouping", "point-distribution index", "wireless sensor network", "honeycomb structure", "surveillance", "redundancy", "fault tolerance", "node-deduction process", "incremental coverage quality algorithm", "sleeping configuration protocol"], "reader_keywords_stem": ["sensor-group", "point-distribut index", "wireless sensor network", "honeycomb structur", "surveil", "redund", "fault toler", "node-deduct process", "increment coverag qualiti algorithm", "sleep configur protocol"], "introduction": "A wireless sensor network WSN consists of a large number of in-situ battery-powered sensor nodes .A WSN can collect the data about physical phenomena of interest 1 .There are many potential applications of WSNs , including environmental monitoring and surveillance , etc. 1 11 .In many application scenarios , WSNs are employed to conduct surveillance tasks in adverse , or even worse , in hostile working environments .One major problem caused is that sensor nodes are subjected to failures .Therefore , fault tolerance of a WSN is critical .One way to achieve fault tolerance is that a WSN should contain a large number of redundant nodes in order to tolerate node failures .It is vital to provide a mechanism that redundant nodes can be working in sleeping mode i.e. , major power-consuming units such as the transceiver of a redundant sensor node can be shut off to save energy , and thus to prolong the network lifetime .Redundancy should be exploited as much as possible for the set of sensors that are currently taking charge in the surveillance work of the network area 6 .We find that the minimum distance between each pair of points normalized by the average distance between each pair of points serves as a good index to evaluate the distribution of the points .We call this index , denoted by t , the normalized minimum distance .If points are moveable , we find that maximizing t results in a honeycomb structure .The honeycomb structure poses that the coverage efficiency is the best if each point represents a sensor node that is providing surveillance work .Employing t in coverage-related problems is thus deemed promising .This enlightens us that maximizing t is a good approach to select a set of sensors that are currently taking charge in the surveillance work of the network area .To explore the effectiveness of employing t in coverage-related problems , we formulate a sensorgrouping problem for high-redundancy WSNs .An algorithm called Maximizing-t Node-Deduction MIND is proposed in which redundant sensor nodes are removed to obtain a large t for each set of sensors that are currently taking charge in the surveillance work of the network area .We also introduce another greedy solution called Incremental Coverage Quality Algorithm ICQA for this problem , which serves as a benchmark to evaluate MIND .The main contribution of this paper is twofold .First , we introduce a novel index t for evaluation of point-distribution .We show that maximizing t of a WSN results in low redundancy of the network .Second , we formulate a general sensor-grouping problem for WSNs and provide a general sensing model .With the MIND algorithm we show that locally maximizing t among each sensor node and its neighbors is a good approach to solve this problem .This demonstrates a good application of employing t in coveragerelated problems .The rest of the paper is organized as follows .In Section 2 , we introduce our point-distribution index t .We survey related work and formulate a sensor-grouping problem together with a general sensing model in Section 3 .Section 4 investigates the application of t in this grouping problem .We propose MIND for this problemand introduce ICQA as a benchmark .In Section 5 , we present our simulation results in which MIND and ICQA are compared .Section 6 provides conclusion remarks .", "title": "A Point-Distribution Index and Its Application to Sensor-Grouping in Wireless Sensor Networks", "author_keywords_stem": ["wireless sensor network", "honeycomb structure", "point-distribution index", "sensor coverage", "sensor group"], "abstract": "We propose t , a novel index for evaluation of point-distribution .t is the minimum distance between each pair of points normalized by the average distance between each pair of points .We find that a set of points that achieve a maximum value of t result in a honeycomb structure .We propose that t can serve as a good index to evaluate the distribution of the points , which can be employed in coverage-related problems in wireless sensor networks WSNs .To validate this idea , we formulate a general sensorgrouping problem for WSNs and provide a general sensing model .We show that locally maximizing t at sensor nodes is a good approach to solve this problem with an algorithm called Maximizingt Node-Deduction MIND .Simulation results verify that MIND outperforms a greedy algorithm that exploits sensor-redundancy we design .This demonstrates a good application of employing t in coverage-related problems for WSNs .", "id": "C-71", "combined_keywords_stem": ["sensor-group", "point-distribut index", "wireless sensor network", "honeycomb structur", "surveil", "redund", "fault toler", "node-deduct process", "increment coverag qualiti algorithm", "sleep configur protocol", "sensor coverag", "sensor group"], "evaluation": "To evaluate the effectiveness of employing t in sensor-grouping problem , we build simulation surveillance networks .We employ MIND and ICQA to group the in-network sensor nodes .We compare the grouping results with respect to how many groups both algorithms find and how the performance of the resulting groups are .For evaluating the coverage quality of the sensing area of a node , we divide the sensing area of a node into several regions and regard the coverage quality of the central point in each region as a representative of the coverage quality of the region .This is a numerical approximation .Larger number of such regions results in better approximation .As sensor nodes are with low computational capacity , there is a tradeoff between the number of such regions and the precision of the resulting coverage quality of the sensing area of a node .In our simulation study , we set this number 12 .For evaluating the improvement of coverage quality in ICQA , we sum up all the improvements at each region-center as the total improvement .We set the total in-network node number to different values and let the networks perform MIND and ICQA .For each n , simulations run with several random seeds to generate different networks .Results are averaged .Figure 2 shows the group numbers found in networks with different n 's .We can see that MIND always outperforms ICQA in terms of the number of groups formed .Obviously , the larger the number of groups can be formed , the more the redundancy of each group is exploited .This output shows that an approach like MIND that aim to maximize t of the resulting topology can exploits redundancy well .As an example , in case that n = 1500 , the results of five networks are listed in Table 2 .The difference between the average t of the groups in each network shows that groups formed by MIND result in topologies with larger t 's .It demonstrates that t is good indicator of redundancy in different networks .Although MIND forms more groups than ICQA does , which implies longer lifetime of the networks , another importance consideration is how these groups formed by MIND and ICQA perform .We let 10000 events randomly occur in the network area except the margin .We compare how many events happen at the locations where the quality is less than the requirement s = 0.6 when each resulting group is conducting surveillance work We call the number of such events the failure number of group .Figure 3 shows the average failure numbers of the resulting groups when different node numbers are set .We can see that the groups formed by MIND outperform those formed by ICQA because the groups formed by MIND result in lower failure numbers .This further demonstrates that MIND is a good approach for sensor-grouping problem .", "combined_keywords": ["sensor-grouping", "point-distribution index", "wireless sensor network", "honeycomb structure", "surveillance", "redundancy", "fault tolerance", "node-deduction process", "incremental coverage quality algorithm", "sleeping configuration protocol", "sensor coverage", "sensor group"], "author_keywords": ["wireless sensor network", "honeycomb structure", "point-distribution index", "sensor coverage", "sensor group"], "method": "Suppose there are n points in a Euclidean space \u2126 .The coordinates of these points are denoted by xi i = 1 , ... , n .It may be necessary to evaluate how the distribution of these points is .There are many metrics to achieve this goal .For example , the Mean Square Error from these points to their mean value can be employed to calculate how these points deviate from their mean i.e. , their central .In resource-sharing evaluation , the Global Fairness Index GFI is often employed to measure how even the resource distributes among these points 8 , when xi represents the amount of resource that belong to point i .In WSNs , GFI is usually used to calculate how even the remaining energy of sensor nodes is .When n is larger than 2 and the points do not all overlap That points all overlap means xi = xj , \u2200 i , j = 1 , 2 , ... , n .We propose a novel index called the normalized minimum distance , namely \u03b9 , to evaluate the distribution of the points .\u03b9 is the minimum distancewhere | | xi \u2212 xj | | denotes the Euclidean distance between point i and point j in \u2126 , the min \u00b7 function calculates the minimum distance between each pair of points , and \u00b5 is the average distance between each pair of points , which is :\u03b9 measures how well the points separate from one another .Obviously , \u03b9 is in interval 0 , 1 .\u03b9 is equal to 1 if and only if n is equal to 3 and these three points forms an equilateral triangle .\u03b9 is equal to zero if any two points overlap .\u03b9 is a very interesting value of a set of points .If we consider each xi \u2200 i = 1 , ... , n is a variable in \u2126 , how these n points would look like if \u03b9 is maximized ?An algorithm is implemented to generate the topology in which \u03b9 is locally maximized The algorithm can be found in 19 .We consider a 2-dimensional space .We select n = 10 , 20 , 30 , ... , 100 and perform this algorithm .In order to avoid that the algorithm converge to local optimum , we select different random seeds to generate the initial points for 1000 time and obtain the best one that results in the largest \u03b9 when the algorithm converges .Figure 1 demonstrates what the resulting topology looks like when n = 20 as an example .Suppose each point represents a sensor node .If the sensor coverage model is the Boolean coverage model 15 17 18 14 and the coverage radius of each node is the same .It is exciting to see that this topology results in lowest redundancy because the Vonoroi diagram 2 formed by these nodes A Vonoroi diagram formed by a set of nodes partitions a space into a set of convex polygons such that points inside a polygon are closest to only one particular node is a honeycomb-like structure1 .This enlightens us that \u03b9 may be employed to solve problems related to sensor-coverage of an area .In WSNs , it is desirablethat the active sensor nodes that are performing surveillance task should separate from one another .Under the constraint that the sensing area should be covered , the more each node separates from the others , the less the redundancy of the coverage is .\u03b9 indicates the quality of such separation .It should be useful for approaches on sensor-coverage related problems .In our following discussions , we will show the effectiveness of employing \u03b9 in sensor-grouping problem .In many application scenarios , to achieve fault tolerance , a WSN contains a large number of redundant nodes in order to tolerate node failures .A node sleeping-working schedule scheme is therefore highly desired to exploit the redundancy of working sensors and let as many nodes as possible sleep .Much work in the literature is on this issue 6 .Yan et al introduced a differentiated service in which a sensor node finds out its responsible working duration with cooperation of its neighbors to ensure the coverage of sampled points 17 .Ye et al developed PEAS in which sensor nodes wake up randomly over time , probe their neighboring nodes , and decide whether they should begin to take charge of surveillance work 18 .Xing et al exploited a probabilistic distributed detection model with a protocol called Coordinating Grid Co-Grid 16 .Wang et al designed an approach called Coverage Configuration Protocol CCP which introduced the notion that the coverage degree of intersection-points of the neighboring nodes ' sensing-perimeters indicates the coverage of a convex region 15 .In our recent work 7 , we also provided a sleeping configuration protocol , namely SSCP , in which sleeping eligibility of a sensor node is determined by a local Voronoi diagram .SSCP can provide different levels of redundancy to maintain different requirements of fault tolerance .The major feature of the aforementioned protocols is that they employ online distributed and localized algorithms in which a sensor node determines its sleeping eligibility and/or sleeping time based on the coverage requirement of its sensing area with some information provided by its neighbors .Another major approach for sensor node sleeping-working scheduling issue is to group sensor nodes .Sensor nodes in a network are divided into several disjoint sets .Each set of sensor nodes are able to maintain the required area surveillance work .The sensor nodes are scheduled according to which set they belong to .These sets work successively .Only one set of sensor nodes work at any time .We call the issue sensor-grouping problem .The major advantage of this approach is that it avoids the overhead caused by the processes of coordination of sensor nodes to make decision on whether a sensor node is a candidate to sleep orwork and how long it should sleep or work .Such processes should be performed from time to time during the lifetime of a network in many online distributed and localized algorithms .The large overhead caused by such processes is the main drawback of the online distributed and localized algorithms .On the contrary , roughly speaking , this approach groups sensor nodes in one time and schedules when each set of sensor nodes should be on duty .It does not require frequent decision-making on working/sleeping eligibility 2 .In 13 by Slijepcevic et al , the sensing area is divided into regions .Sensor nodes are grouped with the most-constrained leastconstraining algorithm .It is a greedy algorithm in which the priority of selecting a given sensor is determined by how many uncovered regions this sensor covers and the redundancy caused by this sensor .In 5 by Cardei et al , disjoint sensor sets are modeled as disjoint dominating sets .Although maximum dominating sets computation is NP-complete , the authors proposed a graphcoloring based algorithm .Cardei et al also studied similar problem in the domain of covering target points in 4 .The NP-completeness of the problem is proved and a heuristic that computes the sets are proposed .These algorithms are centralized solutions of sensorgrouping problem .However , global information e.g. , the location of each in-network sensor node of a large scale WSN is also very expensive to obtained online .Also it is usually infeasible to obtain such information before sensor nodes are deployed .For example , sensor nodes are usually deployed in a random manner and the location of each in-network sensor node is determined only after a node is deployed .The solution of sensor-grouping problem should only base on locally obtainable information of a sensor node .That is to say , nodes should determine which group they should join in a fully distributed way .Here locally obtainable information refers to a node 's local information and the information that can be directly obtained from its adjacent nodes , i.e. , nodes within its communication range .In Subsection 3.1 , we provide a general problem formulation of the sensor-grouping problem .Distributed-solution requirement is formulated in this problem .It is followed by discussion in Subsection 3.2 on a general sensing model , which serves as a given condition of the sensor-grouping problem formulation .To facilitate our discussions , the notations in our following discussions are described as follows .We assume that each sensor node can know its approximate physical location .The approximate location information is obtainable if each sensor node carries a GPS receiver or if some localization algorithms are employed e.g. , 3 .2Note that if some nodes die , a re-grouping process might also be performed to exploit the remaining nodes in a set of sensor nodes .How to provide this mechanism is beyond the scope of this paper and yet to be explored .In this formulation , we call sensor nodes within a circular area centered at a sensor node i with a radius equal to 2 \u00b7 R the sensing neighbors of node i .This is because sensors nodes in this area , together with node i , may be cooperative to ensure the coverage of a point inside node i 's sensing area .We assume that the communication range of a sensor node is larger than 2 \u00b7 R , which is also a general assumption in work that addresses sensor-coverage related problems .That is to say , the first given condition in Problem 1 is the information that can be obtained directly from a node 's adjacent nodes .It is therefore locally obtainable information .The last two given conditions in this problem formulation can be programmed into a node before it is deployed or by a node-programming protocol e.g. , 9 during network runtime .Therefore , the given conditions can all be easily obtained by a sensor-grouping scheme with fully distributed implementation .We reify this problem with a realistic sensing model in next subsection .As WSNs are usually employed to monitor possible events in a given area , it is therefore a design requirement that an event occurring in the network area must/may be successfully detected by sensors .This issue is usually formulated as how to ensure that an event signal omitted in an arbitrary point in the network area can be detected by sensor nodes .Obviously , a sensing model is required to address this problem so that how a point in the network area is covered can be modeled and quantified .Thus the coverage quality of a WSN can be evaluated .Different applications of WSNs employ different types of sensors , which surely have widely different theoretical and physical characteristics .Therefore , to fulfill different application requirements , different sensing models should be constructed based on the characteristics of the sensors employed .A simple theoretical sensing model is the Boolean sensing model 15 18 17 14 .Boolean sensing model assumes that a sensor node can always detect an event occurring in its responsible sensing area .But most sensors detect events according to the signal strength sensed .Event signals usually fade in relation to the physical distance between an event and the sensor .The larger the distance , the weaker the event signals that can be sensed by the sensor , which results in a reduction of the probability that the event can be successfully detected by the sensor .As in WSNs , event signals are usually electromagnetic , acoustic , or photic signals , they fade exponentially with the increasing oftheir transmit distance .Specifically , the signal strength E d of an event that is received by a sensor node satisfies :where d is the physical distance from the event to the sensor node ; \u03b1 is related to the signal strength omitted by the event ; and \u03b2 is signal fading factor which is typically a positive number larger than or equal to 2 .Usually , \u03b1 and \u03b2 are considered as constants .Based on this notion , to be more reasonable , researchers propose collaborative sensing model to capture application requirements : Area coverage can be maintained by a set of collaborative sensor nodes : For a point with physical location L , the point is considered covered by the collaboration of i sensors denoted by k1 , ... , ki if and only if the following two equations holds 7 10 12 .C L is regarded as the coverage quality of location L in the network area 7 10 12 .However , we notice that defining the sensibility as the sum of the sensed signal strength by each collaborative sensor implies a very special application : Applications must employ the sum of the signal strength to achieve decision-making .To capture generally realistic application requirement , we modify the definition described in Equation 5 .The model we adopt in this paper is described in details as follows .We consider the probability P L , kj that an event located at L can be detected by sensor kj is related to the signal strength sensed by kj .Formally ,where \u03b3 is a constant and \u03b4 = \u03b3\u03b1 is a constant too .~ normalizes the distance to a proper scale and the `` +1 '' item is to avoid infinite value of P L , kj .The probability that an event located at L can be detected by any collaborative sensors that satisfied Equation 4 is :As the detection probability P L reasonably determines how an event occurring at location L can be detected by the networks , it is a good measure of the coverage quality of location L in a WSN .Specifically , Equation 5 is modified to :To sum it up , we consider a point at location L is covered if Equation 4 and 8 hold .Before we process to introduce algorithms to solve the sensor grouping problem , let us define the margin denoted by \u03b8 of an area \u03c6 monitored by the network as the band-like marginal area of \u03c6 and all the points on the outer perimeter of \u03b8 is \u03c1 distance away from all the points on the inner perimeter of \u03b8 .\u03c1 is called the margin length .In a practical network , sensor nodes are usually evenly deployed in the network area .Obviously , the number of sensor nodes that can sense an event occurring in the margin of the network is smaller than the number of sensor nodes that can sense an event occurring in other area of the network .Based on this consideration , in our algorithm design , we ensure the coverage quality of the network area except the margin .The information on \u03c6 and \u03c1 is networkbased .Each in-network sensor node can be pre-programmed or on-line informed about \u03c6 and \u03c1 , and thus calculate whether a point in its sensing area is in the margin or not .The node-deduction process of our Maximizing-\u03b9 Node-Deduction Algorithm MIND is simple .A node i greedily maximizes \u03b9 of the sub-network composed by itself , its ungrouped sensing neighbors , and the neighbors that are in the same group of itself .Under the constraint that the coverage quality of its sensing area should be ensured , node i deletes nodes in this sub-network one by one .The candidate to be pruned satisfies that :A candidate is deleted if the deletion of the candidate results in largest \u03b9 of the sub-network compared to the deletion of other candidates .This node-deduction process continues until no candidate can be found .Then all the ungrouped sensing neighbors that are not deleted are grouped into the same group of node i .We call the sensing neighbors that are in the same group of node i the group sensing neighbors of node i .We then call node i a finished node , meaning that it has finished the above procedure and the sensing area of the node is covered .Those nodes that have not yet finished this procedure are called unfinished nodes .The above procedure initiates at a random-selected node that is not in the margin .The node is grouped to the first group .It calculates the resulting group sensing neighbors of it based on the above procedure .It informs these group sensing neighbors that they are selected in the group .Then it hands over the above procedure to an unfinished group sensing neighbors that is the farthest from itself .This group sensing neighbor continues this procedure until no unfinished neighbor can be found .Then the first group is formed Algorithmic description of this procedure can be found at 19 .After a group is formed , another random-selected ungrouped node begins to group itself to the second group and initiates the above procedure .In this way , groups are formed one by one .When a node that involves in this algorithm found out that the coverage quality if its sensing area , except what overlaps the network margin , can not be ensured even if all its ungrouped sensing neighbors are grouped into the same group as itself , the algorithm stops .MIND is based on locally obtainable information of sensor nodes .It is a distributed algorithm that serves as an approximate solution of Problem 1 .To evaluate the effectiveness of introducing \u03b9 in the sensor-group problem , another algorithm for sensor-group problem called Incremental Coverage Quality Algorithm ICQA is designed .Our aimis to evaluate how an idea , i.e. , MIND , based on locally maximize t performs .In ICQA , a node-selecting process is as follows .A node i greedily selects an ungrouped sensing neighbor in the same group as itself one by one , and informs the neighbor it is selected in the group .The criterion is : \u2022 The selected neighbor is responsible to provide surveillance work for some uncovered parts of node i 's sensing area .i.e. , the coverage quality requirement of the parts is not fulfilled if this neighbor is not selected .\u2022 The selected neighbor results in highest improvement of the coverage quality of the neighbor 's sensing area .The improvement of the coverage quality , mathematically , should be the integral of the the improvements of all points inside the neighbor 's sensing area .A numerical approximation is employed to calculate this improvement .Details are presented in our simulation study .This node-selecting process continues until the sensing area of node i is entirely covered .In this way , node i 's group sensing neighbors are found .The above procedure is handed over as what MIND does and new groups are thus formed one by one .And the condition that ICQA stops is the same as MIND .ICQA is also based on locally obtainable information of sensor nodes .ICQA is also a distributed algorithm that serves as an approximate solution of Problem 1 .", "conclusions": "This paper proposes t , a novel index for evaluation of pointdistribution .t is the minimum distance between each pair of points normalized by the average distance between each pair of points .We find that a set of points that achieve a maximum value of t result in a honeycomb structure .We propose that t can serve as a good index to evaluate the distribution of the points , which can be employed in coverage-related problems in wireless sensor networks WSNs .We set out to validate this idea by employing t to a sensorgrouping problem .We formulate a general sensor-grouping problem for WSNs and provide a general sensing model .With an algorithm called Maximizing-t Node-Deduction MIND , we show that maximizing t at sensor nodes is a good approach to solve this problem .Simulation results verify that MIND outperforms a greedy algorithm that exploits sensor-redundancy we design in terms of the number and the performance of the groups formed .This demonstrates a good application of employing t in coverage-related problems ."}