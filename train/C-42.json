{"reader_keywords": ["ensemble kalman filter", "datum assimilation methodology", "hydrocarbon reservoir simulation", "energy exploration", "tigre grid computing environment", "grid computing", "cyberinfrastructure development project", "high performance computing", "tigre grid middleware", "strategic application area", "gridway metascheduler", "pooling license", "grid-enabling"], "reader_keywords_stem": ["ensembl kalman filter", "data assimil methodolog", "hydrocarbon reservoir simul", "energi explor", "tigr grid comput environ", "grid comput", "cyberinfrastructur develop project", "high perform comput", "tigr grid middlewar", "strateg applic area", "gridwai metaschedul", "pool licens", "grid-enabl"], "introduction": "Grid computing 1 is an emerging `` collaborative '' computing paradigm to extend institution/organization specific high performance computing HPC capabilities greatly beyond local resources .Its importance stems from the fact that ground breaking research in strategic application areas such as bioscience and medicine , energy exploration and environmental modeling involve strong interdisciplinary components and often require intercampus collaborations and computational capabilities beyond institutional limitations .The Texas Internet Grid for Research and Education TIGRE 2,3 is a state funded cyberinfrastructure development project carried out by five Rice , A&M , TTU , UH and UT Austin major university systems collectively called TIGRE Institutions .The purpose of TIGRE is to create a higher education Grid to sustain and extend research and educational opportunities across Texas .TIGRE is a project of the High Performance Computing across Texas HiPCAT 4 consortium .The goal of HiPCAT is to support advanced computational technologies to enhance research , development , and educational activities .The primary goal of TIGRE is to design and deploy state-of-the-art Grid middleware that enables integration of computing systems , storage systems and databases , visualization laboratories and displays , and even instruments and sensors across Texas .The secondary goal is to demonstrate the TIGRE capabilities to enhance research and educational opportunities in strategic application areas of interest to the State of Texas .These are bioscience and medicine , energy exploration and air quality modeling .Vision of the TIGRE project is to foster interdisciplinary and intercampus collaborations , identify novel approaches to extend academic-government-private partnerships , and become a competitive model for external funding opportunities .The overall goal of TIGRE is to support local , campus and regional user interests and offer avenues to connect with national Grid projects such as Open Science Grid 5 , and TeraGrid 6 .Within the energy exploration strategic application area , we have Grid-enabled the ensemble Kalman Filter EnKF 7 approach for data assimilation in reservoir modeling and demonstrated the extensibility of the application using the TIGRE environment and the GridWay 8 metascheduler .Section 2 provides an overview of the TIGRE environment and capabilities .Application description and the need for Grid-enabling EnKF methodology is provided in Section 3 .The implementation details and merits of our approach are discussed in Section 4 .Conclusions are provided in Section 5 .Finally , observations and lessons learned are documented in Section 6 .", "title": "Demonstration of Grid-Enabled Ensemble Kalman Filter Data Assimilation Methodology for Reservoir Characterization", "author_keywords_stem": ["reservoir model", "energy exploration", "enkf", "tigre"], "abstract": "Ensemble Kalman filter data assimilation methodology is a popular approach for hydrocarbon reservoir simulations in energy exploration .In this approach , an ensemble of geological models and production data of oil fields is used to forecast the dynamic response of oil wells .The Schlumberger ECLIPSE software is used for these simulations .Since models in the ensemble do not communicate , message-passing implementation is a good choice .Each model checks out an ECLIPSE license and therefore , parallelizability of reservoir simulations depends on the number licenses available .We have Grid-enabled the ensemble Kalman filter data assimilation methodology for the TIGRE Grid computing environment .By pooling the licenses and computing resources across the collaborating institutions using GridWay metascheduler and TIGRE environment , the computational accuracy can be increased while reducing the simulation runtime .In this paper , we provide an account of our efforts in Gridenabling the ensemble Kalman Filter data assimilation methodology .Potential benefits of this approach , observations and lessons learned will be discussed .", "id": "C-42", "combined_keywords_stem": ["ensembl kalman filter", "data assimil methodolog", "hydrocarbon reservoir simul", "energi explor", "tigr grid comput environ", "grid comput", "cyberinfrastructur develop project", "high perform comput", "tigr grid middlewar", "strateg applic area", "gridwai metaschedul", "pool licens", "grid-enabl", "reservoir model", "enkf", "tigr"], "evaluation": "The Grid-enabling efforts for EnKF application have provided ample opportunities to gather insights on the visibility and promise of Grid computing environments for application development and support .The main issues are industry standard data security and QoS comparable to cluster computing .Since the reservoir modeling research involves proprietary data of the field , we had to invest substantial efforts initially in educating the application researchers on the ability of Grid services in supporting the industry standard data security through role and privilege-based access using X. 509 standard .With respect to QoS , application researchers expect `` cluster '' level QoS with Grid environments .Also , there is a steep learning curve in Grid computing compared to the conventional `` cluster '' computing .Since Grid computing is still an `` emerging '' technology , and it spans over several administrative domains , Grid computing is still premature especially in terms of the level of QoS although , it offers better data security standards compared to commodity clusters .It is our observation that training and outreach programs that compare and contrast the Grid and cluster computing environments would be a suitable approach for enhancing user participation in Grid computing .This approach also helps users to match their applications and abilities Grids can offer .In summary , our efforts through TIGRE in Grid-enabling the EnKF data assimilation methodology showed substantial promise in engaging Petroleum Engineering researchers through intercampus collaborations .Efforts are under way to involve more schools in this effort .These efforts may result in increased collaborative research , educational opportunities , and workforce development through graduate/faculty research programs across TIGRE Institutions .", "combined_keywords": ["ensemble kalman filter", "datum assimilation methodology", "hydrocarbon reservoir simulation", "energy exploration", "tigre grid computing environment", "grid computing", "cyberinfrastructure development project", "high performance computing", "tigre grid middleware", "strategic application area", "gridway metascheduler", "pooling license", "grid-enabling", "reservoir model", "enkf", "tigre"], "author_keywords": ["reservoir model", "energy exploration", "enkf", "tigre"], "method": "The TIGRE Grid middleware consists of minimal set of components derived from a subset of the Virtual Data Toolkit VDT 9 which supports a variety of operating systems .The purpose of choosing a minimal software stack is to support applications at hand , and to simplify installation and distribution of client/server stacks across TIGRE sites .Additional components will be added as they become necessary .The PacMan 10 packaging and distribution mechanism is employed for TIGRE client/server installation and management .The PacMan distribution mechanism involves retrieval , installation , and often configuration of the packaged software .This approach allows the clients to keep current , consistent versions of TIGRE software .It also helps TIGRE sites to install the needed components on resources distributed throughout the participating sites .The TIGRE client/server stack consists of an authentication and authorization layer , Globus GRAM4-based job submission via web services pre-web services installations are available up on request .The tools for handling Grid proxy generation , Grid-enabled file transfer and Grid-enabled remote login are supported .The pertinent details of TIGRE services and tools for job scheduling and management are provided below .The TIGRE security infrastructure includes a certificate authority CA accredited by the International Grid Trust Federation IGTF for issuing X. 509 user and resource Grid certificates 11 .The Texas Advanced Computing Center TACC , University of Texas at Austin is the TIGRE 's shared CA .The TIGRE Institutions serve as Registration Authorities RA for their respective local user base .For up-to-date information on securing user and resource certificates and their installation instructions see ref 2 .The users and hosts on TIGRE are identified by their distinguished name DN in their X. 509 certificate provided by the CA .A native Grid-mapfile that contains a list of authorized DNs is used to authenticate and authorize user job scheduling and management on TIGRE site resources .At Texas Tech University , the users are dynamically allocated one of the many generic pool accounts .This is accomplished through the Grid User Management System GUMS 12 .The TIGRE environment supports GRAM4-based job submission via web services .The job submission scripts are generated using XML .The web services GRAM translates the XML scripts into target cluster specific batch schedulers such as LSF , PBS , or SGE .The high bandwidth file transfer protocols such as GridFTP are utilized for staging files in and out of the target machine .The login to remote hosts for compilation and debugging is only through GSISSH service which requires resource authentication through X. 509 certificates .The authentication and authorization of Grid jobs are managed by issuing Grid certificates to both users and hosts .The certificate revocation lists CRL are updated on a daily basis to maintain high security standards of the TIGRE Grid services .The TIGRE portal 2 documentation area provides a quick start tutorial on running jobs on TIGRE .The metascheduler interoperates with the cluster level batch schedulers such as LSF , PBS in the overall Grid workflow management .In the present work , we have employed GridWay 8 metascheduler a Globus incubator project to schedule and manage jobs across TIGRE .The GridWay is a light-weight metascheduler that fully utilizes Globus functionalities .It is designed to provide efficient use of dynamic Grid resources by multiple users for Grid infrastructures built on top of Globus services .The TIGRE site administrator can control the resource sharing through a powerful built-in scheduler provided by GridWay or by extending GridWay 's external scheduling module to provide their own scheduling policies .Application users can write job descriptions using GridWay 's simple and direct job template format see Section 4 for details or standard Job Submission Description Language JSDL .See section 4 for implementation details .A TIGRE portal 2 was designed and deployed to interface users and resource providers .It was designed using GridPort 13 and is maintained by TACC .The TIGRE environment is supported by open source tools such as the Open Ticket Request System OTRS 14 for servicing trouble tickets , and MoinMoin 15 Wiki for TIGRE content and knowledge management for education , outreach and training .The links for OTRS and Wiki are consumed by the TIGRE portal 2 the gateway for users and resource providers .The TIGRE resource status and loads are monitored by the Grid Port Information Repository GPIR service of the GridPort toolkit 13 which interfaces with local cluster load monitoring service such as Ganglia .The GPIR utilizes `` cron '' jobs on each resource to gather site specific resource characteristics such as jobs that are running , queued and waiting for resource allocation .The main goal of hydrocarbon reservoir simulations is to forecast the production behavior of oil and gas field denoted as field hereafter for its development and optimal management .In reservoir modeling , the field is divided into several geological models as shown in Figure 1 .For accurate performance forecasting of the field , it is necessary to reconcile several geological models to the dynamic response of the field through history matching 16-20 .Figure 1 .Cross-sectional view of the Field .Vertical layers correspond to different geological models and the nails are oil wells whose historical information will be used for forecasting the production behavior .Figure Ref : http://faculty.smu.edu/zchen/research.html .The EnKF is a Monte Carlo method that works with an ensemble of reservoir models .This method utilizes crosscovariances 21 between the field measurements and the reservoir model parameters derived from several models to estimate prediction uncertainties .The geological model parameters in the ensemble are sequentially updated with a goal to minimize the prediction uncertainties .Historical production response of the field for over 50 years is used in these simulations .The main advantage of EnKF is that it can be readily linked to any reservoir simulator , and can assimilate latest production data without the need to re-run the simulator from initial conditions .Researchers in Texas are large subscribers of the Schlumberger ECLIPSE 22 package for reservoir simulations .In the reservoir modeling , each geological model checks out an ECLIPSE license .The simulation runtime of the EnKF methodology depends on the number of geological models used , number of ECLIPSE licenses available , production history of the field , and propagated uncertainties in history matching .The overall EnKF workflow is shown Figure 2 .At START , the master/control process EnKF main program reads the simulation configuration file for number N of models , and model-specific input files .Then , N working directories are created to store the output files .At the end of iteration , the master/control process collects the output files from N models and post processes crosscovariances 21 to estimate the prediction uncertainties .This information will be used to update models or input files for the next iteration .The simulation continues until the production histories are exhausted .Typical EnKF simulation with N = 50 and field histories of 50-60 years , in time steps ranging from three months to a year , takes about three weeks on a serial computing environment .In parallel computing environment , there is no interprocess communication between the geological models in the ensemble .However , at the end of each simulation time-step , model-specific output files are to be collected for analyzing cross covariances 21 and to prepare next set of input files .Therefore , master-slave model in messagepassing MPI environment is a suitable paradigm .In this approach , the geological models are treated as slaves and are distributed across the available processors .The masterprocess collects model-specific output files , analyzes and prepares next set of input files for the simulation .Since each geological model checks out an ECLIPSE license , parallelizability of the simulation depends on the number of licenses available .When the available number of licenses is less than the number of models in the ensemble , one or more of the nodes in the MPI group have to handle more than one model in a serial fashion and therefore , it takes longer to complete the simulation .A Petroleum Engineering Department usually procures 10-15 ECLIPSE licenses while at least ten-fold increase in the number of licenses would be necessary for industry standard simulations .The number of licenses can be increased by involving several Petroleum Engineering Departments that support ECLIPSE package .Since MPI does not scale very well for applications that involve remote compute clusters , and to get around the firewall issues with license servers across administrative domains , Grid-enabling the EnKF workflow seems to be necessary .With this motivation , we have implemented Grid-enabled EnKF workflow for the TIGRE environment and demonstrated parallelizability of the application across TIGRE using GridWay metascheduler .Further details are provided in the next section .To Grid-enable the EnKF approach , we have eliminated the MPI code for parallel processing and replaced with N single processor jobs or sub-jobs where , N is the number of geological models in the ensemble .These model-specific sub-jobs were distributed across TIGRE sites that support ECLIPSE package using the GridWay 8 metascheduler .For each sub-job , we have constructed a GridWay job template that specifies the executable , input and output files , and resource requirements .Since the TIGRE compute resources are not expected to change frequently , we have used static resource discovery policy for GridWay and the sub-jobs were scheduled dynamically across the TIGRE resources using GridWay .Figure 3 represents the sub-job template file for the GridWay metascheduler .In Figure 3 , REQUIREMENTS flag is set to choose the resources that satisfy the application requirements .In the case of EnKF application , for example , we need resources that support ECLIPSE package .ARGUMENTS flag specifies the model in the ensemble that will invoke ECLIPSE at a remote site .INPUT_FILES is prepared by the EnKF main program or master/control process and is transferred by GridWay to the remote site where it is untared and is prepared for execution .Finally , OUTPUT_FILES specifies the name and location where the output files are to be written .The command-line features of GridWay were used to collect and process the model-specific outputs to prepare new set of input files .This step mimics MPI process synchronization in master-slave model .At the end of each iteration , the compute resources and licenses are committed back to the pool .Table 1 shows the sub-jobs in TIGRE Grid via GridWay using `` gwps '' command and for clarity , only selected columns were shownJID is the job id and HOST corresponds to site specific cluster and its local batch scheduler .When a job is submitted to GridWay , it will go through a series of dispatch DM and execution EM states .For DM , the states include pend ing , prol og , wrap per , epil og , and done .DM = '' prol '' means the job has been scheduled to a resource and the remote working directory is in preparation .DM = '' warp '' implies that GridWay is executing the wrapper which in turn executes the application .DM = '' epil '' implies the job has finished running at the remote site and results are being transferred back to the GridWay server .Similarly , when EM = '' pend '' implies the job is waiting in the queue for resource and the job is running when EM = '' actv '' .For complete list of message flags and their descriptions , see the documentation in ref 8 .We have demonstrated the Grid-enabled EnKF runs using GridWay for TIGRE environment .The jobs are so chosen that the runtime does n't exceed more than a half hour .The simulation runs involved up to 20 jobs between A&M and TTU sites with TTU serving 10 licenses .For resource information , see Table I .One of the main advantages of Grid-enabled EnKF simulation is that both the resources and licenses are released back to the pool at the end of each simulation time step unlike in the case of MPI implementation where licenses and nodes are locked until the completion of entire simulation .However , the fact that each sub-job gets scheduled independently via GridWay could possibly incur another time delay caused by waiting in queue for execution in each simulation time step .Such delays are not expected in MPI implementation where the node is blocked for processing sub-jobs model-specific calculation until the end of the simulation .There are two main scenarios for comparing Grid and cluster computing approaches .Scenario I : The cluster is heavily loaded .The conceived average waiting time of job requesting large number of CPUs is usually longer than waiting time of jobs requesting single CPU .Therefore , overall waiting time could be shorter in Grid approach which requests single CPU for each sub-job many times compared to MPI implementation that requests large number of CPUs at a single time .It is apparent that Grid scheduling is beneficial especially when cluster is heavily loaded and requested number of CPUs for the MPI job is not readily available .Scenario II : The cluster is relatively less loaded or largely available .It appears the MPI implementation is favorable compared to the Grid scheduling .However , parallelizability of the EnKF application depends on the number of ECLIPSE licenses and ideally , the number of licenses should be equal to the number of models in the ensemble .Therefore , if a single institution does not have sufficient number of licenses , the cluster availability does n't help as much as it is expected .Since the collaborative environment such as TIGRE can address both compute and software resource requirements for the EnKF application , Grid-enabled approach is still advantageous over the conventional MPI implementation in any of the above scenarios .TIGRE is a higher education Grid development project and its purpose is to sustain and extend research and educational opportunities across Texas .Within the energy exploration application area , we have Grid-enabled the MPI implementation of the ensemble Kalman filter data assimilation methodology for reservoir characterization .This task was accomplished by removing MPI code for parallel processing and replacing with single processor jobs one for each geological model in the ensemble .These single processor jobs were scheduled across TIGRE via GridWay metascheduler .We have demonstrated that by pooling licenses across TIGRE sites , more geological models can be handled in parallel and therefore conceivably better simulation accuracy .This approach has several advantages over MPI implementation especially when a site specific cluster is heavily loaded and/or the number licenses required for the simulation is more than those available at a single site .Towards the future work , it would be interesting to compare the runtime between MPI , and Grid implementations for the EnKF application .This effort could shed light on quality of service QoS of Grid environments in comparison with cluster computing .Another aspect of interest in the near future would be managing both compute and license resources to address the job or processor to-license ratio management ."}