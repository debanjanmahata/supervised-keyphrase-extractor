{"reader_keywords": ["distributed computation", "immediate predecessor tracking", "common global memory", "message transfer delay", "vector clock", "tracking causality", "vector timestamp", "transitive reduction", "channel ordering property", "ipt protocol", "checkpointing problem", "relevant event", "immediate predecessor", "control information", "piggybacking"], "reader_keywords_stem": ["distribut comput", "immedi predecessor track", "common global memori", "messag transfer delai", "vector clock", "track causal", "vector timestamp", "transit reduct", "channel order properti", "ipt protocol", "checkpoint problem", "relev event", "immedi predecessor", "control inform", "piggyback"], "introduction": "A distributed computation consists of a set of processes that cooperate to achieve a common goal .A main characteristic of these computations lies in the fact that theprocesses do not share a common global memory , and communicate only by exchanging messages over a communication network .Moreover , message transfer delays are finite but unpredictable .This computation model defines what is known as the asynchronous distributed system model .It is particularly important as it includes systems that span large geographic areas , and systems that are subject to unpredictable loads .Consequently , the concepts , tools and mechanisms developed for asynchronous distributed systems reveal to be both important and general .Causality is a key concept to understand and master the behavior of asynchronous distributed systems 18 .More precisely , given two events e and f of a distributed computation , a crucial problem that has to be solved in a lot of distributed applications is to know whether they are causally related , i.e. , if the occurrence of one of them is a consequence of the occurrence of the other .The causal past of an event e is the set of events from which e is causally dependent .Events that are not causally dependent are said to be concurrent .Vector clocks 5 , 16 have been introduced to allow processes to track causality and concurrency between the events they produce .The timestamp of an event produced by a process is the current value of the vector clock of the corresponding process .In that way , by associating vector timestamps with events it becomes possible to safely decide whether two events are causally related or not .Usually , according to the problem he focuses on , a designer is interested only in a subset of the events produced by a distributed execution e.g. , only the checkpoint events are meaningful when one is interested in determining consistent global checkpoints 12 .It follows that detecting causal dependencies or concurrency on all the events of the distributed computation is not desirable in all applications 7 , 15 .In other words , among all the events that may occur in a distributed computation , only a subset of them are relevant .In this paper , we are interested in the restriction of the causality relation to the subset of events defined as being the relevant events of the computation .Being a strict partial order , the causality relation is transitive .As a consequence , among all the relevant events that causally precede a given relevant event e , only a subset are its immediate predecessors : those are the events f such that there is no relevant event on any causal path from f to e. Unfortunately , given only the vector timestamp associated with an event it is not possible to determine which events of its causal past are its immediate predecessors .This comes from the fact that the vector timestamp associated with e determines , for each process , the last relevant event belong210 ing to the causal past of e , but such an event is not necessarily an immediate predecessor of e. However , some applications 4 , 6 require to associate with each relevant event only the set of its immediate predecessors .Those applications are mainly related to the analysis of distributed computations .Some of those analyses require the construction of the lattice of consistent cuts produced by the computation 15 , 16 .It is shown in 4 that the tracking of immediate predecessors allows an efficient on the fly construction of this lattice .More generally , these applications are interested in the very structure of the causal past .In this context , the determination of the immediate predecessors becomes a major issue 6 .Additionally , in some circumstances , this determination has to satisfy behavior constraints .If the communication pattern of the distributed computation can not be modified , the determination has to be done without adding control messages .When the immediate predecessors are used to monitor the computation , it has to be done on the fly .We call Immediate Predecessor Tracking IPT the problem that consists in determining on the fly and without additional messages the immediate predecessors of relevant events .This problem consists actually in determining the transitive reduction Hasse diagram of the causality graph generated by the relevant events of the computation .Solving this problem requires tracking causality , hence using vector clocks .Previous works have addressed the efficient implementation of vector clocks to track causal dependence on relevant events .Their aim was to reduce the size of timestamps attached to messages .An efficient vector clock implementation suited to systems with FIFO channels is proposed in 19 .Another efficient implementation that does not depend on channel ordering property is described in 11 .The notion of causal barrier is introduced in 2 , 17 to reduce the size of control information required to implement causal multicast .However , none of these papers considers the IPT problem .This problem has been addressed for the first time to our knowledge in 4 , 6 where an IPT protocol is described , but without correctness proof .Moreover , in this protocol , timestamps attached to messages are of size n .This raises the following question which , to our knowledge , has never been answered : `` Are there efficient vector clock implementation techniques that are suitable for the IPT problem ? ''.This paper has three main contributions : 1 a positive answer to the previous open question , 2 the design of a family of efficient IPT protocols , and 3 a formal correctness proof of the associated protocols .From a methodological point of view the paper uses a top-down approach .It states abstract properties from which more concrete properties and protocols are derived .The family of IPT protocols is defined by a general condition that allows application messages to piggyback control information whose size can be smaller than the system size i.e. , smaller than the number of processes composing the system .In that sense , this family defines low cost IPT protocols when we consider the message size .In addition to efficiency , the proposed approach has an interesting design property .Namely , the family is incrementally built in three steps .The basic vector clock protocol is first enriched by adding to each process a boolean vector whose management allows the processes to track the immediate predecessor events .Then , a general condition is stated to reduce the size of the control information carried by messages .Finally , according to the way this condition is implemented , three IPT protocols are obtained .The paper is composed of seven sections .Sections 2 introduces the computation model , vector clocks and the notion of relevant events .Section 3 presents the first step of the construction that results in an IPT protocol in which each message carries a vector clock and a boolean array , both of size n the number of processes .Section 4 improves this protocol by providing the general condition that allows a message to carry control information whose size can be smaller than n. Section 5 provides instantiations of this condition .Section 6 provides a simulation study comparing the behaviors of the proposed protocols .Finally , Section 7 concludes the paper .Due to space limitations , proofs of lemmas and theorems are omitted .They can be found in 1 .", "title": "Tracking Immediate Predecessors in Distributed Computations", "author_keywords_stem": ["causality track", "hasse diagram", "immediate predecessor", "message-pass", "timestamp", "vector clock"], "abstract": "A distributed computation is usually modeled as a partially ordered set of relevant events the relevant events are a subset of the primitive events produced by the computation .An important causality-related distributed computing problem , that we call the Immediate Predecessors Tracking IPT problem , consists in associating with each relevant event , on the fly and without using additional control messages , the set of relevant events that are its immediate predecessors in the partial order .So , IPT is the on-the-fly computation of the transitive reduction i.e. , Hasse diagram of the causality relation defined by a distributed computation .This paper addresses the IPT problem : it presents a family of protocols that provides each relevant event with a timestamp that exactly identifies its immediate predecessors .The family is defined by a general condition that allows application messages to piggyback control information whose size can be smaller than n the number of processes .In that sense , this family defines message size-efficient IPT protocols .According to the way the general condition is implemented , different IPT protocols can be obtained .Two of them are exhibited .", "id": "C-77", "combined_keywords_stem": ["distribut comput", "immedi predecessor track", "common global memori", "messag transfer delai", "vector clock", "track causal", "vector timestamp", "transit reduct", "channel order properti", "ipt protocol", "checkpoint problem", "relev event", "immedi predecessor", "control inform", "piggyback", "causal track", "hass diagram", "messag-pass", "timestamp"], "evaluation": "This section compares the behaviors of the previous protocols .This comparison is done with a simulation study .IPT1 denotes the protocol presented in Section 3.3 that uses the condition K1 m , k which is always equal to false .IPT2 denotes the protocol presented in Section 5.2 that uses the condition K2 m , k where messages carry triples .Finally , IPT3 denotes the protocol presented in Section 5.3 that also uses the condition K2 m , k but where messages carry additional boolean vectors .This section does not aim to provide an in-depth simulation study of the protocols , but rather presents a general view on the protocol behaviors .To this end , it compares IPT2 and IPT3 with regard to IPT1 .More precisely , for IPT2 the aim was to evaluate the gain in terms of triples k , V Ci k , IPi k not transmitted with respect to the systematic transmission of whole vectors as done in IPT1 .For IPT3 , the aim was to evaluate the tradeoff between the additional boolean vectors transmitted and the number of saved triples .The behavior of each protocol was analyzed on a set of programs .The simulator provides different parameters enabling to tune both the communication and the processes features .These parameters allow to set the number of processes for the simulated computation , to vary the rate of communication send/receive events , and to alter the time duration between two consecutive relevant events .Moreover , to be independent of a particular topology of the underlying network , a fully connected network is assumed .Internal events have not been considered .Since the presence of the triples k , V Ci k , IPi k piggybacked by a message strongly depends on the frequency at which relevant events are produced by a process , different time distributions between two consecutive relevant events have been implemented e.g. , normal , uniform , and Poisson distributions .The senders of messages are chosen according to a random law .To exhibit particular configurations of a distributed computation a given scenario can be provided to the simulator .Message transmission delays follow a standard normal distribution .Finally , the last parameter of the simulator is the number of send events that occurred during a simulation .To compare the behavior of the three IPT protocols , we performed a large number of simulations using different parameters setting .We set to 10 the number of processes participating to a distributed computation .The number of communication events during the simulation has been set to 10 000 .The parameter \u03bb of the Poisson time distribution \u03bb is the average number of relevant events in a given time interval has been set so that the relevant events are generated at the beginning of the simulation .With the uniform time distribution , a relevant event is generated in the average every 10 communication events .The location parameter of the standard normal time distribution has been set so that the occurrence of relevant events is shifted around the third part of the simulation experiment .As noted previously , the simulator can be fed with a given scenario .This allows to analyze the worst case scenarios for IPT2 and IPT3 .These scenarios correspond to the case where the relevant events are generated at the maximal frequency i.e. , each time a process sends or receives a message , it produces a relevant event .Finally , the three IPT protocols are analyzed with the same simulation parameters .The results are displayed on the Figures 3.a-3 .d .These figures plot the gain of the protocols in terms of the number of triples that are not transmitted y axis with respect to the number of communication events x axis .From these figures , we observe that , whatever the time distribution followed by the relevant events , both IPT2 and IPT3 exhibit a behavior better than IPT1 i.e. , the total number of piggybacked triples is lower in IPT2 and IPT3 than in IPT1 , even in the worst case see Figure 3 .d .Let us consider the worst scenario .In that case , the gain is obtained at the very beginning of the simulation and lasts as long as it exists a process Pj for which Vk : V Cj k = 0 .In that case , the condition Vk : K m , k is satisfied .As soon as 3k : VCj k = ~ 0 , both IPT2 and IPT3 behave as IPT1 the shape of the curve becomes flat since the condition K m , k is no longer satisfied .Figure 3 .a shows that during the first events of the simulation , the slope of curves IPT2 and IPT3 are steep .The same occurs in Figure 3 .d that depicts the worst case scenario .Then the slope of these curves decreases and remains constant until the end of the simulation .In fact , as soon as V Cj k becomes greater than 0 , the condition K m , k reduces to Mi j , k = 0 V IPi k = 0 .Figure 3 .b displays an interesting feature .It considers \u03bb = 100 .As the relevant events are taken only during the very beginning of the simulation , this figure exhibits a very steep slope as the other figures .The figure shows that , as soon as no more relevant events are taken , on average , 45 % of the triples are not piggybacked by the messages .This shows the importance of matrix Mi .Furthermore , IPT3 benefits from transmitting additional boolean vectors to save triple transmissions .The Figures 3.a-3.c show that the average gain of IPT3 with respect to IPT2 is close to 10 % .Finally , Figure 3.c underlines even more the importance 217 of matrix Mi .When very few relevant events are taken , IPT2 and IPT3 turn out to be very efficient .Indeed , this figure shows that , very quickly , the gain in number of triples that are saved is very high actually , 92 % of the triples are saved .Of course , all simulation results are consistent with the theoretical results .IPT3 is always better than or equal to IPT2 , and IPT2 is always better than IPT1 .The simulation results teach us more : 9 The first lesson we have learnt concerns the matrix Mi .Its use is quite significant but mainly depends on the time distribution followed by the relevant events .On the one hand , when observing Figure 3 .b where a large number of relevant events are taken in a very short time , IPT2 can save up to 45 % of the triples .However , we could have expected a more sensitive gain of IPT2 since the boolean vector IP tends to stabilize to 1 , ... , 1 when no relevant events are taken .In fact , as discussed in Section 5.3 , the management of matrix Mi within IPT2 does not allow a transitive transmission of information but only a direct transmission of this information .This explains why some columns of Mi may remain equal to 0 while they could potentially be equal to 1 .Differently , as IPT3 benefits from transmitting additional boolean vectors providing a transitive transmission information it reaches a gain of 50 % .On the other hand , when very few relevant events are taken in a large period of time see Figure 3 .c , the behavior of IPT2 and IPT3 turns out to be very efficient since the transmission of up to 92 % of the triples is saved .This comes from the fact that very quickly the boolean vector IPi tends to stabilize to 1 , ... , 1 and that matrix Mi contains very few 0 since very few relevant events have been taken .Thus , a direct transmission of the information is sufficient to quickly get matrices Mi equal to 1 , ... , 1 , ... , 1 , ... , 1 .9 The second lesson concerns IPT3 , more precisely , the tradeoff between the additional piggybacking of boolean vectors and the number of triples whose transmission is saved .With n = 10 , adding 10 booleans to a triple does not substantially increases its size .The Figures 3.a-3.c exhibit the number of triples whose transmission is saved : the average gain in number of triples of IPT3 with respect to IPT2 is about 10 % .", "combined_keywords": ["distributed computation", "immediate predecessor tracking", "common global memory", "message transfer delay", "vector clock", "tracking causality", "vector timestamp", "transitive reduction", "channel ordering property", "ipt protocol", "checkpointing problem", "relevant event", "immediate predecessor", "control information", "piggybacking", "causality track", "hasse diagram", "message-pass", "timestamp"], "author_keywords": ["causality track", "hasse diagram", "immediate predecessor", "message-pass", "timestamp", "vector clock"], "method": "A distributed program is made up of sequential local programs which communicate and synchronize only by exchanging messages .A distributed computation describes the execution of a distributed program .The execution of a local program gives rise to a sequential process .Let P1 , P2 , ... , Pn be the finite set of sequential processes of the distributed computation .Each ordered pair of communicating processes Pi , Pj is connected by a reliable channel cij through which Pi can send messages to Pj .We assume that each message is unique and a process does not send messages to itself1 .Message transmission delays are finite but unpredictable .Moreover , channels are not necessarily FIFO .Process speeds are positive but arbitrary .In other words , the underlying computation model is asynchronous .The local program associated with Pi can include send , receive and internal statements .The execution of such a statement produces a corresponding send/receive/internal event .These events are called primitive events .Let exi be the x-th event produced by process Pi .The sequence hi = e1i e2i ... exi ... constitutes the history of Pi , denoted Hi .Let H = Uni = 1Hi be the set of events produced by a distributed computation .This set is structured as a partial order by Lamport 's happened before relation 14 denotedClearly the restriction of hb + to Hi , for a given i , is a total order .Thus we will use the notation exi < eyi iff x < y. Throughout the paper , we will use the following notation : if e E Hi is not the first event produced by Pi , then pred e denotes the event immediately preceding e in the sequence Hi .If e is the first event produced by Pi , then pred e is Ve E Hi : L < e .The partial order H b = H , hb denoted by L meaning that there is no such event , and + constitutes a formal model of the distributed computation it is associated with .For a given observer of a distributed computation , only some events are relevant2 7 , 9 , 15 .An interesting example of `` what an observation is '' , is the detection of predicates on consistent global states of a distributed computation 3 , 6 , 8 , 9 , 13 , 15 .In that case , a relevant event corresponds to the modification of a local variable involved in the global predicate .Another example is the checkpointing problem where a relevant event is the definition of a local checkpoint 10 , 12 , 20 .The left part of Figure 1 depicts a distributed computation using the classical space-time diagram .In this figure , only relevant events are represented .The sequence of relevant events produced by process Pi is denoted by Ri , and R = Uni = 1Ri C _ H denotes the set of all relevant events .Let + be the relation on R defined in the following way : ` d e , f ERxR : e + f 4 * e hb + f .The poset R , + constitutes an abstraction of the distributed computation 7 .In the following we consider a distributed computation at such an abstraction level .Moreover , without loss of generality we consider that the set of relevant events is a subset of the internal events if a communication event has to be observed , a relevant internal event can be generated just before a send and just after a receive communication event occurred .Each relevant event is identified by a pair process id , sequence number see Figure 1 .Note that , if e E R then 1 e = f E R I f + e .In the computation described in Figure 1 , we have , for the event e identified 2 , 2 : 1 e = 1 , 1 , 1 , 2 , 2 , 1 , 3 , 1 .The following properties are immediate consequences of the previous definitions .Let e E H.Let us consider the event e identified 2,2 in Figure 1 .We have lastr e , 1 = 1 , 2 , lastr e , 2 = 2 , 1 , lastr e , 3 = 3 , 1 .The following properties relate the events lastr e , j and lastr f , j for all the predecessors f of e in the relation + .These properties follow directly from the definitions .LR2 If e is a receive event of m : ` dj = ~ i : lastr e , j = max lastr pred e , j , lastr send m , j .Definition As a fundamental concept associated with the causality theory , vector clocks have been introduced in 1988 , simultaneously and independently by Fidge 5 and Mattern 16 .A vector clock system is a mechanism that associates timestamps with events in such a way that the comparison of their timestamps indicates whether the corresponding events are or are not causally related and , if they are , which one is the first .More precisely , each process Pi has a vector of integers VCi 1 ..n such that V Ci j is the number of relevant events produced by Pj , that belong to the current relevant causal past of Pi .Note that VCi i counts the number of relevant events produced so far by Pi .When a process Pi produces a relevant event e , it associates with e a vector timestamp whose value denoted e.V C is equal to the current value of VCi .Vector Clock Implementation The following implementation of vector clocks 5 , 16 is based on the observation that ` di , ` de E Hi , ` dj : e.V Ci j = y 4 * lastr e , j = ey j where e.V Ci is the value of V Ci just after the occurrence of e this relation results directly from the properties LR0 , LR1 , and LR2 .Each process Pi manages its vector clock V Ci 1 ..n according to the following rules :indicate it has produced one more relevant event , then Pi associates with e the timestamp e.VC = V Ci .VC2 When a process Pi sends a message m , it attaches to m the current value of VCi .Let m.V C denote this value .VC3 When Pi receives a message m , it updates its vector clock as follows : ` dk : VCi k : = max VCi k , m.V C k .In this section , the Immediate Predecessor Tracking IPT problem is stated Section 3.1 .Then , some technical properties of immediate predecessors are stated and proved Section 3.2 .These properties are used to design the basic IPT protocol and prove its correctness Section 3.3 .This IPT protocol , previously presented in 4 without proof , is built from a vector clock protocol by adding the management of a local boolean array at each process .As indicated in the introduction , some applications e.g. , analysis of distributed executions 6 , detection of distributed properties 7 require to determine on-the-fly and without additional messages the transitive reduction of the relation + i.e. , we must not consider transitive causal dependency .Given two relevant events f and e , we say that f is an immediate predecessor of e if f + e and there is no relevant event g such that f + g + e.As noted in the Introduction , the IPT problem is the computation of the Hasse diagram associated with the partially ordered set of the relevant events produced by a distributed computation .In order to design a protocol solving the IPT problem , it is useful to consider the notion of immediate relevant predecessor of any event , whether relevant or not .First , we observe that , by definition , the immediate predecessor on Pj of an event e is necessarily the lastr e , j event .Second , for lastr e , j to be immediate predecessor of e , there must not be another lastr e , k event on a path between lastr e , j and e .These observations are formalized in the following definition :It follows from this definition that ZP e C _ lastr e , j | j = 1 , ... , n CT e .When we consider Figure 1 , The graph depicted in its right part describes the immediate predecessors of the relevant events of the computation defined in its left part , more precisely , a directed edge e , f means that the relevant event e is an immediate predecessor of the relevant event f 3 .The following lemmas show how the set of immediate predecessors of an event is related to those of its predecessors in the relation hb + .They will be used to design and prove the protocols solving the IPT problem .To ease the reading of the paper , their proofs are presented in Appendix A .The intuitive meaning of the first lemma is the following : if e is not a receive event , all the causal paths arriving at e have pred e as next-to-last event see CP1 .So , if pred e is a relevant event , all the relevant events belonging to its relevant causal past are `` separated '' from e by pred e , and pred e becomes the only immediate predecessor of e .In other words , the event pred e constitutes a `` reset '' w.r.t. the set of immediate predecessors of e. On the other hand , if pred e is not relevant , it does not separate its relevant causal past from e.The intuitive meaning of the next lemma is as follows : if e is a receive event receive m , the causal paths arriving at e have either pred e or send m as next-to-last events .If pred e is relevant , as explained in the previous lemma , this event `` hides '' from e all its relevant causal past and becomes an immediate predecessor of e. Concerning the last relevant predecessors of send m , only those that are not predecessors of pred e remain immediate predecessors of e.The intuitive meaning of the next lemma is the following : if e is a receive event receive m , and pred e is not relevant , the last relevant events in the relevant causal past of e are obtained by merging those of pred e and those of send m and by taking the latest on each process .So , the immediate predecessors of e are either those of pred e or those of send m .On a process where the last relevant events of pred e and of send m are the same event f , none of the paths from f to e must contain another relevant event , and thus , f must be immediate predecessor of both events pred e and send m .The basic protocol proposed here associates with each relevant event e , an attribute encoding the set ZP e of its immediate predecessors .From the previous lemmas , the set 3Actually , this graph is the Hasse diagram of the partial order associated with the distributed computation .213 ZP e of any event e depends on the sets ZP of the events pred e and/or send m when e = receive m .Hence the idea to introduce a data structure allowing to manage the sets ZPs inductively on the poset H , hb \u2192 .To take into account the information from pred e , each process manages a boolean array IPi such that , ` de E Hi the value of IPi when e occurs denoted e.IPi is the boolean array representation of the set ZP e .More precisely , ` dj : IPi j = 1 4 * lastr e , j E ZP e .As recalled in Section 2.3 , the knowledge of lastr e , j for every e and every j is based on the management of vectors VCi .Thus , the set ZP e is determined in the following way :Each process Pi updates IPi according to the Lemmas 1 , 2 , and 3 :particular , as stated in the Lemmas , the determination of succ e .IPi depends on whether e is relevant or not .Thus , the value of IPi just after the occurrence of event e must `` keep track '' of this event .The following protocol , previously presented in 4 without proof , ensures the correct management of arrays V Ci as in Section 2.3 and IPi according to the Lemmas of Section 3.2 .The timestamp associated with a relevant event e is denoted e.TS .The proof of the following theorem directly follows from Lemmas 1 , 2 and 3 .This section addresses a previously open problem , namely , `` How to solve the IPT problem without requiring each application message to piggyback a whole vector clock and a whole boolean array ? ''.First , a general condition that characterizes which entries of vectors V Ci and IPi can be omitted from the control information attached to a message sent in the computation , is defined Section 4.1 .It is then shown Section 4.2 that this condition is both sufficient and necessary .However , this general condition can not be locally evaluated by a process that is about to send a message .Thus , locally evaluable approximations of this general condition must be defined .To each approximation corresponds a protocol , implemented with additional local data structures .In that sense , the general condition defines a family of IPT protocols , that solve the previously open problem .This issue is addressed in Section 5 .Let us consider the previous IPT protocol Section 3.3 .Rule R3 shows that a process Pj does not systematically update each entry V Cj k each time it receives a message m from a process Pi : there is no update of V Cj k when V Cj k > m.V C k .In such a case , the value m.V C k is useless , and could be omitted from the control information transmitted with m by Pi to Pj .Similarly , some entries IPj k are not updated when a message m from Pi is received by Pj .This occurs when 0 < V Cj k = m.V C k n m.IP k = 1 , or when V Cj k > m.V C k , or when m.VC k = 0 in the latest case , as m.IP k = IPi k = 0 then no update of IPj k is necessary .Differently , some other entries are systematically reset to 0 this occurs when 0 < V Cj k = m.V C k n m.IP k = 0 .These observations lead to the definition of the condition K m , k that characterizes which entries of vectors V Ci and IPi can be omitted from the control information attached to a message m sent by a process Pi to a process Pj :We show here that the condition K m , k is both necessary and sufficient to decide which triples of the form k , send m .V Ci k , send m .IPi k can be omitted in an outgoing message m sent by Pi to Pj .A triple attached to m will also be denoted k , m.V C k , m.IP k .Due to space limitations , the proofs of Lemma 4 and Lemma 5 are given in 1 .The proof of Theorem 2 follows directly from these lemmas .It results from the previous theorem that , if Pi could evaluate K m , k when it sends m to Pj , this would allow us improve the previous IPT protocol in the following way : in rule R2 , the triple k , V Ci k , IPi k is transmitted with m only if K m , k .Moreover , rule R3 is appropriately modified to consider only triples carried by m. However , as previously mentioned , Pi can not locally evaluate K m , k when it is about to send m .More precisely , when Pi sends m to Pj , Pi knows the exact values of send m .V Ci k and send m .IPi k they are the current values of V Ci k and IPi k .But , as far as the value of pred receive m .VCj k is concerned , two cases are possible .Case i : If pred receive m hb \u2192 send m , then Pi can know the value of pred receive m .VCj k and consequently can evaluate K m , k .Case ii : If pred receive m and send m are concurrent , Pi can not know the value of pred receive m .VCj k and consequently can not evaluate K m , k .Moreover , when it sends m to Pj , whatever the case i or ii that actually occurs , Pi has no way to know which case does occur .Hence the idea to define evaluable approximations of the general condition .Let K ' m , k be an approximation of K m , k , that can be evaluated by a process Pi when it sends a message m. To be correct , the condition K ' must ensure that , every time Pi should transmit a triple k , VCi k , IPi k according to Theorem 2 i.e. , each time K m , k , then Pi transmits this triple when it uses condition K ' .Hence , the definition of a correct evaluable approximation :This definition means that a protocol evaluating K ' to decide which triples must be attached to messages , does not miss triples whose transmission is required by Theorem 2 .Let us consider the `` constant '' condition denoted K1 , that is always false , i.e. , V m , k : K1 m , k = false .This trivially correct approximation of K actually corresponds to the particular IPT protocol described in Section 3 in which each message carries a whole vector clock and a whole boolean vector .The next section presents a better approximation of K denoted K2 .locally evaluated while the others can not .More precisely , K = _ a V \u03b1 V , Q n b , where a = _ send m .VCi k = 0 and b = _ send m .IPi k = 1 are locally evaluable , whereas \u03b1 = _ send m .V Ci k < pred receive m .VCj k and , Q = _ send m .V Ci k = pred receive m .VCj k are not .But , from easy boolean calculus , a V \u03b1V , Q nb == : > .aV\u03b1VSo , Pi needs to approximate the predicate send m .VCi k < pred receive m .VCj k .To be correct , this approximation has to be a locally evaluable predicate ci j , k such that , when Pi is about to send a message m to Pj , ci j , k = : > .send m .V Ci k < pred receive m .VCj k .Informally , that means that , when ci j , k holds , the local context of Pi allows to deduce that the receipt of m by Pj will not lead to VCj k update `` Pj knows as much as Pi about Pk '' .Hence , the `` concrete '' condition K2 is the following : K2 = _ send m .VCi k = 0 V ci j , k n send m .IPi k = 1 .Let us now examine the design of such a predicate denoted ci .First , the case j = i can be ignored , since it is assumed Section 2.1 that a process never sends a message to itself .Second , in the case j = k , the relation send m .V Ci j < pred receive m .VCj j is always true , because the receipt of m by Pj can not update VCj j .Thus , Vj = ~ i : ci j , j must be true .Now , let us consider the case where j = ~ i and j = ~ k Figure 2 .Suppose that there exists an event e ' = receive m ' with e ' < send m , m ' sent by Pj and piggybacking the triple k , m ' .V C k , m ' .IP k , and m ' .V C k > VCi k hence m ' .V C k = receive m ' .V Ci k .As V Cj k can not decrease this means that , as long as V Ci k does not increase , for every message m sent by Pi to Pj we have the following : send m .V Ci k = receive m ' .V Ci k = send m ' .V Cj k < receive m .VCj k , i.e. , ci j , k must remain true .In other words , once ci j , k is true , the only event of Pi that could reset it to false is either the receipt of a message that increases VCi k or , if k = i , the occurrence of a relevant event that increases V Ci i .Similarly , once ci j , k is false , the only event that can set it to true is the receipt of a message m ' from Pj , piggybacking the triple k , m ' .V C k , m ' .IP k with m ' .V C k > VCi k .In order to implement the local predicates ci j , k , each process Pi is equipped with a boolean matrix Mi as in 11 such that M j , k = 1 4 * ci j , k .It follows from the previous discussion that this matrix is managed according to the following rules note that its i-th line is not significant case j = i , and that its diagonal is always equal to 1 :The following lemma results from rules M0-M3 .The theorem that follows shows that condition K2 m , k is correct .Both are proved in 1 .The complete text of the IPT protocol based on the previous discussion follows .4Actually , the value of this column remains constant after its first update .In fact , \u2200 j , Mi j , i can be set to 1 only upon the receipt of a message from Pj , carrying the value VCj i see R3 .But , as Mj i , i = 1 , Pj does not send VCj i to Pi .So , it is possible to improve the protocol by executing this `` reset '' of the column Mi \u2217 , i only when Pi produces its first relevant event .endcaseThe condition K2 m , k shows that a triple has not to be transmitted when Mi j , k = 1 \u2227 IPi k = 1 \u2228 VCi k > 0 .Let us first observe that the management of IPi k is governed by the application program .More precisely , the IPT protocol does not define which are the relevant events , it has only to guarantee a correct management of IPi k .Differently , the matrix Mi does not belong to the problem specification , it is an auxiliary variable of the IPT protocol , which manages it so as to satisfy the following implication when Pi sends m to Pj : Mi j , k = 1 \u21d2 pred receive m .VCj k \u2265 send m .VCi k .The fact that the management of Mi is governed by the protocol and not by the application program leaves open the possibility to design a protocol where more entries of Mi are equal to 1 .This can make the condition K2 m , k more often satisfied5 and can consequently allow the protocol to transmit less triples .We show here that it is possible to transmit less triples at the price of transmitting a few additional boolean vectors .The previous IPT matrix-based protocol Section 5.2 is modified in the following way .The rules RM2 and RM3 are replaced with the modified rules RM2 ' and RM3 ' Mi \u2217 , k denotes the kth column of Mi .Similarly to the proofs described in 1 , it is possible to prove that the previous protocol still satisfies the property proved in Lemma 6 , namely , \u2200 i , \u2200 m sent by Pi to Pj , \u2200 k we have send m .Mi j , k = 1 \u21d2 send m .VCi k \u2264 pred receive m .VCj k .5Let us consider the previously described protocol Section 5.2 where the value of each matrix entry Mi j , k is always equal to 0 .The reader can easily verify that this setting correctly implements the matrix .Moreover , K2 m , k is then always false : it actually coincides with K1 k , m which corresponds to the case where whole vectors have to be transmitted with each message .216 Intuitively , the fact that some columns of matrices M are attached to application messages allows a transitive transmission of information .More precisely , the relevant history of Pk known by Pj is transmitted to a process Pi via a causal sequence of messages from Pj to Pi .In contrast , the protocol described in Section 5.2 used only a direct transmission of this information .In fact , as explained Section 5.1 , the predicate c locally implemented by the matrix M was based on the existence of a message m ' sent by Pj to Pi , piggybacking the triple k , m ' .V C k , m ' .IP k , and m ' .V C k > V Ci k , i.e. , on the existence of a direct transmission of information by the message m ' .The resulting IPT protocol defined by the rules RM0 , RM1 , RM2 ' and RM3 ' uses the same condition K2 m , k as the previous one .It shows an interesting tradeoff between the number of triples k , V Ci k , IPi k whose transmission is saved and the number of boolean vectors that have to be additionally piggybacked .It is interesting to notice that the size of this additional information is bounded while each triple includes a non-bounded integer namely a vector clock value .", "conclusions": "This paper has addressed an important causality-related distributed computing problem , namely , the Immediate Predecessors Tracking problem .It has presented a family of protocols that provide each relevant event with a timestamp that exactly identify its immediate predecessors .The family is defined by a general condition that allows application messages to piggyback control information whose size can be smaller than n the number of processes .In that sense , this family defines message size-efficient IPT protocols .According to the way the general condition is implemented , different IPT protocols can be obtained .Three of them have been described and analyzed with simulation experiments .Interestingly , it has also been shown that the efficiency of the protocols measured in terms of the size of the control information that is not piggybacked by an application message depends on the pattern defined by the communication events and the relevant events .Last but not least , it is interesting to note that if one is not interested in tracking the immediate predecessor events , the protocols presented in the paper can be simplified by suppressing the IPi booleans vectors but keeping the boolean matrices Mi .The resulting protocols , that implement a vector clock system , are particularly efficient as far as the size of the timestamp carried by each message is concerned .Interestingly , this efficiency is not obtained at the price of additional assumptions such as FIFO channels ."}